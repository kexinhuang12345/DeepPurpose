{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import DTI.models as models\n",
    "from DTI.utils import data_process, convert_y_unit, generate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total: 133 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 87\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 113\n",
      "-- Encoding AAC takes time. Time Reference: 24s for ~100 sequences in a CPU. Calculate your time by the unique target sequence #, instead of the entire dataset.\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df_Kd = pd.read_csv('./DTBA_data_folder/Kd/data.csv')\n",
    "df_Kd = df_Kd.sample(frac = 0.002, replace = False)# toy dataset\n",
    "\n",
    "X_drug = df_Kd.SMILES.values\n",
    "X_target = df_Kd['Target Sequence'].values \n",
    "# support nM to p (logspace) convertion to help regression\n",
    "y = convert_y_unit(df_Kd.Kd.values, 'nM', 'p') \n",
    "\n",
    "drug_encoding = 'ECFP4'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup, you can adjust the config file by typing in model parameters. e.g. cls_hidden_dim = [256, 32]\n",
    "config = generate_config(drug_encoding, target_encoding)\n",
    "model = models.model_initialize(drug_encoding, target_encoding, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 49.618973\n",
      "Validation at Epoch 1 , MSE: 13.385996113479642 , Pearson Correlation: -0.18776432138026336 with p-value: 0.5390282621855491 , Concordance Index: 0.4722222222222222\n",
      "Training at Epoch 2 iteration 0 with loss 1.9656172\n",
      "Validation at Epoch 2 , MSE: 12.268444797253498 , Pearson Correlation: -0.35187780208393715 with p-value: 0.2383721211216671 , Concordance Index: 0.5138888888888888\n",
      "Training at Epoch 3 iteration 0 with loss 0.000382868\n",
      "Validation at Epoch 3 , MSE: 9.817124640453986 , Pearson Correlation: -0.1032013980740257 with p-value: 0.7372460543155873 , Concordance Index: 0.5555555555555556\n",
      "Training at Epoch 4 iteration 0 with loss 0.7580768\n",
      "Validation at Epoch 4 , MSE: 10.609886467775194 , Pearson Correlation: -0.15560934723718006 with p-value: 0.6117088807588327 , Concordance Index: 0.4861111111111111\n",
      "Training at Epoch 5 iteration 0 with loss 0.019163823\n",
      "Validation at Epoch 5 , MSE: 14.575248966855192 , Pearson Correlation: -0.18863690796088464 with p-value: 0.537109102191674 , Concordance Index: 0.5138888888888888\n",
      "Training at Epoch 6 iteration 0 with loss 6.1597958\n",
      "Validation at Epoch 6 , MSE: 16.76627257588861 , Pearson Correlation: -0.4793489966843707 with p-value: 0.09742585652497394 , Concordance Index: 0.3611111111111111\n",
      "Training at Epoch 7 iteration 0 with loss 4.295676\n",
      "Validation at Epoch 7 , MSE: 15.081754546178077 , Pearson Correlation: -0.5088121939608389 with p-value: 0.0757815252444298 , Concordance Index: 0.4305555555555556\n",
      "Training at Epoch 8 iteration 0 with loss 2.6369812\n",
      "Validation at Epoch 8 , MSE: 17.854209325448284 , Pearson Correlation: -0.37185847087854296 with p-value: 0.2108869556884366 , Concordance Index: 0.4861111111111111\n",
      "Training at Epoch 9 iteration 0 with loss 3.6412065\n",
      "Validation at Epoch 9 , MSE: 25.40246347390782 , Pearson Correlation: -0.017435016141205052 with p-value: 0.9549179262066764 , Concordance Index: 0.5833333333333334\n",
      "Training at Epoch 10 iteration 0 with loss 4.592439\n",
      "Validation at Epoch 10 , MSE: 20.676706094504976 , Pearson Correlation: 0.04886406453126471 with p-value: 0.8740451780334413 , Concordance Index: 0.6388888888888888\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 2.955977707346394 , Pearson Correlation: 0.1086863644075014 with p-value: 0.5894518086193065 , Concordance Index: 0.5230769230769231\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test['Target Sequence'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_repurpose = test.SMILES.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test.target_encoding.iloc[0]\n",
    "x = test.drug_encoding.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.tile(t, (len(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.7370],\n",
       "        [6.8289],\n",
       "        [6.6317],\n",
       "        [7.0390],\n",
       "        [6.4034],\n",
       "        [6.7295],\n",
       "        [6.8686],\n",
       "        [5.8693],\n",
       "        [6.8866],\n",
       "        [6.6668],\n",
       "        [6.4435],\n",
       "        [6.7394],\n",
       "        [6.5740],\n",
       "        [6.7912],\n",
       "        [6.5648],\n",
       "        [6.7815],\n",
       "        [6.8936],\n",
       "        [6.8324],\n",
       "        [6.1336],\n",
       "        [5.9698],\n",
       "        [6.0565],\n",
       "        [6.8936],\n",
       "        [7.1831],\n",
       "        [6.8331],\n",
       "        [6.7370],\n",
       "        [6.4034],\n",
       "        [7.1325]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.repurpose((torch.Tensor(np.vstack(x).astype(np.float)), torch.Tensor(t)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
