{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Training models with DeepPurpose.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XcQNiphHfFl"
   },
   "source": [
    "### Loading DeepPurpose"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SHgfNjHvVkDy"
   },
   "source": [
    "!pip install git+https://github.com/yazdanimehdi/DeepPurpose\n",
    "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
    "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
    "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
    "! conda install -c rdkit rdkit -y\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "brzFhG-VV4G_"
   },
   "source": [
    "!pip install git+https://github.com/bp-kelley/descriptastorus"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2howcQ-KV4Ai"
   },
   "source": [
    "import rdkit\n",
    "import DeepPurpose"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlVCaPfjV380",
    "outputId": "3644a359-03a7-4cb6-e9cf-72dc55abe519"
   },
   "source": [
    "from DeepPurpose import DTI as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P44bsp4THZrE"
   },
   "source": [
    "### Loading BindingDB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TaUcw-_czjNY"
   },
   "source": [
    "import os\n",
    "os.chdir('../')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BMwZd6hZ3bD2"
   },
   "source": [
    "def download_BindingDB_edited(path = './data'):\n",
    "\n",
    "\tprint('Beginning to download dataset...')\n",
    "\n",
    "\tif not os.path.exists(path):\n",
    "\t    os.makedirs(path)\n",
    "\n",
    "\turl = 'https://www.bindingdb.org/bind/downloads/BindingDB_All_2021m4.tsv.zip'\n",
    "\tsaved_path = wget.download(url, path)\n",
    "\n",
    "\tprint('Beginning to extract zip file...')\n",
    "\twith ZipFile(saved_path, 'r') as zip:\n",
    "\t    zip.extractall(path = path)\n",
    "\t    print('Done!')\n",
    "\tpath = path + '/BindingDB_All.tsv'\n",
    "\treturn path"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PE2jUIvf3kww"
   },
   "source": [
    "X_drug, X_target, y  = process_BindingDB(download_BindingDB_edited('../data/BindingDB_All.tsv'),\n",
    "\t\t\t\t\t y = 'IC50', \n",
    "\t\t\t\t\t binary = True, \n",
    "\t\t\t\t\t convert_to_log = False,\n",
    "           threshold=30)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLDYFbgHHNCu"
   },
   "source": [
    "### Morgan-AAC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rn_KYDOH9wTv"
   },
   "source": [
    "drug_encoding, target_encoding = 'Morgan', 'AAC'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfbN5k5t9wMX",
    "outputId": "228cd6a1-7018-4270-f1d6-28900bed7f95"
   },
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random', \n",
    "                                frac=[0.7,0.1,0.2],\n",
    "                                random_seed=1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 1309264 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 650166\n",
      "rdkit not found this smiles for morgan: CC(C)(C)OC(=O)N1CC(=O)N(C(=O)C1)c1ccc(cc1)N1CC(COC(=O)[N]2=CC=C(Cl)S2)OC1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CSc1ccc(cc1)C1=C(C=C[N]([O-])=C1)[C@@H]1CCC(F)(F)C[C@H]1C(=O)NCC#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C1NC(=O)c2c1c1c3ccccc3n3[Ru](C#[O])[n+]4cccc2c4c13 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C(=O)c2c(C1=O)c1cc(F)c[n+]3[Ru](C#[O])n4c5ccc(O)cc5c2c4c13 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(CC[N]23CC4=CC=CC=[N]4[Re+]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(CC[N@@]23CC(=O)O[Re]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=C[N]2=C1C[N]1(CCc3ccc(SOON)cc3)CC3=[N](C=CN3C)[Re+]21 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(NC(=S)NCCCCCCCC[N]23CC4=CC=CC=[N]4[Re+]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(NC(=S)NCCOCCOCC[N]23CC4=CC=CC=[N]4[Re+]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(NC(=S)NCCCCC[N]23CC4=CC=CC=[N]4[Re+]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NOOSc1ccc(NC(=S)NCCCCCCCC[N@@]23CC(=O)O[Re]2[N]2=C(C3)C=CC=C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=C[N]2=C1C[N]1(CCCCCCCCCCNC(=S)Nc3ccc(SOON)cc3)CC3=[N](C=CN3C)[Re+]21 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OB(O)C1CCCN1C(=O)CNC(=O)CCCCC[N]12CC3=CC=CC=[N]3[Re+]1[N]1=C(C2)C=CC=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OB(O)C1CCCN1C(=O)CNC(=O)CCCCC[N@@]12CC(=O)O[Re]1[N]1=C(C2)C=CC=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=C[N]2=C1C[N]1(CCCCCC(=O)NCC(=O)N3CCCC3B(O)O)CC3=[N](C=CN3C)[Re+]21 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(O)CCC[C@H]1c1cccnc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CCC[C@H]1c1cccnc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c(Nc2c(Cl)ccc(CNC(=O)C3=CC=CC=[N]3O)c2Cl)nc2cc(C(=O)NCCC(F)(F)F)c(cc12)N1CCC(CC1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C(C)[N]1=CC=C(F)C=C1)c1cc(cc2c1oc(cc2=O)N1CCOCC1)C(=O)N(C)C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: ONC(=O)c1ccc(CNC(=O)c2nc(cc2-c2ccc(F)cc2)-c2cccs2)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)Nc1nc(cc2ncn(C)c(=O)c12)C1=CC=C(N2CCOCC2)[N](O)=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1Cc2nn(C)c(c2-c2nc(NC3=[N](C)NC(C)=C3)ncc12)-c1ccccc1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[N]1=C(C=CC=C1)c1ccc(cc1)C(=O)NC\\C=C\\CN1CCN(CC1)c1cccc(Cl)c1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [OH2+][V]12([OH2+])(=O)OC(=O)c3ccccc3[N]1=Cc1cc(Br)ccc1O2 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [OH2+][V]12([OH2+])(=O)OC(=O)c3ccccc3[N]1=Cc1cc(ccc1O2)[N+]([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc2O[V]3(=O)(Oc4ccc(Cl)cc4C=[N]3c3ccccc3)[N](=Cc2c1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Brc1ccc2O[V]3(=O)(Oc4ccc(Br)cc4C=[N]3c3ccccc3)[N](=Cc2c1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [O-][N+](=O)c1ccc2O[V]3(=O)(Oc4ccc(cc4C=[N]3c3ccccc3)[N+]([O-])=O)[N](=Cc2c1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC[N]1(CC)CCN(CCOc2ccc3[nH]c(=O)c4CCCNc4c3c2)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(C[N](C)(C)C2CCCC2)cc2[nH]c(=O)c3CCCNc3c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=C2C(N(C(=O)C2=[N](N1)C1CC1)c1cc(C)c(=O)n(C)c1)c1ccc(Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1[nH]c(C(=O)NCc2ccc(F)cc2)\\c(=N\\O)c2ncccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: ON(=O)c1cccc(N\\N=C2/C(=O)Nc3ccccc23)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: ON(=O)c1cccc(N\\N=C2/C(=O)Nc3ccc(cc23)S(O)(=O)=O)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [H][N]1([H])CCN(CC1)c1ncnc2sc3CCCCc3c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [H][N]1(C)CCCN(CC1)c1ncnc2sccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)Cc1ccc(cc1)-c1cc(N(C)[C@H]2CC[C@@H](CC2)NC(C)=O)c(C)c(c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)Cc1ccc(cc1)-c1cc(N(C)[C@@H]2CC[C@@H](CC2)NC(C)=O)c(C)c(c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)Cc1ccc(cn1)-c1cc(N(C)[C@@H]2CC[C@@H](CC2)NC(C)=O)c(C)c(c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN([C@@H]1CC[C@@H](CC1)NC(C)=O)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CO)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)Cc1ccc(cc1)-c1cc(N(C)[C@H]2CC[C@H](N)CC2)c(C)c(c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1cnn(C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN(C)C)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCN(C)CC2)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(C)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1cccc(CN2CCOCC2)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CC(CN3CCOCC3)C2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(C)c(CNC(=O)c2cc(cc(NC3CCOCC3)c2C)-c2ccc(CN3CCOCC3)cc2)c(=O)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCNc1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(CO)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)N(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(cc1)C(=O)N1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCN(CC1)S(C)(=O)=O)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCN(CC1)C(C)=O)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCNCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCN(CC1)C(=O)C(C)(C)C)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN([C@H]1CC[C@H](N)CC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN([C@H]1CC[C@@H](CC1)NC(C)=O)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(c(F)c(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2=O)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCSCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCS(=O)CC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)c(C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCS(=O)(=O)CC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)[nH]c2=O)c1C)-c1ccc(C[N]2(O)CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(C)c(CNC(=O)c2cc(cc(N(CC(F)(F)F)C3CCOCC3)c2C)-c2ccc(CN3CCOCC3)cc2)c(=O)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1CC)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)c(c1)C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN([C@H]1CC[C@@H](CC1)N(C)C)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1c(Nc2ccccc2)nc2cnc(Nc3ccc(cc3)C(=O)N[N]3=CCN(C)CC3)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1c(Nc2cccc(NC(C)=O)c2)nc2cnc(Nc3ccc(cc3F)C(=O)N[N]3=CCN(C)CC3)nc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C1OC[C@@H](N1c1ccn2cc[nH]c2c1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C1O[C@@H]([C@@H](N1c1ccn2cc[nH]c2c1)c1ccccc1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCOc1ccc(cc1)[C@H]1COC(=O)N1c1ccn2cc[nH]c2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(cc1)[C@H]1COC(=O)N1c1ccn2cc[nH]c2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC[C@@H](N[C@@H](C)CC(N)=O)c1ccc(Cl)c(C(=O)C2=CC=[N]([O-])C=C2)c1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=N[N](C)=C(C)C1N[S+]([O-])(=O)c1c(Cl)cc(cc1Cl)-c1cccc2CNCCc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=C(CC=N1)Nc1cc(ncc1C(=O)NC[C@@H](F)C(C)(C)O)-n1ccc2cc(cnc12)C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cn1)-c1cc(NC(=O)C2=C3N=CC=C[N]3=NC2)n(n1)-c1ccc(C)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(cc1)-n1nc(cc1NC(=O)C1=C2N=CC=C[N]2=NC1)C1=CCN(CC1)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(C)nc12)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)C1CC1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCOCC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(CN2CCCN(C)CC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN([C@H]1CC[C@@H](CC1)N(C)C)c1cc(Cl)cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNC(=O)C1=CC(CCCN2CCOCC2)[N](=C1C)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2c[nH]n(CC(=O)Nc3nc(cs3)-c3cc(F)c(OCC(C)(C)C)c(F)c3)c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2c[nH]n(CC(=O)Nc3nc(cs3)-c3cc(F)c(OCC(C)(C)C)c(Cl)c3)c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2c[nH]n(CC(=O)Nc3nc(cs3)-c3cc(F)c(OCC4CCC4)c(F)c3)c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2c[nH]n(CC(=O)Nc3nc(cs3)-c3cc(Cl)c(OCC(C)(C)C)c(Cl)c3)c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2c[nH]n(CC(=O)Nc3nc(cs3)-c3ccc(OCC(C)(C)C)c(F)c3)c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c2=[N]=C[N](CC(=O)Nc3nc(cs3)-c3ccc(Br)cc3)=c2c(=O)n(C)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(N1N=C(CC1c1ccccc1)c1cnc2ccccc12)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(C)CCN(CC1)c1ccc(cn1)-c1nc(oc1Sc1ccc(Cl)cc1)C1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCC[N]1=NC(N=C1C)c1ccc2ncc(C(=O)Nc3cc(ccc3C)-c3noc(n3)C3CC(F)(F)C3)n2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)CCc1c(CC(=O)OCC)cnc1\\C=N\\O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)C=C(C#N)C(=O)N1CCC(Cc2nc(C3CCC(CC3)Oc3ccccc3)c3c(N)ncnc23)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C(N1CCC(CC1)c1nnn2cnc3[nH]ccc3c12)C1=C[N]2=C(S1)C=CC=C2 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: [N-]=[N]=NC[C@H]1CC[C@@H](CC1)c1nnn2cnc3[nH]ccc3c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1CC(C1)[N]1=CNc2cc(NC(=O)N[C@H](C)c3ccc(F)cc3)ncc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=C(c2cnc(N)c(n2)-c2ccc(C(=O)NCc3cccc(c3)S(C)(=O)=O)c(F)c2)[N](C)=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(N1CCN(CC1)c1ccc(cc1)C#N)n1sc2[nH]cccc2c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)N1CCN(CC1)C(=O)n1sc2[nH]cccc2c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(C1CC1)N1CCN(CC1)C(=O)n1sc2[nH]cccc2c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cc1OC)C(=O)N1CCN(CC1)C(=O)n1sc2[nH]cccc2c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc2ccccc2c1-c1ccc(cc1)C(=O)NO convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(-c2ccc(cc2)C(=O)NO)c2ccccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: ONC(=O)c1ccc(cc1)-c1cc(Cc2ccccc2)c2ccccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)CCc1cc(-c2ccc(cc2)C(=O)NO)c2ccccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1CCN(CCc2cc(-c3ccc(cc3)C(=O)NO)c3ccccc23)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)OC(=O)N(C1CC1)C1=NC(=C[N]2=C(\\C=C3/NC(=O)NC3=O)C=NC12)c1cccc(OC(F)(F)F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C1NC(=O)\\C(N1)=C\\C1=[N]2C=C(N=C(NC3CC3)C2N=C1)C#Cc1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C1NC(=O)\\C(N1)=C\\C1=[N]2C=C(N=C(NC3CC3)C2N=C1)c1cccc(CN2CCOCC2)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)(F)Oc1cccc(c1)C1=C[N]2=C(\\C=C3/NC(=O)NC3=O)C=NC2C(NC2CC2)=N1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Fc1cccc(c1)C1=C[N]2=C(\\C=C3/NC(=O)NC3=O)C=NC2C(NC2CC2)=N1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(O)c1nc(ncc1F)N1C[C@H]2CSC(N)=[N]([C@H]2C1)c1cnccn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)(F)c1cccc(Nc2ccc3C(CCCN4CCOCC4)[N](=Cc3c2)c2ccccc2)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)NC(=O)[C@@H]1C[C@H]2C[C@H]2N1C(=O)C[N]1#[N]=C(C(C)=O)c2cc(OCc3ncccn3)ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NS(=O)(=O)c1nnc(s1)N1C(=O)C2=[N](N(C(=C2C(=O)c2ccccc2)c2ccccc2)c2cccc(c2)[N+]([O-])=O)[Co]11N(C(=O)C2=[N]1N(C(=C2C(=O)c1ccccc1)c1ccccc1)c1cccc(c1)[N+]([O-])=O)c1nnc(s1)S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NS(=O)(=O)c1nnc(s1)N1C(=O)C2=[N](N(C(=C2C(=O)c2ccccc2)c2ccccc2)c2cccc(c2)[N+]([O-])=O)[Ni]11N(C(=O)C2=[N]1N(C(=C2C(=O)c1ccccc1)c1ccccc1)c1cccc(c1)[N+]([O-])=O)c1nnc(s1)S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NS(=O)(=O)c1nnc(s1)N1C(=O)C2=[N](N(C(=C2C(=O)c2ccccc2)c2ccccc2)c2cccc(c2)[N+]([O-])=O)[Cu]11N(C(=O)C2=[N]1N(C(=C2C(=O)c1ccccc1)c1ccccc1)c1cccc(c1)[N+]([O-])=O)c1nnc(s1)S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(c1nc(nc2N3CCOC[C@H]3COc12)[N]1=C(N)Nc2ccccc12)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(c1nc(nc2N3CCOC[C@H]3COc12)[N]1=C(Nc2ccccc12)N1CCOCC1)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)(F)CN1CCC(CC1)S(=O)c1ccc(CNC(=O)[N]2=Cc3ccncc3O2)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1nccc1[C@H]1CCCCC[C@@H]1Oc1cc(F)c(c(F)c1)S(=O)(=O)Nc1cc[nH]cn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccccc3Cl)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3cccc(Cl)c3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccc(Cl)cc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccc(Cl)s3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccccc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)n1cccc(-c2cc(NCc3ccc(Cl)s3)nn2)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(CC#N)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3nnn[nH]3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCCn1cccc(-c2cc(NCc3ccc(Cl)s3)nn2)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(CCc3ccccc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccco3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccoc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3cccc4ccccc34)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccc4ccccc4c3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3cccnn3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccccn3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3cccnc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccncc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ncccn3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3cccs3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(Cc3ccsc3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(CC(=O)N3CCOCC3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(CCN3CCOCC3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1ccc(CNc2cc(nn2)-c2cccn(CCc3ccccn3)c2=O)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1cccc(-c2cc(NCc3ccc(Cl)s3)nn2)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)Cn1cccc(-c2cc(NCc3ccc(Cl)s3)nn2)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)OC(=O)Cn1cccc(-c2cc(NCc3ccc(Cl)s3)nn2)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(Cl)cc1-c1nc(cc1C#N)-c1cc(N)ncn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(Cl)cc1-c1cc(nc1C(N)=O)-c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(Cl)cc1-c1cc(nc1C(N)=O)-c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(cc1-c1cc(nc1C(N)=O)-c1ncnc2[nH]ccc12)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNc1cc(ncn1)-c1cc(C(N)=O)c(n1)-c1cc(Cl)ccc1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(Cl)cc1-c1nc(cc1C(N)=O)-c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(Cl)cc1-c1nc(cc1C(N)=O)-c1nc[nH]c2nccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(Cl)cc1-c1nc(cc1C(N)=O)-c1cc(N)ncn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(Cl)cc1-c1nc(cc1C(N)=O)-c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=O)c1cc(nc1-c1cc(ccc1Cl)C(F)(F)F)-c1cc(N)ncn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNc1cc(ncn1)-c1cc(C(N)=O)c(n1)-c1cc(ccc1Cl)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=O)c1cc(nc1-c1cc(ccc1Cl)C(F)(F)F)-c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(cc1-c1nc(cc1C(N)=O)-c1cc(N)ncn1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNc1cc(ncn1)-c1cc(C(N)=O)c(n1)-c1cc(ccc1C)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(cc1-c1nc(cc1C(N)=O)-c1ncnc2[nH]ccc12)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(cc1-c1nc(cc1C(N)=O)-c1cc(N)ncn1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(cc1-c1nc(cc1C(N)=O)-c1cc(NC)ncn1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1ccc(cc1-c1nc(cc1C(N)=O)-c1ncnc2[nH]ccc12)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1nn(cc1CN1CCn2[nH]nnc2C1c1ccc(F)cc1)-c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1cccc(Cl)c1NC(=O)N1CCN(CC1)c1ccc(cc1)-c1[nH]cnn1CCc1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Clc1cccc(Cl)c1NC(=O)N1CCN(CC1)c1ccc(cc1)-c1ncnn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(cc1)-c1nc([nH]o1)-c1ccc(cc1)N1CCN(CC1)C(=O)Nc1ccccc1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccc(o1)-c1cnc(CCC2=NN3C(N2)C=CC=C3C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=CC=CC2NC(CCc3ncc(n3)-c3ccsc3)=NN12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=CC=CC2NC(CCc3ncc(n3)-c3cccnc3)=NN12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cscc1-c1cnc(CCC2=NN3C(N2)C=CC=C3C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=CC=CN2N=C(CCc3ncc(n3)-c3cccnc3)NC12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1=CC=CN2N=C(CCc3ncc(n3)-c3cncs3)NC12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1=CC=CN2N=C(CCc3ncc(n3)-c3cccnc3)NC12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1=CC=CN2N=C(CCc3ncc(n3)-c3cccs3)NC12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1=CC=CN2N=C(CCc3ncc(n3)-c3ccc(C)o3)NC12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(nc1Cc1ccccc1)C(=O)NCc1ccc(CN)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCc1c(Cc2ccc(Cn3ccccc3=O)cc2)c(C)cc1C(=O)NCc1c(C)cc(CN)cc1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(nn1)-c1cc(C(=O)Nc2ccc(F)cn2)c2ncnn2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H](Nc1nc(nc2nc(C3=C(C)N(C)[N](C)=C3)n(Cc3ccc(cc3)C(F)(F)F)c12)C(O)=O)C1CCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=C(OC(=C1)c1cccc(Nc2nccc(n2)-c2cccnc2)c1)N1CCNC(=O)C11CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ccnc(Nc2cccc(C3=C[N](C)=C(O3)N3CCNC(=O)C33CC3)c2C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2C[N](C)(C)CCc2cc1Nc1ncc(Cl)c(Nc2ccccc2S(=O)(=O)C(C)C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(C)CC(C1)c1ccc(cc1)-c1ccc(c(c1-c1nn[nH]n1)S(N)(=O)=O)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(C)CCC(Cc2ccc(-c3ccc(cc3)C3CNC3)c(-c3nn[nH]n3)c2S(N)(=O)=O)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=[N](C)C=C1c1ccc(C[C@H](NC(=O)[C@H]2N[C@@H]3CC[C@H]2C3)C#N)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1cnc(Cn2cnc(c(Oc3cc(Cl)cc(c3)C#N)c2=O)C(F)(F)F)c[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1(C)CC2C[C@@]3(C[N]23c2cc(nc3c(nccc23)-c2ccn[nH]2)N2CCOCC2)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nc(nc2[nH]nc(N)c12)-c1ccc(NS(=O)(=O)c2csccc2Br)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nc(nc2[nH]nc(N)c12)-c1ccc(NS(=O)(=O)c2csccc2Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OCC(=O)N1C2CCC1CC(C2)Oc1ccc(cc1C#N)C1=NC(Nc2ccc(cc2)N2CCN(CC2)C2COC2)=[N]=CN1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)C(F)(F)F.C[N]1=C(C(NC(=O)c2csc3ncc(N[C@@H]4CCCC[C@@H]4N)nc23)=CN1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC1Nc2ccc(cc2[N]2=NN=NN12)-c1ccc(CNc2ncccc2C(=O)NCc2ccc(F)c(F)c2)s1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](NC(=O)c1nc(cnc1NCc1ccc(cc1)C1=C2N(C=CN=C2N)[N](C)=C1)C#N)c1ccc(F)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CC(=CN1)c1cc(-c2ccc(nc2)N2CCN(CC2)S(=O)(=O)CC2CC2)c2c(cnn2c1)C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)Nc1ccc(C(=O)COC(=O)C2(O)CCC3=C2[N]([O-])=CC(=C3)c2cc(Cl)ccc2NC(=O)OC(C)(C)C)c(F)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)OC(=O)Nc1ccc(Cl)cc1C1=CC2=C([N]([O-])=C1)C(O)(CC2)c1nc(Cl)c([nH]1)-c1ccc(s1)C(=O)OC(C)(C)C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)c1scc(C(=O)COC(=O)C2(O)CCC3=C2[N]([O-])=CC(=C3)c2cc(Cl)ccc2NC(=O)OC(C)(C)C)c1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)Nc1ccc(cc1)-c1cnc(o1)C1(O)CCC2=CC(=C[N](O)=C12)c1c(F)c(Cl)ccc1-n1cnnn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: F[B](F)(F)[C@]1(CC(=C(C(=O)N1)n1nn[nH]c1=O)c1ccc2CCCCc2c1)c1cnn(CCCCCCC(F)(F)F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](NCc1ccc2n(CC3CCCN3[C](=C)=O)c(NC(=O)c3ccc(Cl)cc3)nc2c1)C(C)(C)C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1ncnc2n(nc(C(=O)NC3=[O]c4ccc(cc4N3)-c3ccccc3)c12)[C@@H]1CCN(C1)C(=O)C=C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1ncnc2n(nc(C(=O)NC3=[O]c4ccc(cc4N3)C(F)(F)F)c12)[C@@H]1CCN(C1)C(=O)C=C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)c1ccncc1NC[C@@H]1CCOc2cc(ccc12)-c1ccccc1[B](F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCCCCC(=O)NNC(=O)c1c(O)c2c(Cl)cccc2nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCCCCCCCCC(=O)NNC(=O)c1c(O)c2c(Cl)cccc2nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCCCCCCCCC(=O)NNC(=O)c1c(O)c2c(F)cccc2nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(O)[C@H]1COC(=O)N1c1nc(N[C@@H](C)C2CCN(CC2)c2ccc(Cl)c(c2)C#[F][O](F)F)ncc1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC[N]1=CC=C(N1)n1nnc2CN([C@@H](C)Cc12)C(=O)c1ccnc(c1Cl)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(c1ccccc1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCC(CC)n1c2cc(ccc2c2ncc(cc12)-c1c(C)[nH]oc1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCC(c1ccccc1)n1c2cc(ccc2c2ncc(cc12)-c1c(C)[nH]oc1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(CCC(F)(F)F)CCC(F)(F)F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCC(COC)n1c2cc(ccc2c2ncc(cc12)-c1c(C)[nH]oc1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCC(CCC)n1c2cc(ccc2c2ncc(cc12)-c1c(C)[nH]oc1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](CCC(F)(F)F)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](CCC(F)(F)F)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](C1CC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](C1CCC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](C1CCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCOC(C)(C)C1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](C1CCOC(C)(C)C1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](CCC(F)(F)F)c1cscn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](CCC(F)(F)F)c1cscn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](CCC(F)(F)F)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@H](CCC(F)(F)F)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1o[nH]cc1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1o[nH]cc1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(CCC(F)(F)F)CCC(F)(F)F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](CCC(F)(F)F)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](CCC(F)(F)F)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCCC(CCC)n1c2cc(ccc2c2ncc(cc12)-c1c(C)n[nH]n1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1[nH]ncc1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1[nH]ncc1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccc(F)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1)c1cc(c(F)cc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccc(F)cc1)c1cc(c(F)cc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1)c1c(F)c(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cccc(F)c1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cccc(F)c1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1F)c1c(F)c(ccc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ccccc1F)c1c(F)c(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cc(F)cc(F)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cc(F)cc(F)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cccc(F)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cccc(F)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1c(F)cc(F)cc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1c(F)cc(F)cc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccccc1)c1cc(c(F)cc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1c(F)cc(F)cc1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cc(F)ccc1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cc(F)ccc1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cccc(F)c1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cccc(F)c1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1ccc(F)cc1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccc(F)cc1F)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@H](C1CCOCC1)c1cccc(F)c1)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cccc(F)c1)c1cc(cc(F)c21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1cc(F)ccc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1c(F)cccc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1cccc(F)c1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1cccc(F)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ccccc1F)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1cc(ccc21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1cc(ccc21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ccccc1)c1cc(ccc21)C(C)(C)N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)CC(=O)NC(C)(C)c1ccc2c(c1)n(C(C1CCOCC1)c1ccccc1)c1cc(cnc21)-c1c(C)n[nH]n1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(cc2n(C(C3CCOCC3)c3ncccc3F)c3cc(cnc3c12)-c1c(C)n[nH]n1C)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOc1cc(cc2n(C(C3CCC(F)(F)CC3)c3ccccc3)c3cc(cnc3c12)-c1c(C)n[nH]n1C)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ncccc1F)c1cc(cc(F)c21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1c(ccc(F)c21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ncccc1F)c1cc(ccc21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1c(ccc(OCC(F)F)c21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1c(ccc(OCC(C)(F)F)c21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cc1)C(C1CCOCC1)n1c2cc(ccc2c2ncc(cc12)-c1c(C)n[nH]n1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(CCC(F)(F)F)c1ccccn1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)S(C)(=N)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]oc(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)C(O)C[N+]#[C-] convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(CC1CC1)C1CCOCC1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCC(C1CCOCC1)n1c2cc(ccc2c2ncc(cc12)-c1c(C)[nH]nn1C)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ccc(Cl)cc1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1cccc(Cl)c1)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ccccc1Cl)c1cc(ccc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)[C@](C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)[C@@](C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1F)c1c(F)c(ccc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1F)c1c(F)c(ccc21)[C@@](C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(c(F)cc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1F)c1cc(c(F)cc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(c(F)cc21)C(C)(O)C1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1N=[F]C(C)=C1c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1cc(c(F)cc21)C(C)(C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=C(CN2C3CC2CN(C3)c2ccc(cn2)-c2cc(OCC(C)(C)O)cn3ncc(C#N)c23)[N](C)=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)N1CCC(C1)OC1=CC(=C=[N]=C1)n1cc(cn1)-c1cc(ccc1C)C(=O)NC1CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H]1CN(Cc2cc(ccc2C)C(CC(O)=O)C2=CC3N=N[N](C)=C3C=C2)S(=O)(=O)c2ccccc2O1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(N)nc(C)c1CNC(=O)c1ccc2C3OC(c4cc(C[N]5(O)CCOCC5)ccc34)c2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(N)nc(C)c1CNC(=O)c1ccc2[C@H]3O[C@@H](c2c1)c1cc(ccc31)C1=CC=CC=[N]1O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(N)nc(C)c1CNC(=O)c1ccc2[C@H]3O[C@@H](c2c1)c1cc(ccc31)C1=[N](O)C=C(F)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1cc(N)nc(C)c1CNC(=O)c1ccc2[C@H]3O[C@@H](c2c1)c1cc(ccc31)C1=C(F)C=[N](O)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nc(N)cc(C2CC2)c1CNC(=O)c1ccc2[C@H]3O[C@@H](c2c1)c1cc(ccc31)C1=C(F)C=[N](O)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1cc(N)nc(C)c1CNC(=O)c1ccc2[C@H]3O[C@@H](c2c1)c1cc(ccc31)C1=C(F)C=CC=[N]1O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)N[C@@H](CC1=CNC=[N]1C)C(=O)Nc1cccc(n1)-c1ccc(Oc2ccc(F)cc2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)[N]1(O)CCC(CC1)c1ccc(Nc2nc(cnc2C(N)=O)N2CCC[C@H](C2)NC(=O)N(C)C)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(O)(CS(=O)(=O)c1ccc(F)cc1)[c](=O):c:n-c1ccc(C#N)c(c1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(C1CCS(=O)CC1)c1cc(cc(C(=O)NCc2c(C)cc(C)nc2=O)c1C)-c1ccc(C[N+]2([O-])CCOCC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1ccc(C[N]2=CC(C=N2)c2cccc(c2)C(F)(F)F)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(C[N]2=CC(C=N2)c2ccc(cc2)C(F)(F)F)n(C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H](Oc1nc(cc2nn(C)c(C)c12)C1=CN[N](=C1)C(C)(C)C)[C@H]1CNC(=O)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=O)C1=[N](NC=C1NC(=O)c1cnn2ccc(nc12)N1CCNCC1)c1ccncc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CSC1=N[N]2=C(C=CC2C=N1)C(=O)Nc1cn(C)nc1C(N)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCc1ccc(NC(=O)C2=[N](OC[C@@H]3CCCO3)N(c3ncnc(N)c23)C2(C)CC2)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(\\C=C\\c1cnc2NC(=O)CCc2c1)N1C[C@H]2C[N](=C[C@H]2C1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(\\C=C\\c1cnc2NC(=O)CCc2c1)N1C[C@@H]2C[N](=C[C@@H]2C1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O=C(\\C=C\\c1cnc2NC(=O)CCc2c1)N1C[C@H]2C[N](=C[C@H]2C1)c1ccncc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](c1ccccc1)[N]1=Cc2cc3c(n[nH]c3cc2NC1=O)-c1ccnc(C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ncccc1-c1n[nH]c2C(N(C(=O)c12)C1=CC2C(=NN=[N]2C)C(C)=C1)c1ccc(Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CC2C=CC(COc3ccnn3-c3cc(ccn3)C(O)=O)=CC2=N1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nnn(C)c1-c1ccc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1cc(cnc21)-c1c(C)[nH]nn1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1N=N[N](C)=C1c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1cc(ccc21)-c1c(C)nnn1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1c(ccc(N3CCCS3(=O)=O)c21)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)C1(C)COC(=O)N1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n([C@@H](C1CCOCC1)c1ccccc1)c1c(F)c(ccc21)C1(O)CCOC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1cc(ccc21)N1CCC(F)(F)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1cc(ccc21)N1CCS(=O)(=O)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCOCC1)c1ncccc1F)c1cc(ccc21)N1CCC(CC1)S(C)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1[nH]nn(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1c(C)ccc(N3CCC(F)(F)CC3)c21 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1cc(ccc21)N1CCC(F)(F)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1n[nH]n(C)c1-c1cnc2c(c1)n(C(C1CCC(F)(F)CC1)c1ccccc1)c1cc(ccc21)N1CCC(CC1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CC(=CN1)c1cc(-c2ccc(nc2)N2CCOCC2)c2c(cnn2c1)C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCn1c(nc2C(N3CCOCC3)[N](C)(C=Nc12)c1cn[nH]c1)C1CC(CCN1C=O)N1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C(C2CN(CCC2N2CCOCC2)C=O)[N](C)(c2cn[nH]c2)c2c1nccc2N1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C(C2CN(CCC22COC2)C=O)[N](C)(c2cn[nH]c2)c2c1ncc(F)c2N1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C(C2CN(CCC2N2CCOCC2)C=O)[N](C)(c2cn[nH]c2)c2c1ncc(F)c2N1CCOCC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C(=O)Nc1ccc(cc1)C1=N[N](=NN1)C(F)(F)F)n1ccc(cc1=O)-c1cc(Cl)ccc1C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC[N]1=NNC(=N1)c1ccc(NC(=O)C(C)n2ccc(cc2=O)-c2cc(Cl)ccc2C#N)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H]1CCC[C@@H]1n1cc(cn1)-c1nc(cn2nccc12)C1=CN[N](C[C@@H](O)CO)=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(NC(C)=O)cc1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc2OCCOc2c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)S(C)(=O)=O)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc2OCOc2c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)C(N)=O)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(NC(C)=O)c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)C#N)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cc1OC)-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)N(C)C)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(F)c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(C)c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(CO)cc1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(Cl)c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(C)cc1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccccc1-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)C(C)(C)C)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(C)c(CNC(=O)c2cc(nc3n(ncc23)C(C)(C)C)-c2ccc3OCCOc3c2)c(=O)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOc1ccc(cc1)-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccccc1Cl)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccccc1C)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cccc(c1)-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(cc1)C(C)=O)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cc1)-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(c1)C(C)=O)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)Oc1ccc(cc1)-c1cc(C(=O)NCc2c(C)cc(C)nc2=O)c2cnn(C(C)C)c2n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(c1)N(C)C)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1cccc(CO)c1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)n1ncc2c(cc(nc12)-c1ccc(F)cc1)C(=O)NCc1c(C)cc(C)nc1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(O)c1cc(O[C@H]2CC[C@H](CC2)N2C[N](CC#N)(C2)n2cc(cn2)-c2ncnc3[nH]ccc23)nc(c1)C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(OC)cc(c1)C(\\O)=C1\\CC=c2ncc(cc2=[N]1CCO)-c1cnn(C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)c1cn(-c2ccc(N3CCNC3=O)c(F)c2)c(=O)n(Cc2cccc(c2C)N([O-])=O)c1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1c(Cn2c(=O)c(cn(-c3ccc(N4CCNC4=O)c(F)c3)c2=O)C(O)=O)cccc1N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1c(Cn2c(=O)c(cn(-c3ccc(cc3)N3CCOC3=O)c2=O)C(O)=O)cccc1N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(Nc1nc(C)nc(N)c1C#N)C1=Nc2cccc(Cl)c2C(=O)[N@@]1(c1ccccc1)c1cc(F)cc(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(Nc1nc(N)nc(Cl)c1C#N)C1=Nc2cccc(Cl)c2C(=O)[N@@]1(c1ccccc1)c1cc(F)cc(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](NC(=O)c1c[nH]cc2cccnc12)c1cc2cccc(C#Cc3cnn(C)c3)c2c(=O)n1-c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1c[nH]c(C(=O)N[C@@H](C)c2cc3cccc(C#Cc4cnn(C)c4)c3c(=O)n2-c2ccccc2)c(N)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nnc2ccc3n(Cc4cccc(Cl)c4)c(cc3n12)C1=CC=[N](N1)C1CNC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1nnc2ccc3n(Cc4cccc(Cl)c4)c(cc3n12)C1=CC=[N](N1)C1(CC#N)CNC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H]1CC(=O)Nc2cccc(C3=[N](C)c4ccccc4C3)c2O1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(F)cc(C)c1C(=O)c1sc2cc([Na]O)ccc2c1-c1ccc(OCCN2CC(C2)C(=O)O[Na])cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNC1=NC(c2ccccc2)=[N](S1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C(NC1=NC(c2ccccc2)=[N](S1)c1ccccc1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: N(C1=NC(c2ccccc2)=[N](S1)c1ccccc1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(Nc2ncc(c(Nc3cc(F)c(C)cc3NC(=O)C=C)n2)C(F)(F)F)c(C)c[nH]1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC1=CC=[N](C=C1)c1nc(COc2cc3ncnc(Nc4ccc(Cl)c(Cl)c4)c3cc2OC)no1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2c(Nc3ccc(Cl)c(Cl)c3)ncnc2cc1OCC1=N[N](CS(=O)(=O)c2ccccn2)=CO1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1C=NC=[N]1c1ccccc1NC(=O)[C@@H]1C[C@@H](F)CN1C(=O)Cn1nc(C(N)=O)c2cc(ccc12)-c1ccnnc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(cc(OC)c1OC)-c1cnc2ncc(-c3ccc4[nH]ccc4c3)c2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(CCNCC1)S(=O)(=O)Nc1cccc(c1)-c1ccc(cc1)[C@H]1C[C@@H]1NC1CCC(N)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(C)CC[C@H](C1)NS(=O)(=O)c1ccc(-c2cccc3[nH]c(N)nc23)c(-c2nn[nH]n2)c1S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(C)CC(C1)NS(=O)(=O)c1ccc(-c2cccc3[nH]c(N)nc23)c(-c2nn[nH]n2)c1S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(CCN)CC[C@@H](C1)NS(=O)(=O)c1ccc(-c2cccc3[nH]c(N)nc23)c(-c2nn[nH]n2)c1S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1nn2cc(nc2s1)-c1cc2ccc(cc2o1)N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(=O)C1CCC(CC1)Oc1cc(CNC(=O)c2cccn(Cc3ccc(F)c(F)c3)c2=O)cc(c1)-c1c[nH]c2ncccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(CC#N)[N]1=NN=NC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: N[C@@H](CC#C)[N]1=NN=NC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CC(Nc2nccc(n2)-c2ccc3C(CCCCc3c2)NC(=O)c2nnc(s2)C(C)(C)C)=CN1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(CCOc2ccc(CC(=O)NS(C)(=O)=O)cc2)CC(CN[C@@H]2C[C@H]2c2ccccc2)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(CCOc2ccc(cc2)C(=O)NS(C)(=O)=O)CC(CN[C@@H]2C[C@H]2c2ccccc2)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)[C@@H](NC(=O)c1cc(ccc1F)C(F)(F)F)C(=O)N1CCC2(CC1)N(C(=O)N(C)C2=O)C1=CC=[N](O)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(Cn2c3ccc(cc3c(=O)n(Cc3cnc(C)n3)c2=O)S(=O)(=O)NC2(C)CC2)n(C)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(Cn2c(=O)n(C)c3ccc(cc3c2=O)S(=O)(=O)NC2(C)CC2)nn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN[N]1=CN(Cc2cc(C)no2)C(=O)c2cc(ccc12)S(=O)(=O)NC1(C)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)OC[N]1=CN(Cc2cnn(C)c2)C(=O)c2cc(ccc12)S(=O)(=O)NC1(C)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(CN2C=[N](C(O)=O)c3ccc(cc3C2=O)S(=O)(=O)NC2(C)CC2)on1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(Cn2c3ccc(cc3c(=O)n(Cc3cnn(C)c3)c2=O)S(=O)(=O)NC2(CF)CC2)nn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1ncc(Cn2c3ccc(cc3c(=O)n(Cc3cnn(C)c3)c2=O)S(=O)(=O)NC2(CF)CC2)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1cc(Cn2c(=O)n(Cc3ncnn3)c3ccc(cc3c2=O)S(=O)(=O)NC2(CF)CC2)cn1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1c2ncccc2OC[C@H](NC(=O)C2=N[N](Cc3cc(F)cc(c3)C#N)=C=C2F)C1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)CCCCCN1C(=O)N\\C(=C/C2=C(NCc3ccco3)N=C3C=CC=C[N]3=[C]2=O)C1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)[H]c1cccc(CN2CC[C@H](Oc3cc(F)c(cc3Cl)S(=O)(=O)Nc3cscn3)[C@H](F)C2)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOC(=O)N1CCN(CC1)c1ccc(NC(=O)CC2=C[O]=C(C(C)=C2)c2ccnc(C)c2)nc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)[F]c1cc(Oc2cccc(F)c2)nc(n1)N1CCC2(CC1)CNC(=O)CO2 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)[F]c1cc(Oc2cccc(F)c2)nc(n1)N1CCC2(CC1)COCCN2 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)N1CCn2c(C1)c[nH]c2-c1cccc(CNC(=O)c2ccc-3c(OCc4cnccc-34)c2)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)C(=O)C[N]1=CNc2c1ccc(c2Oc1ccc(F)cc1F)-c1cn(C)c(=O)c2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=CC=[N](C=C1)c1ccc(cc1)-c1nc2c(ncnc2[nH]1)-c1ccc(OC2CCOCC2)c(c1)C#N convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(=O)N1CC(C1)n1ncc2c(cc(Br)cc12)C(=O)NCC1=[C](=O)C=C(C)NC1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)C12CCC(CC1)(CC2)C(=O)N1CCC2(C1CCc1cc(C=[F]C(F)(F)F)ccc21)S(=O)(=O)c1ccc(F)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)C1CC2(C1)CC(C2)C(=O)[N]12CCCCC1(c1ccc(cc1OC2)C(F)(C(F)(F)F)C(F)(F)F)S(=O)(=O)c1ccc(F)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(=O)[C@H]1CC[C@@H](CC1)C(=O)N1CCC2(C1CCc1cc(C=[F]C(F)(F)F)ccc21)S(=O)(=O)c1ccc(Cl)cc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN(C)[C](=O)(=O)c1ccc(Cl)c(c1)-c1cccc(NC(=O)[C@@H]2C[C@@H](F)CN2C(=O)Cn2nc(C(C)=O)c3cc(ccc23)-c2cnc(C)nc2)c1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: N#CC1=CC=[N](C=C1)c1ccnc2ncnn12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[Na]1CCC(CC1)OC(=O)Nc1cc(-c2ccc(C#N)c(F)c2)n2ncnc2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1oc2=C[F]=C(F)C=c2c1Nc1ccccc1Cl convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@@H]1CN(CCN1C(=O)Cn1cnc2cccnc12)c1cccc2CCN(Cc12)[C]1(=O)=CC=CC=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)NS(=O)(=O)c1ccc(-c2sc(nc2Cc2ccccc2)C(=O)[K]O)c2ccccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)C(=O)N1CCC(CC1)c1cc(-c2ccc(NC(=O)C3=CC(=N[N](c4ccccc4)=[C]3=O)C3CC3)cc2)c2c(N)ncnn12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[C@@]1(CCN(C1=O)c1cccc(c1)[N](=O)(=O)N1CCNCC1)C(=O)NCc1cc(F)cc(Cl)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)[N]1=CC(NC(=O)c2cnn3ccc(N[C@@H]4CCCC[C@@H]4O)nc23)=C(N1)C(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)(C)[N]1=CC(NC(=O)c2cnn3ccc(N[C@@H]4CCCC(F)(F)[C@@H]4N)nc23)=C(N1)C(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)Oc1cc2c(OCC3CCOC3)nccc2cc1[C](=N)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2c(OC[C@@H]3C[N@@](F)(CC(F)(F)F)C(=O)N3)cccc2cc1C(N)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc2c(OC[C@@H]3C[N@](F)(CC(F)(F)F)C(=O)N3)cccc2cc1C(N)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=N[N](=CN1)c1cc(Cl)c(C(=O)NC2(CO)CCc3nn4cc(C)ccc4c3C2)c(Cl)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=[C](=O)C=CC(Nc2cc(ncc2C(=O)NC[C@@H](F)C(C)(C)O)-c2ccc3cc(cnn23)C#N)=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1=[C](=O)C=C(Nc2cc(ncc2C(=O)NC[C@@H](F)C(C)(C)O)-c2ccc3cc(cnn23)C#N)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)[N]1=CC(C=N1)C1CC(C1)N1CCN(C1=O)c1cccc(n1)-c1nncn1C(C)C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CNS(=O)(=O)C[C@H]1CCC(CC1)N(C)c1c(cnc2[nH]ccc12)N([O-])=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COC(=O)NC[C@H]1CC[C@@H](CC1)N1C(=N[N]2=CN=c3ccsc3=C12)[C@@H](C)O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)[H]c1ccc(nc1)C(F)(F)CN1CCC(CC1)Nc1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[F]c1ccc(nc1)C(F)(F)CN1CCC(CC1)Nc1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: FC(F)[H]c1ccc(cc1)C(F)(F)CN1CCC(CC1)Nc1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1(C)Cc2[nH]c(c(Nc3ccc(cc3)N([O-])=O)c2C(=O)C1)-c1ccncc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H]1CN(C[C@@H](C)N1C(=O)[H]C(F)F)S(=O)(=O)N(Cc1ccc(cc1)-c1nnc(o1)C(F)F)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1[O]=C(CC(OC[C@H]2O[C@H]([C@@H](F)[C@@H]2O)n2cnc3c(N)nc(Cl)nc23)(C(O)=O)C(O)=O)C=C1C(O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[C@H](CNC(=O)c1cccc([H]C(F)F)c1)[C@@H]1Cc2ccccc2CN1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: O[C@H](CNC(=O)c1ccc(cc1)C(=O)N1CCC(O)([H]C(F)F)CC1)[C@@H]1Cc2ccccc2CN1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cc1cc(ncc1C#N)[N]1=NCC(CN2CCN[C@@H](C2)c2ccc3C(=O)OCc3c2C)=N1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCOc1ncccc1-c1cc(NCC2=CC(CF)=[O]N2)c2n(nc(C)c2n1)C(C)C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NCC1(Cc2ccccc2C1)[N]1=[C](=O)C=CC(=C1)c1ncnc2[nH]ccc12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1ccc(cc1F)-c1c(nc(NC2CCNCC2)n(C)c1=O)-c1ccc(cc1)C#[N]C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[F]c1cc(ccn1)-c1ccc(OC[C@@](C)(N)CC(C)C)c(n1)C(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[N]1(CCN)CC[C@H](C1)NS(=O)(=O)c1ccc(-c2cccc3[nH]c(N)nc23)c(-c2nn[nH]n2)c1S(N)(=O)=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: NC(=O)c1csc(Nc2cccc(c2)-c2ccc(c(c2-c2nn[nH]n2)S(N)(=O)=O)[S](=O)(=O)=N[C@@H]2CCNC2)n1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(cn2ncnc12)-c1[nH]c2ccc(nc2c1C(C)C)N1CCN(CC[N](C)(=O)=O)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1c([nH]c2ccc(nc12)N1CC[N]2(CCCC[C@H]2C1)C(=O)CN(C)C)-c1cn2ncnc2c(C)c1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1c([nH]c2ccc(nc12)N1CC[N]2(CCS(C)(=O)=O)CCCC[C@H]2C1)-c1cn2ncnc2c(C)c1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Cn1c(nc(-c2ccc(C#N)c(F)c2)c(-c2ccc3C(=[F])NCc3c2)c1=O)N1CCC(N)CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: ONC(=O)c1cccc(Nc2nc3cc(Cl)c(cc3[nH]2)N([O-])=O)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[O]1CCC(CC1)Nc1nc(Nc2cc(C)ns2)nc2ccn(-c3cnn(C)c3)c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)Nc1nc(Nc2cc(C)ns2)nc2ccn(C3=CC=[N]4OCOC4=C3)c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)Nc1nc(Nc2cc(C)nn2)nc2ccn(-c3cnn(c3)C3CCOCC3)c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[O](C)c1ccc(cc1)-n1ccc2nc(Nc3cc(C)ns3)nc(OC3CCOCC3)c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)N1C(=O)C(CNC(=O)[C@@H]2CCCN2S(=O)(=O)c2cc3cnccc3o2)=CC(c2ccc(cc2)C(F)(F)F)=[C]1=O convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[C@H](NC1=C(C#N)C(N)=[N](O)C=N1)c1cc2ncc(Cl)n2nc1-c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C\\[O]=C(/C=C(C)C)c1cccc(Nc2nc(Nc3cccc(OC(F)(F)F)c3)ncc2F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C\\[O]=C(/C=C(C)C)c1cccc(Nc2nc(Nc3cccc(c3)S(N)(=O)=O)ncc2C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C(N1CCN(CC1)c1ccc2nc(oc2c1)C1=Nc2ccccc2[Na]1)c1ccccc1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CN1CCN(Cc2cc(Cl)c(O[C@H]3CCc4c3cccc4-c3ccccc3F)cc2OCc2cncc(c2)C#[F])CC1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Nc1nccc2[C@@H](CCc12)NC(=O)C1=CN(Cc2ccc(CN3CC4CCCN4C3=O)cc2)N=[N]1C(F)(F)F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COCCN1C[C@@H](NC(=O)Nc2c(C)c(nn2-c2ccccc2)-c2cnc3c(CN(C)N3=O)c2)[C@@H](O1)c1cnc(F)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN1C[C@@H](NC(=O)Nc2c(C)c(nn2-c2ccccc2)C2=C[N](C)=[C](=O)C=C2)[C@@H](O1)c1ccc(F)c(F)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1C[C@H](NC(=O)[C@H](Cc2ccncc2)NC(=O)[C@H](CCc2ccccc2)NC(=O)c2cc(CN3CCOCC3)on2)C(=O)[C]2(C)(CO2)C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: OC(CCNC(=O)c1ccc(O[H]C(F)F)cc1)CN1CCc2ccccc2C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C[F]CN(C)CC(=O)N1CCC(CC1)c1ccc2[nH]c(c(C(C)C)c2c1)-c1cc(C)nc(C)c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1c([nH]c2ccc(cc12)C1CCN(CC2=C[N](C)=NN2)CC1)-c1cc(C)ncc1C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)c1c([nH]c2ccc(cc12)C1CCN(CC2=C[N](C)=NN2)CC1)-c1cc(C)ncc1F convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC1=C(C=[N]([O-])C=C1)c1ccc2nc(NC(=O)[C@@H]3C[C@@H]3F)sc2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CCN(CN(=O)CC(=O)N[C@@H](Cc1ccc(C)cc1C)B(O)O)S(=O)(=O)C=C convert to all 0 features\n",
      "rdkit not found this smiles for morgan: C1C=[O]C=C1c1ccnc2[nH]nc(-c3ccccc3)c12 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: COc1cc(Nc2ccc3ncc(nc3c2C#N)N2CCOCC2)ccc1OCC1=C[N](O)=C(C)C=C1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[B]1234[B]567[B]89%10[B]%11%12%13[B]585[B]%118%11[B]%12%12%14[B]9%139[B]16%10[C]2%129[C]38%14[B]475%11 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[B]1234[B]567[B]89%10[B]%11%12%13[B]%14%15%16[B]%11%11%17[B]8%128[B]159[C]2%118[B]3%14%17[B]46%15[C]7%10%13%16 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[B]1234[B]567[B]89%10[B]55%11[B]88%12[B]%13%14%15[B]11([B]269[C]%108%131)[B]3%141[B]475[C]%11%12%151 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[C]1234[B]567[B]89%10[B]55%11[B]%12%13%14[B]%15%16%17[B]88([B]169[B]2%158[B]3%12%16[B]475%13)[C]%10%11%14%17 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[B]1234[B]567[B]89%10[B]55%11[B]161[B]556[B]211[B]323[B]478[B]922[C]%10%115[C]6132 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[B]1234[B]567[B]89%10[B]%11%12%13[B]585[B]%118%11[B]%12%12%14[B]9%139[B]16%10[C]2%129[B]38%14[C]475%11 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[C]1234[B]567[B]89%10[B]55%11[B]88%12[B]99%13[B]16%10[B]291[B]323[B]58([B]47%112)[C]%12%1313 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: Oc1ccc(cc1)[C]1234[B]567[B]89%10[B]%11%12%13[B]585[B]%118%11[B]%12%12%14[B]9%139[B]16%10[B]2%129[C]38%14[B]475%11 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: c1ccc2nnnc2c1 convert to all 0 features\n",
      "rdkit not found this smiles for morgan: CC(C)C[C@H](NC(=O)[C@H](CC[C]1234B5B6B5[B--]115[B--]789B%10B%11B%10[C]217[B--]38%11[B--]4659)NC(=O)CNC(=O)[C@H](C)NC(=O)[C@@H](N)Cc1ccc(O)cc1)C(N)=O convert to all 0 features\n",
      "encoding protein...\n",
      "unique target sequence: 5789\n",
      "-- Encoding AAC takes time. Time Reference: 24s for ~100 sequences in a CPU.\t\t\t\t Calculate your time by the unique target sequence #, instead of the entire dataset.\n",
      "splitting dataset...\n",
      "Done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xQsMy41Msb5y"
   },
   "source": [
    "config = generate_config(drug_encoding, \n",
    "                         target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 30, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1-hpmpxlthwL"
   },
   "source": [
    "net = models.model_initialize(**config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z85hyl-vtkHG",
    "outputId": "e3147093-9d23-499a-c5c9-d058b56db6e4"
   },
   "source": [
    "net.train(train, val, test)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 0.70376. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.50161. Total time 0.00805 hours\n",
      "Training at Epoch 1 iteration 200 with loss 0.46846. Total time 0.01638 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.44609. Total time 0.02444 hours\n",
      "Training at Epoch 1 iteration 400 with loss 0.43659. Total time 0.0325 hours\n",
      "Training at Epoch 1 iteration 500 with loss 0.38783. Total time 0.04083 hours\n",
      "Training at Epoch 1 iteration 600 with loss 0.46036. Total time 0.04916 hours\n",
      "Training at Epoch 1 iteration 700 with loss 0.39047. Total time 0.05722 hours\n",
      "Training at Epoch 1 iteration 800 with loss 0.41074. Total time 0.06527 hours\n",
      "Training at Epoch 1 iteration 900 with loss 0.35109. Total time 0.07361 hours\n",
      "Training at Epoch 1 iteration 1000 with loss 0.37992. Total time 0.08166 hours\n",
      "Training at Epoch 1 iteration 1100 with loss 0.35616. Total time 0.09 hours\n",
      "Training at Epoch 1 iteration 1200 with loss 0.33646. Total time 0.09805 hours\n",
      "Training at Epoch 1 iteration 1300 with loss 0.35812. Total time 0.10611 hours\n",
      "Training at Epoch 1 iteration 1400 with loss 0.29186. Total time 0.11444 hours\n",
      "Training at Epoch 1 iteration 1500 with loss 0.38580. Total time 0.1225 hours\n",
      "Training at Epoch 1 iteration 1600 with loss 0.33721. Total time 0.13083 hours\n",
      "Training at Epoch 1 iteration 1700 with loss 0.33560. Total time 0.13888 hours\n",
      "Training at Epoch 1 iteration 1800 with loss 0.31152. Total time 0.14694 hours\n",
      "Training at Epoch 1 iteration 1900 with loss 0.37535. Total time 0.155 hours\n",
      "Training at Epoch 1 iteration 2000 with loss 0.37490. Total time 0.16305 hours\n",
      "Training at Epoch 1 iteration 2100 with loss 0.32051. Total time 0.17111 hours\n",
      "Training at Epoch 1 iteration 2200 with loss 0.37727. Total time 0.17916 hours\n",
      "Training at Epoch 1 iteration 2300 with loss 0.36749. Total time 0.18722 hours\n",
      "Training at Epoch 1 iteration 2400 with loss 0.29917. Total time 0.19527 hours\n",
      "Training at Epoch 1 iteration 2500 with loss 0.29452. Total time 0.20333 hours\n",
      "Training at Epoch 1 iteration 2600 with loss 0.26623. Total time 0.21138 hours\n",
      "Training at Epoch 1 iteration 2700 with loss 0.31900. Total time 0.21972 hours\n",
      "Training at Epoch 1 iteration 2800 with loss 0.42515. Total time 0.22777 hours\n",
      "Training at Epoch 1 iteration 2900 with loss 0.32219. Total time 0.23583 hours\n",
      "Training at Epoch 1 iteration 3000 with loss 0.32078. Total time 0.24388 hours\n",
      "Training at Epoch 1 iteration 3100 with loss 0.30701. Total time 0.25194 hours\n",
      "Training at Epoch 1 iteration 3200 with loss 0.33602. Total time 0.26 hours\n",
      "Training at Epoch 1 iteration 3300 with loss 0.32520. Total time 0.26805 hours\n",
      "Training at Epoch 1 iteration 3400 with loss 0.33747. Total time 0.27611 hours\n",
      "Training at Epoch 1 iteration 3500 with loss 0.32976. Total time 0.28416 hours\n",
      "Validation at Epoch 1, AUROC: 0.90702 , AUPRC: 0.78100 , F1: 0.68531 , Cross-entropy Loss: 4.93792\n",
      "Training at Epoch 2 iteration 0 with loss 0.28334. Total time 0.33222 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.29702. Total time 0.34 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.26689. Total time 0.34805 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.26689. Total time 0.35583 hours\n",
      "Training at Epoch 2 iteration 400 with loss 0.32700. Total time 0.36388 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.28215. Total time 0.37166 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.31758. Total time 0.37972 hours\n",
      "Training at Epoch 2 iteration 700 with loss 0.26200. Total time 0.3875 hours\n",
      "Training at Epoch 2 iteration 800 with loss 0.33023. Total time 0.39555 hours\n",
      "Training at Epoch 2 iteration 900 with loss 0.36768. Total time 0.40333 hours\n",
      "Training at Epoch 2 iteration 1000 with loss 0.26080. Total time 0.41111 hours\n",
      "Training at Epoch 2 iteration 1100 with loss 0.31793. Total time 0.41916 hours\n",
      "Training at Epoch 2 iteration 1200 with loss 0.29703. Total time 0.42694 hours\n",
      "Training at Epoch 2 iteration 1300 with loss 0.29136. Total time 0.435 hours\n",
      "Training at Epoch 2 iteration 1400 with loss 0.29270. Total time 0.44277 hours\n",
      "Training at Epoch 2 iteration 1500 with loss 0.33824. Total time 0.45083 hours\n",
      "Training at Epoch 2 iteration 1600 with loss 0.26321. Total time 0.45861 hours\n",
      "Training at Epoch 2 iteration 1700 with loss 0.29229. Total time 0.46638 hours\n",
      "Training at Epoch 2 iteration 1800 with loss 0.31546. Total time 0.47444 hours\n",
      "Training at Epoch 2 iteration 1900 with loss 0.28126. Total time 0.48222 hours\n",
      "Training at Epoch 2 iteration 2000 with loss 0.30826. Total time 0.49 hours\n",
      "Training at Epoch 2 iteration 2100 with loss 0.28531. Total time 0.49777 hours\n",
      "Training at Epoch 2 iteration 2200 with loss 0.26458. Total time 0.50555 hours\n",
      "Training at Epoch 2 iteration 2300 with loss 0.34725. Total time 0.51361 hours\n",
      "Training at Epoch 2 iteration 2400 with loss 0.27736. Total time 0.52138 hours\n",
      "Training at Epoch 2 iteration 2500 with loss 0.27484. Total time 0.52916 hours\n",
      "Training at Epoch 2 iteration 2600 with loss 0.28926. Total time 0.53722 hours\n",
      "Training at Epoch 2 iteration 2700 with loss 0.32792. Total time 0.545 hours\n",
      "Training at Epoch 2 iteration 2800 with loss 0.24939. Total time 0.55277 hours\n",
      "Training at Epoch 2 iteration 2900 with loss 0.34088. Total time 0.56055 hours\n",
      "Training at Epoch 2 iteration 3000 with loss 0.28858. Total time 0.56861 hours\n",
      "Training at Epoch 2 iteration 3100 with loss 0.23430. Total time 0.57638 hours\n",
      "Training at Epoch 2 iteration 3200 with loss 0.26611. Total time 0.58416 hours\n",
      "Training at Epoch 2 iteration 3300 with loss 0.29551. Total time 0.59194 hours\n",
      "Training at Epoch 2 iteration 3400 with loss 0.33698. Total time 0.59972 hours\n",
      "Training at Epoch 2 iteration 3500 with loss 0.28599. Total time 0.60777 hours\n",
      "Validation at Epoch 2, AUROC: 0.92330 , AUPRC: 0.81456 , F1: 0.72303 , Cross-entropy Loss: 4.46835\n",
      "Training at Epoch 3 iteration 0 with loss 0.25757. Total time 0.655 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.18933. Total time 0.66277 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.25348. Total time 0.67083 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.25533. Total time 0.67861 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.26260. Total time 0.68638 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.22901. Total time 0.69416 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.23529. Total time 0.70194 hours\n",
      "Training at Epoch 3 iteration 700 with loss 0.20742. Total time 0.71 hours\n",
      "Training at Epoch 3 iteration 800 with loss 0.28587. Total time 0.71777 hours\n",
      "Training at Epoch 3 iteration 900 with loss 0.23436. Total time 0.72555 hours\n",
      "Training at Epoch 3 iteration 1000 with loss 0.30932. Total time 0.73333 hours\n",
      "Training at Epoch 3 iteration 1100 with loss 0.21434. Total time 0.74138 hours\n",
      "Training at Epoch 3 iteration 1200 with loss 0.19699. Total time 0.74916 hours\n",
      "Training at Epoch 3 iteration 1300 with loss 0.24750. Total time 0.75694 hours\n",
      "Training at Epoch 3 iteration 1400 with loss 0.22125. Total time 0.76472 hours\n",
      "Training at Epoch 3 iteration 1500 with loss 0.24804. Total time 0.7725 hours\n",
      "Training at Epoch 3 iteration 1600 with loss 0.31506. Total time 0.78027 hours\n",
      "Training at Epoch 3 iteration 1700 with loss 0.26169. Total time 0.78833 hours\n",
      "Training at Epoch 3 iteration 1800 with loss 0.18774. Total time 0.79611 hours\n",
      "Training at Epoch 3 iteration 1900 with loss 0.29653. Total time 0.80388 hours\n",
      "Training at Epoch 3 iteration 2000 with loss 0.27115. Total time 0.81166 hours\n",
      "Training at Epoch 3 iteration 2100 with loss 0.18429. Total time 0.81944 hours\n",
      "Training at Epoch 3 iteration 2200 with loss 0.31157. Total time 0.8275 hours\n",
      "Training at Epoch 3 iteration 2300 with loss 0.24423. Total time 0.83527 hours\n",
      "Training at Epoch 3 iteration 2400 with loss 0.33719. Total time 0.84305 hours\n",
      "Training at Epoch 3 iteration 2500 with loss 0.24597. Total time 0.85083 hours\n",
      "Training at Epoch 3 iteration 2600 with loss 0.26358. Total time 0.85888 hours\n",
      "Training at Epoch 3 iteration 2700 with loss 0.31896. Total time 0.86666 hours\n",
      "Training at Epoch 3 iteration 2800 with loss 0.21202. Total time 0.87444 hours\n",
      "Training at Epoch 3 iteration 2900 with loss 0.23912. Total time 0.8825 hours\n",
      "Training at Epoch 3 iteration 3000 with loss 0.21387. Total time 0.89027 hours\n",
      "Training at Epoch 3 iteration 3100 with loss 0.22272. Total time 0.89833 hours\n",
      "Training at Epoch 3 iteration 3200 with loss 0.21731. Total time 0.90611 hours\n",
      "Training at Epoch 3 iteration 3300 with loss 0.25982. Total time 0.91388 hours\n",
      "Training at Epoch 3 iteration 3400 with loss 0.25611. Total time 0.92166 hours\n",
      "Training at Epoch 3 iteration 3500 with loss 0.23321. Total time 0.92944 hours\n",
      "Validation at Epoch 3, AUROC: 0.93058 , AUPRC: 0.83149 , F1: 0.73796 , Cross-entropy Loss: 4.30822\n",
      "Training at Epoch 4 iteration 0 with loss 0.20227. Total time 0.97694 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.21282. Total time 0.98472 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.20433. Total time 0.9925 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.18921. Total time 1.00027 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.22232. Total time 1.00833 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.22995. Total time 1.01611 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.21090. Total time 1.02388 hours\n",
      "Training at Epoch 4 iteration 700 with loss 0.22157. Total time 1.03166 hours\n",
      "Training at Epoch 4 iteration 800 with loss 0.19558. Total time 1.03944 hours\n",
      "Training at Epoch 4 iteration 900 with loss 0.20707. Total time 1.0475 hours\n",
      "Training at Epoch 4 iteration 1000 with loss 0.21365. Total time 1.05527 hours\n",
      "Training at Epoch 4 iteration 1100 with loss 0.23019. Total time 1.06305 hours\n",
      "Training at Epoch 4 iteration 1200 with loss 0.20229. Total time 1.07083 hours\n",
      "Training at Epoch 4 iteration 1300 with loss 0.22065. Total time 1.07861 hours\n",
      "Training at Epoch 4 iteration 1400 with loss 0.25365. Total time 1.08666 hours\n",
      "Training at Epoch 4 iteration 1500 with loss 0.21462. Total time 1.09444 hours\n",
      "Training at Epoch 4 iteration 1600 with loss 0.21876. Total time 1.10222 hours\n",
      "Training at Epoch 4 iteration 1700 with loss 0.23769. Total time 1.11 hours\n",
      "Training at Epoch 4 iteration 1800 with loss 0.20139. Total time 1.11777 hours\n",
      "Training at Epoch 4 iteration 1900 with loss 0.29048. Total time 1.12583 hours\n",
      "Training at Epoch 4 iteration 2000 with loss 0.18893. Total time 1.13361 hours\n",
      "Training at Epoch 4 iteration 2100 with loss 0.25426. Total time 1.14138 hours\n",
      "Training at Epoch 4 iteration 2200 with loss 0.24551. Total time 1.14916 hours\n",
      "Training at Epoch 4 iteration 2300 with loss 0.22742. Total time 1.15722 hours\n",
      "Training at Epoch 4 iteration 2400 with loss 0.25318. Total time 1.165 hours\n",
      "Training at Epoch 4 iteration 2500 with loss 0.17227. Total time 1.17277 hours\n",
      "Training at Epoch 4 iteration 2600 with loss 0.23236. Total time 1.18083 hours\n",
      "Training at Epoch 4 iteration 2700 with loss 0.21394. Total time 1.18861 hours\n",
      "Training at Epoch 4 iteration 2800 with loss 0.18217. Total time 1.19638 hours\n",
      "Training at Epoch 4 iteration 2900 with loss 0.31985. Total time 1.20444 hours\n",
      "Training at Epoch 4 iteration 3000 with loss 0.19375. Total time 1.21222 hours\n",
      "Training at Epoch 4 iteration 3100 with loss 0.20671. Total time 1.22 hours\n",
      "Training at Epoch 4 iteration 3200 with loss 0.21360. Total time 1.22777 hours\n",
      "Training at Epoch 4 iteration 3300 with loss 0.26783. Total time 1.23583 hours\n",
      "Training at Epoch 4 iteration 3400 with loss 0.22972. Total time 1.24361 hours\n",
      "Training at Epoch 4 iteration 3500 with loss 0.23945. Total time 1.25138 hours\n",
      "Validation at Epoch 4, AUROC: 0.93356 , AUPRC: 0.83810 , F1: 0.74885 , Cross-entropy Loss: 4.22117\n",
      "Training at Epoch 5 iteration 0 with loss 0.21285. Total time 1.29916 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.22855. Total time 1.30722 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.19355. Total time 1.31527 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.17742. Total time 1.32305 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.18976. Total time 1.33083 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.16763. Total time 1.33861 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.15904. Total time 1.34666 hours\n",
      "Training at Epoch 5 iteration 700 with loss 0.17247. Total time 1.35444 hours\n",
      "Training at Epoch 5 iteration 800 with loss 0.27531. Total time 1.36222 hours\n",
      "Training at Epoch 5 iteration 900 with loss 0.18044. Total time 1.37 hours\n",
      "Training at Epoch 5 iteration 1000 with loss 0.20498. Total time 1.37777 hours\n",
      "Training at Epoch 5 iteration 1100 with loss 0.19599. Total time 1.38583 hours\n",
      "Training at Epoch 5 iteration 1200 with loss 0.19329. Total time 1.39361 hours\n",
      "Training at Epoch 5 iteration 1300 with loss 0.15202. Total time 1.40138 hours\n",
      "Training at Epoch 5 iteration 1400 with loss 0.21974. Total time 1.40916 hours\n",
      "Training at Epoch 5 iteration 1500 with loss 0.18229. Total time 1.41722 hours\n",
      "Training at Epoch 5 iteration 1600 with loss 0.24532. Total time 1.425 hours\n",
      "Training at Epoch 5 iteration 1700 with loss 0.19021. Total time 1.43277 hours\n",
      "Training at Epoch 5 iteration 1800 with loss 0.22085. Total time 1.44055 hours\n",
      "Training at Epoch 5 iteration 1900 with loss 0.17788. Total time 1.44833 hours\n",
      "Training at Epoch 5 iteration 2000 with loss 0.26409. Total time 1.45611 hours\n",
      "Training at Epoch 5 iteration 2100 with loss 0.19831. Total time 1.46416 hours\n",
      "Training at Epoch 5 iteration 2200 with loss 0.17654. Total time 1.47194 hours\n",
      "Training at Epoch 5 iteration 2300 with loss 0.19776. Total time 1.47972 hours\n",
      "Training at Epoch 5 iteration 2400 with loss 0.16320. Total time 1.4875 hours\n",
      "Training at Epoch 5 iteration 2500 with loss 0.22416. Total time 1.49527 hours\n",
      "Training at Epoch 5 iteration 2600 with loss 0.17525. Total time 1.50333 hours\n",
      "Training at Epoch 5 iteration 2700 with loss 0.21900. Total time 1.51111 hours\n",
      "Training at Epoch 5 iteration 2800 with loss 0.21452. Total time 1.51888 hours\n",
      "Training at Epoch 5 iteration 2900 with loss 0.21271. Total time 1.52666 hours\n",
      "Training at Epoch 5 iteration 3000 with loss 0.30412. Total time 1.53444 hours\n",
      "Training at Epoch 5 iteration 3100 with loss 0.24625. Total time 1.54222 hours\n",
      "Training at Epoch 5 iteration 3200 with loss 0.21366. Total time 1.55027 hours\n",
      "Training at Epoch 5 iteration 3300 with loss 0.19777. Total time 1.55805 hours\n",
      "Training at Epoch 5 iteration 3400 with loss 0.21758. Total time 1.56583 hours\n",
      "Training at Epoch 5 iteration 3500 with loss 0.23030. Total time 1.57361 hours\n",
      "Validation at Epoch 5, AUROC: 0.93493 , AUPRC: 0.84158 , F1: 0.75607 , Cross-entropy Loss: 4.14625\n",
      "Training at Epoch 6 iteration 0 with loss 0.17830. Total time 1.62111 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.19016. Total time 1.62888 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.12640. Total time 1.63666 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.13458. Total time 1.64444 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.16472. Total time 1.65222 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.18341. Total time 1.66 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.19158. Total time 1.66805 hours\n",
      "Training at Epoch 6 iteration 700 with loss 0.17173. Total time 1.67583 hours\n",
      "Training at Epoch 6 iteration 800 with loss 0.19738. Total time 1.68361 hours\n",
      "Training at Epoch 6 iteration 900 with loss 0.21957. Total time 1.69138 hours\n",
      "Training at Epoch 6 iteration 1000 with loss 0.19554. Total time 1.69916 hours\n",
      "Training at Epoch 6 iteration 1100 with loss 0.16829. Total time 1.70694 hours\n",
      "Training at Epoch 6 iteration 1200 with loss 0.19496. Total time 1.715 hours\n",
      "Training at Epoch 6 iteration 1300 with loss 0.19927. Total time 1.72277 hours\n",
      "Training at Epoch 6 iteration 1400 with loss 0.17521. Total time 1.73055 hours\n",
      "Training at Epoch 6 iteration 1500 with loss 0.23059. Total time 1.73833 hours\n",
      "Training at Epoch 6 iteration 1600 with loss 0.18445. Total time 1.74611 hours\n",
      "Training at Epoch 6 iteration 1700 with loss 0.23950. Total time 1.75416 hours\n",
      "Training at Epoch 6 iteration 1800 with loss 0.15739. Total time 1.76194 hours\n",
      "Training at Epoch 6 iteration 1900 with loss 0.16959. Total time 1.76972 hours\n",
      "Training at Epoch 6 iteration 2000 with loss 0.25285. Total time 1.7775 hours\n",
      "Training at Epoch 6 iteration 2100 with loss 0.21727. Total time 1.78527 hours\n",
      "Training at Epoch 6 iteration 2200 with loss 0.16045. Total time 1.79333 hours\n",
      "Training at Epoch 6 iteration 2300 with loss 0.24283. Total time 1.80111 hours\n",
      "Training at Epoch 6 iteration 2400 with loss 0.25998. Total time 1.80888 hours\n",
      "Training at Epoch 6 iteration 2500 with loss 0.19116. Total time 1.81694 hours\n",
      "Training at Epoch 6 iteration 2600 with loss 0.22886. Total time 1.82472 hours\n",
      "Training at Epoch 6 iteration 2700 with loss 0.21102. Total time 1.83277 hours\n",
      "Training at Epoch 6 iteration 2800 with loss 0.17827. Total time 1.84083 hours\n",
      "Training at Epoch 6 iteration 2900 with loss 0.19025. Total time 1.84861 hours\n",
      "Training at Epoch 6 iteration 3000 with loss 0.26130. Total time 1.85638 hours\n",
      "Training at Epoch 6 iteration 3100 with loss 0.22783. Total time 1.86416 hours\n",
      "Training at Epoch 6 iteration 3200 with loss 0.17610. Total time 1.87194 hours\n",
      "Training at Epoch 6 iteration 3300 with loss 0.18967. Total time 1.87972 hours\n",
      "Training at Epoch 6 iteration 3400 with loss 0.18750. Total time 1.8875 hours\n",
      "Training at Epoch 6 iteration 3500 with loss 0.16808. Total time 1.89555 hours\n",
      "Validation at Epoch 6, AUROC: 0.93507 , AUPRC: 0.84361 , F1: 0.75369 , Cross-entropy Loss: 4.07132\n",
      "Training at Epoch 7 iteration 0 with loss 0.15043. Total time 1.94277 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.13926. Total time 1.95055 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.16962. Total time 1.95833 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.14863. Total time 1.96611 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.19660. Total time 1.97388 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.18671. Total time 1.98166 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.13863. Total time 1.98944 hours\n",
      "Training at Epoch 7 iteration 700 with loss 0.12039. Total time 1.99722 hours\n",
      "Training at Epoch 7 iteration 800 with loss 0.17060. Total time 2.005 hours\n",
      "Training at Epoch 7 iteration 900 with loss 0.18193. Total time 2.01277 hours\n",
      "Training at Epoch 7 iteration 1000 with loss 0.21486. Total time 2.02055 hours\n",
      "Training at Epoch 7 iteration 1100 with loss 0.18403. Total time 2.02833 hours\n",
      "Training at Epoch 7 iteration 1200 with loss 0.20509. Total time 2.03611 hours\n",
      "Training at Epoch 7 iteration 1300 with loss 0.20265. Total time 2.04388 hours\n",
      "Training at Epoch 7 iteration 1400 with loss 0.19527. Total time 2.05194 hours\n",
      "Training at Epoch 7 iteration 1500 with loss 0.16753. Total time 2.05944 hours\n",
      "Training at Epoch 7 iteration 1600 with loss 0.15620. Total time 2.0675 hours\n",
      "Training at Epoch 7 iteration 1700 with loss 0.22334. Total time 2.075 hours\n",
      "Training at Epoch 7 iteration 1800 with loss 0.12653. Total time 2.08305 hours\n",
      "Training at Epoch 7 iteration 1900 with loss 0.20947. Total time 2.09083 hours\n",
      "Training at Epoch 7 iteration 2000 with loss 0.20416. Total time 2.09861 hours\n",
      "Training at Epoch 7 iteration 2100 with loss 0.21329. Total time 2.10638 hours\n",
      "Training at Epoch 7 iteration 2200 with loss 0.13745. Total time 2.11416 hours\n",
      "Training at Epoch 7 iteration 2300 with loss 0.17458. Total time 2.12194 hours\n",
      "Training at Epoch 7 iteration 2400 with loss 0.16366. Total time 2.12972 hours\n",
      "Training at Epoch 7 iteration 2500 with loss 0.13276. Total time 2.1375 hours\n",
      "Training at Epoch 7 iteration 2600 with loss 0.19569. Total time 2.14527 hours\n",
      "Training at Epoch 7 iteration 2700 with loss 0.14803. Total time 2.15305 hours\n",
      "Training at Epoch 7 iteration 2800 with loss 0.17147. Total time 2.16083 hours\n",
      "Training at Epoch 7 iteration 2900 with loss 0.22662. Total time 2.16861 hours\n",
      "Training at Epoch 7 iteration 3000 with loss 0.18573. Total time 2.17638 hours\n",
      "Training at Epoch 7 iteration 3100 with loss 0.19167. Total time 2.18416 hours\n",
      "Training at Epoch 7 iteration 3200 with loss 0.15622. Total time 2.19194 hours\n",
      "Training at Epoch 7 iteration 3300 with loss 0.18002. Total time 2.19972 hours\n",
      "Training at Epoch 7 iteration 3400 with loss 0.18689. Total time 2.2075 hours\n",
      "Training at Epoch 7 iteration 3500 with loss 0.18720. Total time 2.21527 hours\n",
      "Validation at Epoch 7, AUROC: 0.93449 , AUPRC: 0.84476 , F1: 0.75406 , Cross-entropy Loss: 4.01803\n",
      "Training at Epoch 8 iteration 0 with loss 0.13221. Total time 2.26222 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.11936. Total time 2.27 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.14620. Total time 2.27777 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.13533. Total time 2.28555 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.13766. Total time 2.29333 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.14763. Total time 2.30111 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.15832. Total time 2.30888 hours\n",
      "Training at Epoch 8 iteration 700 with loss 0.12053. Total time 2.31666 hours\n",
      "Training at Epoch 8 iteration 800 with loss 0.15483. Total time 2.32444 hours\n",
      "Training at Epoch 8 iteration 900 with loss 0.22764. Total time 2.33222 hours\n",
      "Training at Epoch 8 iteration 1000 with loss 0.18928. Total time 2.34 hours\n",
      "Training at Epoch 8 iteration 1100 with loss 0.20042. Total time 2.34777 hours\n",
      "Training at Epoch 8 iteration 1200 with loss 0.14014. Total time 2.35555 hours\n",
      "Training at Epoch 8 iteration 1300 with loss 0.14924. Total time 2.36333 hours\n",
      "Training at Epoch 8 iteration 1400 with loss 0.17499. Total time 2.37111 hours\n",
      "Training at Epoch 8 iteration 1500 with loss 0.19389. Total time 2.37888 hours\n",
      "Training at Epoch 8 iteration 1600 with loss 0.13229. Total time 2.38666 hours\n",
      "Training at Epoch 8 iteration 1700 with loss 0.18329. Total time 2.39444 hours\n",
      "Training at Epoch 8 iteration 1800 with loss 0.12581. Total time 2.40222 hours\n",
      "Training at Epoch 8 iteration 1900 with loss 0.12536. Total time 2.41 hours\n",
      "Training at Epoch 8 iteration 2000 with loss 0.17256. Total time 2.41777 hours\n",
      "Training at Epoch 8 iteration 2100 with loss 0.22643. Total time 2.42555 hours\n",
      "Training at Epoch 8 iteration 2200 with loss 0.12854. Total time 2.43333 hours\n",
      "Training at Epoch 8 iteration 2300 with loss 0.19641. Total time 2.44111 hours\n",
      "Training at Epoch 8 iteration 2400 with loss 0.19012. Total time 2.44888 hours\n",
      "Training at Epoch 8 iteration 2500 with loss 0.17273. Total time 2.45666 hours\n",
      "Training at Epoch 8 iteration 2600 with loss 0.14308. Total time 2.46444 hours\n",
      "Training at Epoch 8 iteration 2700 with loss 0.13476. Total time 2.47222 hours\n",
      "Training at Epoch 8 iteration 2800 with loss 0.12855. Total time 2.48 hours\n",
      "Training at Epoch 8 iteration 2900 with loss 0.17257. Total time 2.48777 hours\n",
      "Training at Epoch 8 iteration 3000 with loss 0.14109. Total time 2.49555 hours\n",
      "Training at Epoch 8 iteration 3100 with loss 0.17733. Total time 2.50333 hours\n",
      "Training at Epoch 8 iteration 3200 with loss 0.15108. Total time 2.51138 hours\n",
      "Training at Epoch 8 iteration 3300 with loss 0.19479. Total time 2.51916 hours\n",
      "Training at Epoch 8 iteration 3400 with loss 0.18062. Total time 2.52694 hours\n",
      "Training at Epoch 8 iteration 3500 with loss 0.19180. Total time 2.53472 hours\n",
      "Validation at Epoch 8, AUROC: 0.93480 , AUPRC: 0.84289 , F1: 0.75955 , Cross-entropy Loss: 4.06737\n",
      "Training at Epoch 9 iteration 0 with loss 0.13512. Total time 2.58166 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.12437. Total time 2.58972 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.14763. Total time 2.5975 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.13916. Total time 2.60555 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.12727. Total time 2.61333 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.15548. Total time 2.62138 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.09307. Total time 2.62916 hours\n",
      "Training at Epoch 9 iteration 700 with loss 0.11999. Total time 2.63694 hours\n",
      "Training at Epoch 9 iteration 800 with loss 0.12126. Total time 2.64472 hours\n",
      "Training at Epoch 9 iteration 900 with loss 0.12933. Total time 2.6525 hours\n",
      "Training at Epoch 9 iteration 1000 with loss 0.16724. Total time 2.66027 hours\n",
      "Training at Epoch 9 iteration 1100 with loss 0.17869. Total time 2.66805 hours\n",
      "Training at Epoch 9 iteration 1200 with loss 0.13597. Total time 2.67583 hours\n",
      "Training at Epoch 9 iteration 1300 with loss 0.15562. Total time 2.68361 hours\n",
      "Training at Epoch 9 iteration 1400 with loss 0.12658. Total time 2.69138 hours\n",
      "Training at Epoch 9 iteration 1500 with loss 0.17951. Total time 2.69944 hours\n",
      "Training at Epoch 9 iteration 1600 with loss 0.13671. Total time 2.70722 hours\n",
      "Training at Epoch 9 iteration 1700 with loss 0.16556. Total time 2.715 hours\n",
      "Training at Epoch 9 iteration 1800 with loss 0.15744. Total time 2.72277 hours\n",
      "Training at Epoch 9 iteration 1900 with loss 0.15324. Total time 2.73055 hours\n",
      "Training at Epoch 9 iteration 2000 with loss 0.13731. Total time 2.73833 hours\n",
      "Training at Epoch 9 iteration 2100 with loss 0.15013. Total time 2.74611 hours\n",
      "Training at Epoch 9 iteration 2200 with loss 0.12514. Total time 2.75388 hours\n",
      "Training at Epoch 9 iteration 2300 with loss 0.14699. Total time 2.76166 hours\n",
      "Training at Epoch 9 iteration 2400 with loss 0.20450. Total time 2.76944 hours\n",
      "Training at Epoch 9 iteration 2500 with loss 0.14595. Total time 2.77722 hours\n",
      "Training at Epoch 9 iteration 2600 with loss 0.17329. Total time 2.785 hours\n",
      "Training at Epoch 9 iteration 2700 with loss 0.14636. Total time 2.7925 hours\n",
      "Training at Epoch 9 iteration 2800 with loss 0.16844. Total time 2.80027 hours\n",
      "Training at Epoch 9 iteration 2900 with loss 0.24344. Total time 2.80805 hours\n",
      "Training at Epoch 9 iteration 3000 with loss 0.12692. Total time 2.81583 hours\n",
      "Training at Epoch 9 iteration 3100 with loss 0.17425. Total time 2.82361 hours\n",
      "Training at Epoch 9 iteration 3200 with loss 0.16228. Total time 2.83138 hours\n",
      "Training at Epoch 9 iteration 3300 with loss 0.15109. Total time 2.83916 hours\n",
      "Training at Epoch 9 iteration 3400 with loss 0.13055. Total time 2.84694 hours\n",
      "Training at Epoch 9 iteration 3500 with loss 0.19002. Total time 2.85472 hours\n",
      "Validation at Epoch 9, AUROC: 0.93567 , AUPRC: 0.84711 , F1: 0.76345 , Cross-entropy Loss: 3.99007\n",
      "Training at Epoch 10 iteration 0 with loss 0.13502. Total time 2.90222 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.16184. Total time 2.91 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.13522. Total time 2.91777 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.17668. Total time 2.92555 hours\n",
      "Training at Epoch 10 iteration 400 with loss 0.12798. Total time 2.93333 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.13996. Total time 2.94111 hours\n",
      "Training at Epoch 10 iteration 600 with loss 0.13354. Total time 2.94888 hours\n",
      "Training at Epoch 10 iteration 700 with loss 0.15653. Total time 2.95666 hours\n",
      "Training at Epoch 10 iteration 800 with loss 0.13787. Total time 2.96444 hours\n",
      "Training at Epoch 10 iteration 900 with loss 0.16402. Total time 2.97222 hours\n",
      "Training at Epoch 10 iteration 1000 with loss 0.14225. Total time 2.98 hours\n",
      "Training at Epoch 10 iteration 1100 with loss 0.10188. Total time 2.98777 hours\n",
      "Training at Epoch 10 iteration 1200 with loss 0.15608. Total time 2.99555 hours\n",
      "Training at Epoch 10 iteration 1300 with loss 0.12163. Total time 3.00333 hours\n",
      "Training at Epoch 10 iteration 1400 with loss 0.15172. Total time 3.01111 hours\n",
      "Training at Epoch 10 iteration 1500 with loss 0.18521. Total time 3.01888 hours\n",
      "Training at Epoch 10 iteration 1600 with loss 0.12778. Total time 3.02666 hours\n",
      "Training at Epoch 10 iteration 1700 with loss 0.12168. Total time 3.03444 hours\n",
      "Training at Epoch 10 iteration 1800 with loss 0.14778. Total time 3.04222 hours\n",
      "Training at Epoch 10 iteration 1900 with loss 0.17216. Total time 3.05 hours\n",
      "Training at Epoch 10 iteration 2000 with loss 0.13444. Total time 3.05777 hours\n",
      "Training at Epoch 10 iteration 2100 with loss 0.18204. Total time 3.06527 hours\n",
      "Training at Epoch 10 iteration 2200 with loss 0.19173. Total time 3.07305 hours\n",
      "Training at Epoch 10 iteration 2300 with loss 0.16185. Total time 3.08083 hours\n",
      "Training at Epoch 10 iteration 2400 with loss 0.16822. Total time 3.08861 hours\n",
      "Training at Epoch 10 iteration 2500 with loss 0.18886. Total time 3.09638 hours\n",
      "Training at Epoch 10 iteration 2600 with loss 0.13600. Total time 3.10416 hours\n",
      "Training at Epoch 10 iteration 2700 with loss 0.15837. Total time 3.11194 hours\n",
      "Training at Epoch 10 iteration 2800 with loss 0.16298. Total time 3.11972 hours\n",
      "Training at Epoch 10 iteration 2900 with loss 0.17985. Total time 3.1275 hours\n",
      "Training at Epoch 10 iteration 3000 with loss 0.13741. Total time 3.13527 hours\n",
      "Training at Epoch 10 iteration 3100 with loss 0.14882. Total time 3.14305 hours\n",
      "Training at Epoch 10 iteration 3200 with loss 0.18685. Total time 3.15083 hours\n",
      "Training at Epoch 10 iteration 3300 with loss 0.22351. Total time 3.15861 hours\n",
      "Training at Epoch 10 iteration 3400 with loss 0.21728. Total time 3.16638 hours\n",
      "Training at Epoch 10 iteration 3500 with loss 0.19462. Total time 3.17388 hours\n",
      "Validation at Epoch 10, AUROC: 0.93639 , AUPRC: 0.84669 , F1: 0.76593 , Cross-entropy Loss: 3.92623\n",
      "Training at Epoch 11 iteration 0 with loss 0.13510. Total time 3.22111 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.14569. Total time 3.22888 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.17282. Total time 3.23666 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.11007. Total time 3.24444 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.13701. Total time 3.25222 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.14975. Total time 3.26 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.14185. Total time 3.26777 hours\n",
      "Training at Epoch 11 iteration 700 with loss 0.16023. Total time 3.27555 hours\n",
      "Training at Epoch 11 iteration 800 with loss 0.15131. Total time 3.28361 hours\n",
      "Training at Epoch 11 iteration 900 with loss 0.07084. Total time 3.29138 hours\n",
      "Training at Epoch 11 iteration 1000 with loss 0.13259. Total time 3.29916 hours\n",
      "Training at Epoch 11 iteration 1100 with loss 0.15190. Total time 3.30694 hours\n",
      "Training at Epoch 11 iteration 1200 with loss 0.11033. Total time 3.31472 hours\n",
      "Training at Epoch 11 iteration 1300 with loss 0.17010. Total time 3.32277 hours\n",
      "Training at Epoch 11 iteration 1400 with loss 0.14066. Total time 3.33055 hours\n",
      "Training at Epoch 11 iteration 1500 with loss 0.15156. Total time 3.33833 hours\n",
      "Training at Epoch 11 iteration 1600 with loss 0.13794. Total time 3.34611 hours\n",
      "Training at Epoch 11 iteration 1700 with loss 0.14565. Total time 3.35416 hours\n",
      "Training at Epoch 11 iteration 1800 with loss 0.21312. Total time 3.36194 hours\n",
      "Training at Epoch 11 iteration 1900 with loss 0.14428. Total time 3.36972 hours\n",
      "Training at Epoch 11 iteration 2000 with loss 0.15827. Total time 3.3775 hours\n",
      "Training at Epoch 11 iteration 2100 with loss 0.13449. Total time 3.38555 hours\n",
      "Training at Epoch 11 iteration 2200 with loss 0.14660. Total time 3.39333 hours\n",
      "Training at Epoch 11 iteration 2300 with loss 0.14245. Total time 3.40111 hours\n",
      "Training at Epoch 11 iteration 2400 with loss 0.10525. Total time 3.40888 hours\n",
      "Training at Epoch 11 iteration 2500 with loss 0.18389. Total time 3.41694 hours\n",
      "Training at Epoch 11 iteration 2600 with loss 0.20648. Total time 3.42472 hours\n",
      "Training at Epoch 11 iteration 2700 with loss 0.12823. Total time 3.4325 hours\n",
      "Training at Epoch 11 iteration 2800 with loss 0.12135. Total time 3.44027 hours\n",
      "Training at Epoch 11 iteration 2900 with loss 0.18739. Total time 3.44805 hours\n",
      "Training at Epoch 11 iteration 3000 with loss 0.10401. Total time 3.45583 hours\n",
      "Training at Epoch 11 iteration 3100 with loss 0.14126. Total time 3.46361 hours\n",
      "Training at Epoch 11 iteration 3200 with loss 0.14982. Total time 3.47166 hours\n",
      "Training at Epoch 11 iteration 3300 with loss 0.14679. Total time 3.47944 hours\n",
      "Training at Epoch 11 iteration 3400 with loss 0.13796. Total time 3.48722 hours\n",
      "Training at Epoch 11 iteration 3500 with loss 0.17328. Total time 3.495 hours\n",
      "Validation at Epoch 11, AUROC: 0.93437 , AUPRC: 0.84375 , F1: 0.76502 , Cross-entropy Loss: 3.96686\n",
      "Training at Epoch 12 iteration 0 with loss 0.11154. Total time 3.54194 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.08414. Total time 3.54972 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.11616. Total time 3.5575 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.14768. Total time 3.56527 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.12541. Total time 3.57305 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.14224. Total time 3.58083 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.14747. Total time 3.58861 hours\n",
      "Training at Epoch 12 iteration 700 with loss 0.12933. Total time 3.59638 hours\n",
      "Training at Epoch 12 iteration 800 with loss 0.07595. Total time 3.60416 hours\n",
      "Training at Epoch 12 iteration 900 with loss 0.17797. Total time 3.61194 hours\n",
      "Training at Epoch 12 iteration 1000 with loss 0.10792. Total time 3.61972 hours\n",
      "Training at Epoch 12 iteration 1100 with loss 0.14363. Total time 3.6275 hours\n",
      "Training at Epoch 12 iteration 1200 with loss 0.17832. Total time 3.63527 hours\n",
      "Training at Epoch 12 iteration 1300 with loss 0.12201. Total time 3.64305 hours\n",
      "Training at Epoch 12 iteration 1400 with loss 0.14319. Total time 3.65111 hours\n",
      "Training at Epoch 12 iteration 1500 with loss 0.13622. Total time 3.65888 hours\n",
      "Training at Epoch 12 iteration 1600 with loss 0.10744. Total time 3.66666 hours\n",
      "Training at Epoch 12 iteration 1700 with loss 0.14603. Total time 3.67472 hours\n",
      "Training at Epoch 12 iteration 1800 with loss 0.15009. Total time 3.6825 hours\n",
      "Training at Epoch 12 iteration 1900 with loss 0.12628. Total time 3.69027 hours\n",
      "Training at Epoch 12 iteration 2000 with loss 0.11979. Total time 3.69805 hours\n",
      "Training at Epoch 12 iteration 2100 with loss 0.13591. Total time 3.70583 hours\n",
      "Training at Epoch 12 iteration 2200 with loss 0.16935. Total time 3.71333 hours\n",
      "Training at Epoch 12 iteration 2300 with loss 0.11538. Total time 3.72111 hours\n",
      "Training at Epoch 12 iteration 2400 with loss 0.15318. Total time 3.72888 hours\n",
      "Training at Epoch 12 iteration 2500 with loss 0.13207. Total time 3.73666 hours\n",
      "Training at Epoch 12 iteration 2600 with loss 0.12303. Total time 3.74444 hours\n",
      "Training at Epoch 12 iteration 2700 with loss 0.15498. Total time 3.75222 hours\n",
      "Training at Epoch 12 iteration 2800 with loss 0.14305. Total time 3.76 hours\n",
      "Training at Epoch 12 iteration 2900 with loss 0.15804. Total time 3.76777 hours\n",
      "Training at Epoch 12 iteration 3000 with loss 0.16580. Total time 3.77555 hours\n",
      "Training at Epoch 12 iteration 3100 with loss 0.17020. Total time 3.78333 hours\n",
      "Training at Epoch 12 iteration 3200 with loss 0.11805. Total time 3.79111 hours\n",
      "Training at Epoch 12 iteration 3300 with loss 0.12836. Total time 3.79888 hours\n",
      "Training at Epoch 12 iteration 3400 with loss 0.13616. Total time 3.80666 hours\n",
      "Training at Epoch 12 iteration 3500 with loss 0.13902. Total time 3.81444 hours\n",
      "Validation at Epoch 12, AUROC: 0.93500 , AUPRC: 0.84530 , F1: 0.76821 , Cross-entropy Loss: 3.92623\n",
      "Training at Epoch 13 iteration 0 with loss 0.10093. Total time 3.86138 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.08605. Total time 3.86916 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.20787. Total time 3.87666 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.15010. Total time 3.88444 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.10167. Total time 3.89222 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.13255. Total time 3.9 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.16658. Total time 3.90777 hours\n",
      "Training at Epoch 13 iteration 700 with loss 0.09953. Total time 3.91555 hours\n",
      "Training at Epoch 13 iteration 800 with loss 0.08652. Total time 3.92361 hours\n",
      "Training at Epoch 13 iteration 900 with loss 0.14161. Total time 3.93138 hours\n",
      "Training at Epoch 13 iteration 1000 with loss 0.09433. Total time 3.93916 hours\n",
      "Training at Epoch 13 iteration 1100 with loss 0.17680. Total time 3.94694 hours\n",
      "Training at Epoch 13 iteration 1200 with loss 0.14471. Total time 3.95472 hours\n",
      "Training at Epoch 13 iteration 1300 with loss 0.11340. Total time 3.9625 hours\n",
      "Training at Epoch 13 iteration 1400 with loss 0.09791. Total time 3.97027 hours\n",
      "Training at Epoch 13 iteration 1500 with loss 0.09234. Total time 3.97805 hours\n",
      "Training at Epoch 13 iteration 1600 with loss 0.14651. Total time 3.98583 hours\n",
      "Training at Epoch 13 iteration 1700 with loss 0.11185. Total time 3.99361 hours\n",
      "Training at Epoch 13 iteration 1800 with loss 0.10390. Total time 4.00138 hours\n",
      "Training at Epoch 13 iteration 1900 with loss 0.15160. Total time 4.00916 hours\n",
      "Training at Epoch 13 iteration 2000 with loss 0.09392. Total time 4.01694 hours\n",
      "Training at Epoch 13 iteration 2100 with loss 0.13729. Total time 4.02472 hours\n",
      "Training at Epoch 13 iteration 2200 with loss 0.09903. Total time 4.0325 hours\n",
      "Training at Epoch 13 iteration 2300 with loss 0.09017. Total time 4.04027 hours\n",
      "Training at Epoch 13 iteration 2400 with loss 0.11267. Total time 4.04805 hours\n",
      "Training at Epoch 13 iteration 2500 with loss 0.12172. Total time 4.05583 hours\n",
      "Training at Epoch 13 iteration 2600 with loss 0.17982. Total time 4.06361 hours\n",
      "Training at Epoch 13 iteration 2700 with loss 0.16640. Total time 4.07111 hours\n",
      "Training at Epoch 13 iteration 2800 with loss 0.11158. Total time 4.07888 hours\n",
      "Training at Epoch 13 iteration 2900 with loss 0.18952. Total time 4.08666 hours\n",
      "Training at Epoch 13 iteration 3000 with loss 0.12275. Total time 4.09444 hours\n",
      "Training at Epoch 13 iteration 3100 with loss 0.13752. Total time 4.10222 hours\n",
      "Training at Epoch 13 iteration 3200 with loss 0.10626. Total time 4.11 hours\n",
      "Training at Epoch 13 iteration 3300 with loss 0.10107. Total time 4.11777 hours\n",
      "Training at Epoch 13 iteration 3400 with loss 0.09583. Total time 4.12555 hours\n",
      "Training at Epoch 13 iteration 3500 with loss 0.11318. Total time 4.13333 hours\n",
      "Validation at Epoch 13, AUROC: 0.93259 , AUPRC: 0.84290 , F1: 0.76456 , Cross-entropy Loss: 3.90961\n",
      "Training at Epoch 14 iteration 0 with loss 0.08805. Total time 4.18027 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.09283. Total time 4.18833 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.10456. Total time 4.19611 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.10519. Total time 4.20388 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.08228. Total time 4.21166 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.11408. Total time 4.21944 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.09668. Total time 4.22722 hours\n",
      "Training at Epoch 14 iteration 700 with loss 0.12473. Total time 4.235 hours\n",
      "Training at Epoch 14 iteration 800 with loss 0.14600. Total time 4.24277 hours\n",
      "Training at Epoch 14 iteration 900 with loss 0.08409. Total time 4.25055 hours\n",
      "Training at Epoch 14 iteration 1000 with loss 0.10731. Total time 4.25833 hours\n",
      "Training at Epoch 14 iteration 1100 with loss 0.10176. Total time 4.26611 hours\n",
      "Training at Epoch 14 iteration 1200 with loss 0.16587. Total time 4.27388 hours\n",
      "Training at Epoch 14 iteration 1300 with loss 0.12757. Total time 4.28166 hours\n",
      "Training at Epoch 14 iteration 1400 with loss 0.13429. Total time 4.28944 hours\n",
      "Training at Epoch 14 iteration 1500 with loss 0.10870. Total time 4.29722 hours\n",
      "Training at Epoch 14 iteration 1600 with loss 0.11352. Total time 4.305 hours\n",
      "Training at Epoch 14 iteration 1700 with loss 0.11619. Total time 4.31277 hours\n",
      "Training at Epoch 14 iteration 1800 with loss 0.10009. Total time 4.32055 hours\n",
      "Training at Epoch 14 iteration 1900 with loss 0.21633. Total time 4.32805 hours\n",
      "Training at Epoch 14 iteration 2000 with loss 0.11320. Total time 4.33583 hours\n",
      "Training at Epoch 14 iteration 2100 with loss 0.07759. Total time 4.34361 hours\n",
      "Training at Epoch 14 iteration 2200 with loss 0.14548. Total time 4.35166 hours\n",
      "Training at Epoch 14 iteration 2300 with loss 0.08199. Total time 4.35944 hours\n",
      "Training at Epoch 14 iteration 2400 with loss 0.16142. Total time 4.36722 hours\n",
      "Training at Epoch 14 iteration 2500 with loss 0.10277. Total time 4.37527 hours\n",
      "Training at Epoch 14 iteration 2600 with loss 0.08501. Total time 4.38305 hours\n",
      "Training at Epoch 14 iteration 2700 with loss 0.11850. Total time 4.39083 hours\n",
      "Training at Epoch 14 iteration 2800 with loss 0.11926. Total time 4.39861 hours\n",
      "Training at Epoch 14 iteration 2900 with loss 0.12264. Total time 4.40638 hours\n",
      "Training at Epoch 14 iteration 3000 with loss 0.10561. Total time 4.41416 hours\n",
      "Training at Epoch 14 iteration 3100 with loss 0.10638. Total time 4.42194 hours\n",
      "Training at Epoch 14 iteration 3200 with loss 0.14732. Total time 4.42972 hours\n",
      "Training at Epoch 14 iteration 3300 with loss 0.11583. Total time 4.4375 hours\n",
      "Training at Epoch 14 iteration 3400 with loss 0.14237. Total time 4.44527 hours\n",
      "Training at Epoch 14 iteration 3500 with loss 0.12299. Total time 4.45305 hours\n",
      "Validation at Epoch 14, AUROC: 0.93438 , AUPRC: 0.84464 , F1: 0.76359 , Cross-entropy Loss: 3.89800\n",
      "Training at Epoch 15 iteration 0 with loss 0.07684. Total time 4.50027 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.08365. Total time 4.50805 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.07873. Total time 4.51583 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.08184. Total time 4.52361 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.12766. Total time 4.53138 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.08252. Total time 4.53916 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.07316. Total time 4.54722 hours\n",
      "Training at Epoch 15 iteration 700 with loss 0.10241. Total time 4.55472 hours\n",
      "Training at Epoch 15 iteration 800 with loss 0.13234. Total time 4.56277 hours\n",
      "Training at Epoch 15 iteration 900 with loss 0.12501. Total time 4.57027 hours\n",
      "Training at Epoch 15 iteration 1000 with loss 0.11720. Total time 4.57805 hours\n",
      "Training at Epoch 15 iteration 1100 with loss 0.10206. Total time 4.58583 hours\n",
      "Training at Epoch 15 iteration 1200 with loss 0.15383. Total time 4.59361 hours\n",
      "Training at Epoch 15 iteration 1300 with loss 0.08152. Total time 4.60138 hours\n",
      "Training at Epoch 15 iteration 1400 with loss 0.17380. Total time 4.60944 hours\n",
      "Training at Epoch 15 iteration 1500 with loss 0.12304. Total time 4.61722 hours\n",
      "Training at Epoch 15 iteration 1600 with loss 0.13674. Total time 4.625 hours\n",
      "Training at Epoch 15 iteration 1700 with loss 0.15335. Total time 4.63277 hours\n",
      "Training at Epoch 15 iteration 1800 with loss 0.06397. Total time 4.64055 hours\n",
      "Training at Epoch 15 iteration 1900 with loss 0.09012. Total time 4.64833 hours\n",
      "Training at Epoch 15 iteration 2000 with loss 0.07782. Total time 4.65611 hours\n",
      "Training at Epoch 15 iteration 2100 with loss 0.10453. Total time 4.66388 hours\n",
      "Training at Epoch 15 iteration 2200 with loss 0.08847. Total time 4.67166 hours\n",
      "Training at Epoch 15 iteration 2300 with loss 0.10402. Total time 4.67944 hours\n",
      "Training at Epoch 15 iteration 2400 with loss 0.09963. Total time 4.68722 hours\n",
      "Training at Epoch 15 iteration 2500 with loss 0.14938. Total time 4.695 hours\n",
      "Training at Epoch 15 iteration 2600 with loss 0.14188. Total time 4.70277 hours\n",
      "Training at Epoch 15 iteration 2700 with loss 0.11330. Total time 4.71055 hours\n",
      "Training at Epoch 15 iteration 2800 with loss 0.11193. Total time 4.71833 hours\n",
      "Training at Epoch 15 iteration 2900 with loss 0.09207. Total time 4.72611 hours\n",
      "Training at Epoch 15 iteration 3000 with loss 0.15283. Total time 4.73388 hours\n",
      "Training at Epoch 15 iteration 3100 with loss 0.13486. Total time 4.74166 hours\n",
      "Training at Epoch 15 iteration 3200 with loss 0.10004. Total time 4.74944 hours\n",
      "Training at Epoch 15 iteration 3300 with loss 0.14193. Total time 4.75722 hours\n",
      "Training at Epoch 15 iteration 3400 with loss 0.12244. Total time 4.765 hours\n",
      "Training at Epoch 15 iteration 3500 with loss 0.15753. Total time 4.77277 hours\n",
      "Validation at Epoch 15, AUROC: 0.93432 , AUPRC: 0.84242 , F1: 0.76832 , Cross-entropy Loss: 3.90539\n",
      "Training at Epoch 16 iteration 0 with loss 0.10674. Total time 4.82 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.09825. Total time 4.82777 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.08219. Total time 4.83555 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.10785. Total time 4.84333 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.08209. Total time 4.85111 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.11356. Total time 4.85916 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.10278. Total time 4.86694 hours\n",
      "Training at Epoch 16 iteration 700 with loss 0.07828. Total time 4.875 hours\n",
      "Training at Epoch 16 iteration 800 with loss 0.10371. Total time 4.88277 hours\n",
      "Training at Epoch 16 iteration 900 with loss 0.10823. Total time 4.89055 hours\n",
      "Training at Epoch 16 iteration 1000 with loss 0.12745. Total time 4.89861 hours\n",
      "Training at Epoch 16 iteration 1100 with loss 0.11707. Total time 4.90638 hours\n",
      "Training at Epoch 16 iteration 1200 with loss 0.09262. Total time 4.91416 hours\n",
      "Training at Epoch 16 iteration 1300 with loss 0.15066. Total time 4.92194 hours\n",
      "Training at Epoch 16 iteration 1400 with loss 0.16950. Total time 4.92972 hours\n",
      "Training at Epoch 16 iteration 1500 with loss 0.08531. Total time 4.9375 hours\n",
      "Training at Epoch 16 iteration 1600 with loss 0.12325. Total time 4.94555 hours\n",
      "Training at Epoch 16 iteration 1700 with loss 0.10337. Total time 4.95333 hours\n",
      "Training at Epoch 16 iteration 1800 with loss 0.11177. Total time 4.96111 hours\n",
      "Training at Epoch 16 iteration 1900 with loss 0.17270. Total time 4.96888 hours\n",
      "Training at Epoch 16 iteration 2000 with loss 0.11101. Total time 4.97666 hours\n",
      "Training at Epoch 16 iteration 2100 with loss 0.11896. Total time 4.98444 hours\n",
      "Training at Epoch 16 iteration 2200 with loss 0.13787. Total time 4.99222 hours\n",
      "Training at Epoch 16 iteration 2300 with loss 0.11748. Total time 5.00027 hours\n",
      "Training at Epoch 16 iteration 2400 with loss 0.09077. Total time 5.00805 hours\n",
      "Training at Epoch 16 iteration 2500 with loss 0.12138. Total time 5.01583 hours\n",
      "Training at Epoch 16 iteration 2600 with loss 0.09272. Total time 5.02361 hours\n",
      "Training at Epoch 16 iteration 2700 with loss 0.12483. Total time 5.03138 hours\n",
      "Training at Epoch 16 iteration 2800 with loss 0.12112. Total time 5.03916 hours\n",
      "Training at Epoch 16 iteration 2900 with loss 0.06460. Total time 5.04694 hours\n",
      "Training at Epoch 16 iteration 3000 with loss 0.13505. Total time 5.05472 hours\n",
      "Training at Epoch 16 iteration 3100 with loss 0.08300. Total time 5.0625 hours\n",
      "Training at Epoch 16 iteration 3200 with loss 0.12550. Total time 5.07027 hours\n",
      "Training at Epoch 16 iteration 3300 with loss 0.07802. Total time 5.07805 hours\n",
      "Training at Epoch 16 iteration 3400 with loss 0.14226. Total time 5.08583 hours\n",
      "Training at Epoch 16 iteration 3500 with loss 0.12152. Total time 5.09388 hours\n",
      "Validation at Epoch 16, AUROC: 0.93374 , AUPRC: 0.84260 , F1: 0.77006 , Cross-entropy Loss: 3.94892\n",
      "Training at Epoch 17 iteration 0 with loss 0.08007. Total time 5.14083 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.11885. Total time 5.14861 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.08174. Total time 5.15638 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.11240. Total time 5.16416 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.07067. Total time 5.17222 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.08599. Total time 5.18 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.07879. Total time 5.18777 hours\n",
      "Training at Epoch 17 iteration 700 with loss 0.08354. Total time 5.19555 hours\n",
      "Training at Epoch 17 iteration 800 with loss 0.10320. Total time 5.20333 hours\n",
      "Training at Epoch 17 iteration 900 with loss 0.11106. Total time 5.21111 hours\n",
      "Training at Epoch 17 iteration 1000 with loss 0.12336. Total time 5.21888 hours\n",
      "Training at Epoch 17 iteration 1100 with loss 0.10407. Total time 5.22666 hours\n",
      "Training at Epoch 17 iteration 1200 with loss 0.17327. Total time 5.23444 hours\n",
      "Training at Epoch 17 iteration 1300 with loss 0.07824. Total time 5.24222 hours\n",
      "Training at Epoch 17 iteration 1400 with loss 0.11383. Total time 5.25 hours\n",
      "Training at Epoch 17 iteration 1500 with loss 0.18433. Total time 5.25777 hours\n",
      "Training at Epoch 17 iteration 1600 with loss 0.09497. Total time 5.26555 hours\n",
      "Training at Epoch 17 iteration 1700 with loss 0.11248. Total time 5.27361 hours\n",
      "Training at Epoch 17 iteration 1800 with loss 0.17308. Total time 5.28166 hours\n",
      "Training at Epoch 17 iteration 1900 with loss 0.10492. Total time 5.28944 hours\n",
      "Training at Epoch 17 iteration 2000 with loss 0.10556. Total time 5.29722 hours\n",
      "Training at Epoch 17 iteration 2100 with loss 0.08043. Total time 5.305 hours\n",
      "Training at Epoch 17 iteration 2200 with loss 0.11330. Total time 5.31277 hours\n",
      "Training at Epoch 17 iteration 2300 with loss 0.11478. Total time 5.32055 hours\n",
      "Training at Epoch 17 iteration 2400 with loss 0.14096. Total time 5.32833 hours\n",
      "Training at Epoch 17 iteration 2500 with loss 0.11058. Total time 5.33611 hours\n",
      "Training at Epoch 17 iteration 2600 with loss 0.12403. Total time 5.34388 hours\n",
      "Training at Epoch 17 iteration 2700 with loss 0.13094. Total time 5.35166 hours\n",
      "Training at Epoch 17 iteration 2800 with loss 0.11266. Total time 5.35944 hours\n",
      "Training at Epoch 17 iteration 2900 with loss 0.12778. Total time 5.3675 hours\n",
      "Training at Epoch 17 iteration 3000 with loss 0.10646. Total time 5.37527 hours\n",
      "Training at Epoch 17 iteration 3100 with loss 0.06239. Total time 5.38305 hours\n",
      "Training at Epoch 17 iteration 3200 with loss 0.17833. Total time 5.39083 hours\n",
      "Training at Epoch 17 iteration 3300 with loss 0.12168. Total time 5.39861 hours\n",
      "Training at Epoch 17 iteration 3400 with loss 0.11171. Total time 5.40638 hours\n",
      "Training at Epoch 17 iteration 3500 with loss 0.12192. Total time 5.41416 hours\n",
      "Validation at Epoch 17, AUROC: 0.93296 , AUPRC: 0.84186 , F1: 0.76961 , Cross-entropy Loss: 3.90645\n",
      "Training at Epoch 18 iteration 0 with loss 0.08666. Total time 5.46111 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.11041. Total time 5.46888 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.09461. Total time 5.47666 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.10413. Total time 5.48472 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.07619. Total time 5.4925 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.10993. Total time 5.50027 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.12299. Total time 5.50805 hours\n",
      "Training at Epoch 18 iteration 700 with loss 0.08041. Total time 5.51583 hours\n",
      "Training at Epoch 18 iteration 800 with loss 0.10571. Total time 5.52361 hours\n",
      "Training at Epoch 18 iteration 900 with loss 0.10902. Total time 5.53138 hours\n",
      "Training at Epoch 18 iteration 1000 with loss 0.09012. Total time 5.53916 hours\n",
      "Training at Epoch 18 iteration 1100 with loss 0.07775. Total time 5.54694 hours\n",
      "Training at Epoch 18 iteration 1200 with loss 0.12024. Total time 5.55472 hours\n",
      "Training at Epoch 18 iteration 1300 with loss 0.09545. Total time 5.5625 hours\n",
      "Training at Epoch 18 iteration 1400 with loss 0.14304. Total time 5.57027 hours\n",
      "Training at Epoch 18 iteration 1500 with loss 0.12965. Total time 5.57805 hours\n",
      "Training at Epoch 18 iteration 1600 with loss 0.10578. Total time 5.58583 hours\n",
      "Training at Epoch 18 iteration 1700 with loss 0.09919. Total time 5.59361 hours\n",
      "Training at Epoch 18 iteration 1800 with loss 0.08495. Total time 5.60138 hours\n",
      "Training at Epoch 18 iteration 1900 with loss 0.08647. Total time 5.60916 hours\n",
      "Training at Epoch 18 iteration 2000 with loss 0.08990. Total time 5.61694 hours\n",
      "Training at Epoch 18 iteration 2100 with loss 0.07315. Total time 5.625 hours\n",
      "Training at Epoch 18 iteration 2200 with loss 0.13330. Total time 5.63277 hours\n",
      "Training at Epoch 18 iteration 2300 with loss 0.12483. Total time 5.64083 hours\n",
      "Training at Epoch 18 iteration 2400 with loss 0.09048. Total time 5.64861 hours\n",
      "Training at Epoch 18 iteration 2500 with loss 0.13054. Total time 5.65666 hours\n",
      "Training at Epoch 18 iteration 2600 with loss 0.06946. Total time 5.66444 hours\n",
      "Training at Epoch 18 iteration 2700 with loss 0.10444. Total time 5.67222 hours\n",
      "Training at Epoch 18 iteration 2800 with loss 0.08848. Total time 5.68 hours\n",
      "Training at Epoch 18 iteration 2900 with loss 0.11434. Total time 5.68777 hours\n",
      "Training at Epoch 18 iteration 3000 with loss 0.07645. Total time 5.69555 hours\n",
      "Training at Epoch 18 iteration 3100 with loss 0.12792. Total time 5.70333 hours\n",
      "Training at Epoch 18 iteration 3200 with loss 0.08929. Total time 5.71138 hours\n",
      "Training at Epoch 18 iteration 3300 with loss 0.11413. Total time 5.71916 hours\n",
      "Training at Epoch 18 iteration 3400 with loss 0.11702. Total time 5.72694 hours\n",
      "Training at Epoch 18 iteration 3500 with loss 0.10227. Total time 5.73472 hours\n",
      "Validation at Epoch 18, AUROC: 0.93251 , AUPRC: 0.84244 , F1: 0.76639 , Cross-entropy Loss: 3.91594\n",
      "Training at Epoch 19 iteration 0 with loss 0.07851. Total time 5.78166 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.06871. Total time 5.78944 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.09106. Total time 5.7975 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.08066. Total time 5.80527 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.10470. Total time 5.81277 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.12257. Total time 5.82083 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.07841. Total time 5.82833 hours\n",
      "Training at Epoch 19 iteration 700 with loss 0.09487. Total time 5.83611 hours\n",
      "Training at Epoch 19 iteration 800 with loss 0.08685. Total time 5.84416 hours\n",
      "Training at Epoch 19 iteration 900 with loss 0.09994. Total time 5.85194 hours\n",
      "Training at Epoch 19 iteration 1000 with loss 0.12180. Total time 5.85972 hours\n",
      "Training at Epoch 19 iteration 1100 with loss 0.14331. Total time 5.86777 hours\n",
      "Training at Epoch 19 iteration 1200 with loss 0.09918. Total time 5.87555 hours\n",
      "Training at Epoch 19 iteration 1300 with loss 0.07380. Total time 5.88333 hours\n",
      "Training at Epoch 19 iteration 1400 with loss 0.08264. Total time 5.89111 hours\n",
      "Training at Epoch 19 iteration 1500 with loss 0.06810. Total time 5.89888 hours\n",
      "Training at Epoch 19 iteration 1600 with loss 0.08211. Total time 5.90694 hours\n",
      "Training at Epoch 19 iteration 1700 with loss 0.10025. Total time 5.91472 hours\n",
      "Training at Epoch 19 iteration 1800 with loss 0.11451. Total time 5.9225 hours\n",
      "Training at Epoch 19 iteration 1900 with loss 0.10120. Total time 5.93027 hours\n",
      "Training at Epoch 19 iteration 2000 with loss 0.11681. Total time 5.93805 hours\n",
      "Training at Epoch 19 iteration 2100 with loss 0.08891. Total time 5.94583 hours\n",
      "Training at Epoch 19 iteration 2200 with loss 0.09287. Total time 5.95361 hours\n",
      "Training at Epoch 19 iteration 2300 with loss 0.11453. Total time 5.96166 hours\n",
      "Training at Epoch 19 iteration 2400 with loss 0.05892. Total time 5.96944 hours\n",
      "Training at Epoch 19 iteration 2500 with loss 0.10275. Total time 5.97722 hours\n",
      "Training at Epoch 19 iteration 2600 with loss 0.08931. Total time 5.985 hours\n",
      "Training at Epoch 19 iteration 2700 with loss 0.08009. Total time 5.99277 hours\n",
      "Training at Epoch 19 iteration 2800 with loss 0.08663. Total time 6.00055 hours\n",
      "Training at Epoch 19 iteration 2900 with loss 0.11802. Total time 6.00833 hours\n",
      "Training at Epoch 19 iteration 3000 with loss 0.11721. Total time 6.01611 hours\n",
      "Training at Epoch 19 iteration 3100 with loss 0.11692. Total time 6.02388 hours\n",
      "Training at Epoch 19 iteration 3200 with loss 0.16022. Total time 6.03166 hours\n",
      "Training at Epoch 19 iteration 3300 with loss 0.11513. Total time 6.03972 hours\n",
      "Training at Epoch 19 iteration 3400 with loss 0.08667. Total time 6.0475 hours\n",
      "Training at Epoch 19 iteration 3500 with loss 0.09003. Total time 6.05527 hours\n",
      "Validation at Epoch 19, AUROC: 0.93368 , AUPRC: 0.84414 , F1: 0.76699 , Cross-entropy Loss: 3.89985\n",
      "Training at Epoch 20 iteration 0 with loss 0.07023. Total time 6.10305 hours\n",
      "Training at Epoch 20 iteration 100 with loss 0.06197. Total time 6.11083 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.04971. Total time 6.11861 hours\n",
      "Training at Epoch 20 iteration 300 with loss 0.08335. Total time 6.12638 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.11261. Total time 6.13444 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.08490. Total time 6.14222 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.09068. Total time 6.15 hours\n",
      "Training at Epoch 20 iteration 700 with loss 0.10503. Total time 6.15777 hours\n",
      "Training at Epoch 20 iteration 800 with loss 0.11358. Total time 6.16555 hours\n",
      "Training at Epoch 20 iteration 900 with loss 0.10184. Total time 6.17333 hours\n",
      "Training at Epoch 20 iteration 1000 with loss 0.05496. Total time 6.18138 hours\n",
      "Training at Epoch 20 iteration 1100 with loss 0.05831. Total time 6.18916 hours\n",
      "Training at Epoch 20 iteration 1200 with loss 0.08346. Total time 6.19694 hours\n",
      "Training at Epoch 20 iteration 1300 with loss 0.09031. Total time 6.20472 hours\n",
      "Training at Epoch 20 iteration 1400 with loss 0.07613. Total time 6.2125 hours\n",
      "Training at Epoch 20 iteration 1500 with loss 0.09596. Total time 6.22055 hours\n",
      "Training at Epoch 20 iteration 1600 with loss 0.05280. Total time 6.22833 hours\n",
      "Training at Epoch 20 iteration 1700 with loss 0.08810. Total time 6.23638 hours\n",
      "Training at Epoch 20 iteration 1800 with loss 0.14329. Total time 6.24444 hours\n",
      "Training at Epoch 20 iteration 1900 with loss 0.09286. Total time 6.25222 hours\n",
      "Training at Epoch 20 iteration 2000 with loss 0.10858. Total time 6.26027 hours\n",
      "Training at Epoch 20 iteration 2100 with loss 0.09514. Total time 6.26805 hours\n",
      "Training at Epoch 20 iteration 2200 with loss 0.11350. Total time 6.27583 hours\n",
      "Training at Epoch 20 iteration 2300 with loss 0.13560. Total time 6.28388 hours\n",
      "Training at Epoch 20 iteration 2400 with loss 0.10086. Total time 6.29166 hours\n",
      "Training at Epoch 20 iteration 2500 with loss 0.13224. Total time 6.29972 hours\n",
      "Training at Epoch 20 iteration 2600 with loss 0.09790. Total time 6.3075 hours\n",
      "Training at Epoch 20 iteration 2700 with loss 0.13626. Total time 6.31527 hours\n",
      "Training at Epoch 20 iteration 2800 with loss 0.13159. Total time 6.32305 hours\n",
      "Training at Epoch 20 iteration 2900 with loss 0.14503. Total time 6.33111 hours\n",
      "Training at Epoch 20 iteration 3000 with loss 0.07061. Total time 6.33888 hours\n",
      "Training at Epoch 20 iteration 3100 with loss 0.10802. Total time 6.34666 hours\n",
      "Training at Epoch 20 iteration 3200 with loss 0.11013. Total time 6.35444 hours\n",
      "Training at Epoch 20 iteration 3300 with loss 0.07655. Total time 6.3625 hours\n",
      "Training at Epoch 20 iteration 3400 with loss 0.06133. Total time 6.37027 hours\n",
      "Training at Epoch 20 iteration 3500 with loss 0.07347. Total time 6.37805 hours\n",
      "Validation at Epoch 20, AUROC: 0.93237 , AUPRC: 0.84219 , F1: 0.76712 , Cross-entropy Loss: 3.87347\n",
      "Training at Epoch 21 iteration 0 with loss 0.08692. Total time 6.42527 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.05934. Total time 6.43333 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.09401. Total time 6.44111 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.09854. Total time 6.44888 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.11174. Total time 6.45694 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.08522. Total time 6.46472 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.11771. Total time 6.4725 hours\n",
      "Training at Epoch 21 iteration 700 with loss 0.10076. Total time 6.48055 hours\n",
      "Training at Epoch 21 iteration 800 with loss 0.10490. Total time 6.48833 hours\n",
      "Training at Epoch 21 iteration 900 with loss 0.06098. Total time 6.49611 hours\n",
      "Training at Epoch 21 iteration 1000 with loss 0.07206. Total time 6.50388 hours\n",
      "Training at Epoch 21 iteration 1100 with loss 0.08238. Total time 6.51166 hours\n",
      "Training at Epoch 21 iteration 1200 with loss 0.13731. Total time 6.51972 hours\n",
      "Training at Epoch 21 iteration 1300 with loss 0.10359. Total time 6.5275 hours\n",
      "Training at Epoch 21 iteration 1400 with loss 0.12540. Total time 6.53527 hours\n",
      "Training at Epoch 21 iteration 1500 with loss 0.09849. Total time 6.54305 hours\n",
      "Training at Epoch 21 iteration 1600 with loss 0.07106. Total time 6.55083 hours\n",
      "Training at Epoch 21 iteration 1700 with loss 0.08680. Total time 6.55888 hours\n",
      "Training at Epoch 21 iteration 1800 with loss 0.14146. Total time 6.56666 hours\n",
      "Training at Epoch 21 iteration 1900 with loss 0.12425. Total time 6.57444 hours\n",
      "Training at Epoch 21 iteration 2000 with loss 0.09604. Total time 6.58222 hours\n",
      "Training at Epoch 21 iteration 2100 with loss 0.06652. Total time 6.59 hours\n",
      "Training at Epoch 21 iteration 2200 with loss 0.10583. Total time 6.59777 hours\n",
      "Training at Epoch 21 iteration 2300 with loss 0.09218. Total time 6.60583 hours\n",
      "Training at Epoch 21 iteration 2400 with loss 0.07820. Total time 6.61361 hours\n",
      "Training at Epoch 21 iteration 2500 with loss 0.08077. Total time 6.62138 hours\n",
      "Training at Epoch 21 iteration 2600 with loss 0.09983. Total time 6.62916 hours\n",
      "Training at Epoch 21 iteration 2700 with loss 0.13045. Total time 6.63694 hours\n",
      "Training at Epoch 21 iteration 2800 with loss 0.06818. Total time 6.645 hours\n",
      "Training at Epoch 21 iteration 2900 with loss 0.09767. Total time 6.65277 hours\n",
      "Training at Epoch 21 iteration 3000 with loss 0.09371. Total time 6.66055 hours\n",
      "Training at Epoch 21 iteration 3100 with loss 0.08170. Total time 6.66833 hours\n",
      "Training at Epoch 21 iteration 3200 with loss 0.09117. Total time 6.67611 hours\n",
      "Training at Epoch 21 iteration 3300 with loss 0.09628. Total time 6.68388 hours\n",
      "Training at Epoch 21 iteration 3400 with loss 0.10901. Total time 6.69166 hours\n",
      "Training at Epoch 21 iteration 3500 with loss 0.13330. Total time 6.69972 hours\n",
      "Validation at Epoch 21, AUROC: 0.93281 , AUPRC: 0.84361 , F1: 0.77035 , Cross-entropy Loss: 3.90328\n",
      "Training at Epoch 22 iteration 0 with loss 0.08638. Total time 6.74694 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.05041. Total time 6.75472 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.08599. Total time 6.7625 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.11234. Total time 6.77027 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.08781. Total time 6.77805 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.09818. Total time 6.78583 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.07083. Total time 6.79388 hours\n",
      "Training at Epoch 22 iteration 700 with loss 0.09245. Total time 6.80166 hours\n",
      "Training at Epoch 22 iteration 800 with loss 0.07471. Total time 6.80944 hours\n",
      "Training at Epoch 22 iteration 900 with loss 0.12314. Total time 6.81722 hours\n",
      "Training at Epoch 22 iteration 1000 with loss 0.13597. Total time 6.82527 hours\n",
      "Training at Epoch 22 iteration 1100 with loss 0.09752. Total time 6.83305 hours\n",
      "Training at Epoch 22 iteration 1200 with loss 0.15145. Total time 6.84083 hours\n",
      "Training at Epoch 22 iteration 1300 with loss 0.14746. Total time 6.84861 hours\n",
      "Training at Epoch 22 iteration 1400 with loss 0.49203. Total time 6.85666 hours\n",
      "Training at Epoch 22 iteration 1500 with loss 0.10252. Total time 6.86444 hours\n",
      "Training at Epoch 22 iteration 1600 with loss 0.07030. Total time 6.87222 hours\n",
      "Training at Epoch 22 iteration 1700 with loss 0.10112. Total time 6.88 hours\n",
      "Training at Epoch 22 iteration 1800 with loss 0.08536. Total time 6.88777 hours\n",
      "Training at Epoch 22 iteration 1900 with loss 0.08690. Total time 6.89583 hours\n",
      "Training at Epoch 22 iteration 2000 with loss 0.14323. Total time 6.90361 hours\n",
      "Training at Epoch 22 iteration 2100 with loss 0.05782. Total time 6.91138 hours\n",
      "Training at Epoch 22 iteration 2200 with loss 0.10428. Total time 6.91916 hours\n",
      "Training at Epoch 22 iteration 2300 with loss 0.13700. Total time 6.92694 hours\n",
      "Training at Epoch 22 iteration 2400 with loss 0.11154. Total time 6.935 hours\n",
      "Training at Epoch 22 iteration 2500 with loss 0.10415. Total time 6.94277 hours\n",
      "Training at Epoch 22 iteration 2600 with loss 0.11118. Total time 6.95055 hours\n",
      "Training at Epoch 22 iteration 2700 with loss 0.09464. Total time 6.95833 hours\n",
      "Training at Epoch 22 iteration 2800 with loss 0.09038. Total time 6.96611 hours\n",
      "Training at Epoch 22 iteration 2900 with loss 0.14886. Total time 6.97388 hours\n",
      "Training at Epoch 22 iteration 3000 with loss 0.10889. Total time 6.98166 hours\n",
      "Training at Epoch 22 iteration 3100 with loss 0.07583. Total time 6.98944 hours\n",
      "Training at Epoch 22 iteration 3200 with loss 0.13242. Total time 6.9975 hours\n",
      "Training at Epoch 22 iteration 3300 with loss 0.09971. Total time 7.00527 hours\n",
      "Training at Epoch 22 iteration 3400 with loss 0.09552. Total time 7.01305 hours\n",
      "Training at Epoch 22 iteration 3500 with loss 0.11599. Total time 7.02083 hours\n",
      "Validation at Epoch 22, AUROC: 0.93257 , AUPRC: 0.84211 , F1: 0.76913 , Cross-entropy Loss: 3.93256\n",
      "Training at Epoch 23 iteration 0 with loss 0.08927. Total time 7.06805 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.06337. Total time 7.07583 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.15406. Total time 7.08361 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.07065. Total time 7.09138 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.06860. Total time 7.09916 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.12353. Total time 7.10694 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.07943. Total time 7.11472 hours\n",
      "Training at Epoch 23 iteration 700 with loss 0.14585. Total time 7.12277 hours\n",
      "Training at Epoch 23 iteration 800 with loss 0.06835. Total time 7.13055 hours\n",
      "Training at Epoch 23 iteration 900 with loss 0.04390. Total time 7.13833 hours\n",
      "Training at Epoch 23 iteration 1000 with loss 0.07135. Total time 7.14611 hours\n",
      "Training at Epoch 23 iteration 1100 with loss 0.07304. Total time 7.15388 hours\n",
      "Training at Epoch 23 iteration 1200 with loss 0.07979. Total time 7.16166 hours\n",
      "Training at Epoch 23 iteration 1300 with loss 0.09187. Total time 7.16944 hours\n",
      "Training at Epoch 23 iteration 1400 with loss 0.09738. Total time 7.17722 hours\n",
      "Training at Epoch 23 iteration 1500 with loss 0.09657. Total time 7.185 hours\n",
      "Training at Epoch 23 iteration 1600 with loss 0.08796. Total time 7.19277 hours\n",
      "Training at Epoch 23 iteration 1700 with loss 0.11293. Total time 7.20055 hours\n",
      "Training at Epoch 23 iteration 1800 with loss 0.08305. Total time 7.20861 hours\n",
      "Training at Epoch 23 iteration 1900 with loss 0.08939. Total time 7.21638 hours\n",
      "Training at Epoch 23 iteration 2000 with loss 0.06721. Total time 7.22416 hours\n",
      "Training at Epoch 23 iteration 2100 with loss 0.12415. Total time 7.23194 hours\n",
      "Training at Epoch 23 iteration 2200 with loss 0.05987. Total time 7.23972 hours\n",
      "Training at Epoch 23 iteration 2300 with loss 0.14982. Total time 7.2475 hours\n",
      "Training at Epoch 23 iteration 2400 with loss 0.09013. Total time 7.25527 hours\n",
      "Training at Epoch 23 iteration 2500 with loss 0.08572. Total time 7.26305 hours\n",
      "Training at Epoch 23 iteration 2600 with loss 0.07511. Total time 7.27083 hours\n",
      "Training at Epoch 23 iteration 2700 with loss 0.08695. Total time 7.27861 hours\n",
      "Training at Epoch 23 iteration 2800 with loss 0.10283. Total time 7.28666 hours\n",
      "Training at Epoch 23 iteration 2900 with loss 0.12602. Total time 7.29444 hours\n",
      "Training at Epoch 23 iteration 3000 with loss 0.08443. Total time 7.30222 hours\n",
      "Training at Epoch 23 iteration 3100 with loss 0.11834. Total time 7.31 hours\n",
      "Training at Epoch 23 iteration 3200 with loss 0.06476. Total time 7.31777 hours\n",
      "Training at Epoch 23 iteration 3300 with loss 0.07549. Total time 7.32555 hours\n",
      "Training at Epoch 23 iteration 3400 with loss 0.09538. Total time 7.33333 hours\n",
      "Training at Epoch 23 iteration 3500 with loss 0.09269. Total time 7.34111 hours\n",
      "Validation at Epoch 23, AUROC: 0.93436 , AUPRC: 0.84378 , F1: 0.77256 , Cross-entropy Loss: 3.88376\n",
      "Training at Epoch 24 iteration 0 with loss 0.09750. Total time 7.38861 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.06752. Total time 7.39638 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.09340. Total time 7.40416 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.07342. Total time 7.41194 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.07651. Total time 7.41972 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.11811. Total time 7.4275 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.06588. Total time 7.43555 hours\n",
      "Training at Epoch 24 iteration 700 with loss 0.05428. Total time 7.44333 hours\n",
      "Training at Epoch 24 iteration 800 with loss 0.08292. Total time 7.45111 hours\n",
      "Training at Epoch 24 iteration 900 with loss 0.07198. Total time 7.45888 hours\n",
      "Training at Epoch 24 iteration 1000 with loss 0.08728. Total time 7.46666 hours\n",
      "Training at Epoch 24 iteration 1100 with loss 0.08332. Total time 7.47444 hours\n",
      "Training at Epoch 24 iteration 1200 with loss 0.08767. Total time 7.48222 hours\n",
      "Training at Epoch 24 iteration 1300 with loss 0.08656. Total time 7.49 hours\n",
      "Training at Epoch 24 iteration 1400 with loss 0.09141. Total time 7.49777 hours\n",
      "Training at Epoch 24 iteration 1500 with loss 0.10389. Total time 7.50555 hours\n",
      "Training at Epoch 24 iteration 1600 with loss 0.10058. Total time 7.51361 hours\n",
      "Training at Epoch 24 iteration 1700 with loss 0.09534. Total time 7.52138 hours\n",
      "Training at Epoch 24 iteration 1800 with loss 0.08294. Total time 7.52916 hours\n",
      "Training at Epoch 24 iteration 1900 with loss 0.07280. Total time 7.53694 hours\n",
      "Training at Epoch 24 iteration 2000 with loss 0.10667. Total time 7.54472 hours\n",
      "Training at Epoch 24 iteration 2100 with loss 0.06958. Total time 7.5525 hours\n",
      "Training at Epoch 24 iteration 2200 with loss 0.12769. Total time 7.56027 hours\n",
      "Training at Epoch 24 iteration 2300 with loss 0.06206. Total time 7.56833 hours\n",
      "Training at Epoch 24 iteration 2400 with loss 0.07428. Total time 7.57611 hours\n",
      "Training at Epoch 24 iteration 2500 with loss 0.09229. Total time 7.58388 hours\n",
      "Training at Epoch 24 iteration 2600 with loss 0.07705. Total time 7.59166 hours\n",
      "Training at Epoch 24 iteration 2700 with loss 0.06805. Total time 7.59944 hours\n",
      "Training at Epoch 24 iteration 2800 with loss 0.10755. Total time 7.60722 hours\n",
      "Training at Epoch 24 iteration 2900 with loss 0.10279. Total time 7.615 hours\n",
      "Training at Epoch 24 iteration 3000 with loss 0.08525. Total time 7.62277 hours\n",
      "Training at Epoch 24 iteration 3100 with loss 0.09515. Total time 7.63055 hours\n",
      "Training at Epoch 24 iteration 3200 with loss 0.07555. Total time 7.63833 hours\n",
      "Training at Epoch 24 iteration 3300 with loss 0.06316. Total time 7.64638 hours\n",
      "Training at Epoch 24 iteration 3400 with loss 0.07624. Total time 7.65416 hours\n",
      "Training at Epoch 24 iteration 3500 with loss 0.10166. Total time 7.66194 hours\n",
      "Validation at Epoch 24, AUROC: 0.93391 , AUPRC: 0.84386 , F1: 0.77337 , Cross-entropy Loss: 3.86002\n",
      "Training at Epoch 25 iteration 0 with loss 0.10165. Total time 7.70888 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.04521. Total time 7.71666 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.08967. Total time 7.72472 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.08557. Total time 7.7325 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.07405. Total time 7.74027 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.08600. Total time 7.74805 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.11941. Total time 7.75583 hours\n",
      "Training at Epoch 25 iteration 700 with loss 0.12332. Total time 7.76361 hours\n",
      "Training at Epoch 25 iteration 800 with loss 0.09561. Total time 7.77138 hours\n",
      "Training at Epoch 25 iteration 900 with loss 0.09421. Total time 7.77944 hours\n",
      "Training at Epoch 25 iteration 1000 with loss 0.09472. Total time 7.7875 hours\n",
      "Training at Epoch 25 iteration 1100 with loss 0.05673. Total time 7.79527 hours\n",
      "Training at Epoch 25 iteration 1200 with loss 0.07142. Total time 7.80305 hours\n",
      "Training at Epoch 25 iteration 1300 with loss 0.06242. Total time 7.81083 hours\n",
      "Training at Epoch 25 iteration 1400 with loss 0.04779. Total time 7.81861 hours\n",
      "Training at Epoch 25 iteration 1500 with loss 0.09122. Total time 7.82638 hours\n",
      "Training at Epoch 25 iteration 1600 with loss 0.05683. Total time 7.83416 hours\n",
      "Training at Epoch 25 iteration 1700 with loss 0.10274. Total time 7.84222 hours\n",
      "Training at Epoch 25 iteration 1800 with loss 0.08183. Total time 7.85 hours\n",
      "Training at Epoch 25 iteration 1900 with loss 0.06630. Total time 7.85777 hours\n",
      "Training at Epoch 25 iteration 2000 with loss 0.10173. Total time 7.86555 hours\n",
      "Training at Epoch 25 iteration 2100 with loss 0.06280. Total time 7.87333 hours\n",
      "Training at Epoch 25 iteration 2200 with loss 0.09533. Total time 7.88111 hours\n",
      "Training at Epoch 25 iteration 2300 with loss 0.08988. Total time 7.88916 hours\n",
      "Training at Epoch 25 iteration 2400 with loss 0.08364. Total time 7.89694 hours\n",
      "Training at Epoch 25 iteration 2500 with loss 0.08364. Total time 7.90472 hours\n",
      "Training at Epoch 25 iteration 2600 with loss 0.10082. Total time 7.9125 hours\n",
      "Training at Epoch 25 iteration 2700 with loss 0.07455. Total time 7.92055 hours\n",
      "Training at Epoch 25 iteration 2800 with loss 0.07213. Total time 7.92833 hours\n",
      "Training at Epoch 25 iteration 2900 with loss 0.07709. Total time 7.93611 hours\n",
      "Training at Epoch 25 iteration 3000 with loss 0.08113. Total time 7.94388 hours\n",
      "Training at Epoch 25 iteration 3100 with loss 0.06778. Total time 7.95194 hours\n",
      "Training at Epoch 25 iteration 3200 with loss 0.10833. Total time 7.95972 hours\n",
      "Training at Epoch 25 iteration 3300 with loss 0.07000. Total time 7.9675 hours\n",
      "Training at Epoch 25 iteration 3400 with loss 0.09680. Total time 7.97527 hours\n",
      "Training at Epoch 25 iteration 3500 with loss 0.09688. Total time 7.98305 hours\n",
      "Validation at Epoch 25, AUROC: 0.93311 , AUPRC: 0.84295 , F1: 0.77340 , Cross-entropy Loss: 3.87268\n",
      "Training at Epoch 26 iteration 0 with loss 0.07204. Total time 8.03027 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.07261. Total time 8.03805 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.05860. Total time 8.04611 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.07582. Total time 8.05388 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.09013. Total time 8.06166 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.08065. Total time 8.06972 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.05248. Total time 8.0775 hours\n",
      "Training at Epoch 26 iteration 700 with loss 0.07039. Total time 8.08555 hours\n",
      "Training at Epoch 26 iteration 800 with loss 0.07079. Total time 8.09333 hours\n",
      "Training at Epoch 26 iteration 900 with loss 0.08005. Total time 8.10111 hours\n",
      "Training at Epoch 26 iteration 1000 with loss 0.06475. Total time 8.10888 hours\n",
      "Training at Epoch 26 iteration 1100 with loss 0.06577. Total time 8.11666 hours\n",
      "Training at Epoch 26 iteration 1200 with loss 0.10976. Total time 8.12444 hours\n",
      "Training at Epoch 26 iteration 1300 with loss 0.10281. Total time 8.1325 hours\n",
      "Training at Epoch 26 iteration 1400 with loss 0.05460. Total time 8.14027 hours\n",
      "Training at Epoch 26 iteration 1500 with loss 0.05698. Total time 8.14805 hours\n",
      "Training at Epoch 26 iteration 1600 with loss 0.11399. Total time 8.15611 hours\n",
      "Training at Epoch 26 iteration 1700 with loss 0.11985. Total time 8.16416 hours\n",
      "Training at Epoch 26 iteration 1800 with loss 0.11059. Total time 8.17194 hours\n",
      "Training at Epoch 26 iteration 1900 with loss 0.05975. Total time 8.17972 hours\n",
      "Training at Epoch 26 iteration 2000 with loss 0.06744. Total time 8.1875 hours\n",
      "Training at Epoch 26 iteration 2100 with loss 0.09188. Total time 8.19555 hours\n",
      "Training at Epoch 26 iteration 2200 with loss 0.08619. Total time 8.20333 hours\n",
      "Training at Epoch 26 iteration 2300 with loss 0.11542. Total time 8.21111 hours\n",
      "Training at Epoch 26 iteration 2400 with loss 0.08055. Total time 8.21888 hours\n",
      "Training at Epoch 26 iteration 2500 with loss 0.10761. Total time 8.22666 hours\n",
      "Training at Epoch 26 iteration 2600 with loss 0.10068. Total time 8.23444 hours\n",
      "Training at Epoch 26 iteration 2700 with loss 0.09698. Total time 8.24222 hours\n",
      "Training at Epoch 26 iteration 2800 with loss 0.07994. Total time 8.25027 hours\n",
      "Training at Epoch 26 iteration 2900 with loss 0.06359. Total time 8.25805 hours\n",
      "Training at Epoch 26 iteration 3000 with loss 0.08320. Total time 8.26583 hours\n",
      "Training at Epoch 26 iteration 3100 with loss 0.12828. Total time 8.27388 hours\n",
      "Training at Epoch 26 iteration 3200 with loss 0.09049. Total time 8.28166 hours\n",
      "Training at Epoch 26 iteration 3300 with loss 0.13139. Total time 8.28972 hours\n",
      "Training at Epoch 26 iteration 3400 with loss 0.11420. Total time 8.29777 hours\n",
      "Training at Epoch 26 iteration 3500 with loss 0.12554. Total time 8.30555 hours\n",
      "Validation at Epoch 26, AUROC: 0.93276 , AUPRC: 0.84209 , F1: 0.77174 , Cross-entropy Loss: 3.84471\n",
      "Training at Epoch 27 iteration 0 with loss 0.06526. Total time 8.35361 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.07231. Total time 8.36166 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.07025. Total time 8.36944 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.07274. Total time 8.3775 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.05550. Total time 8.38527 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.04957. Total time 8.39305 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.14247. Total time 8.40111 hours\n",
      "Training at Epoch 27 iteration 700 with loss 0.05037. Total time 8.40888 hours\n",
      "Training at Epoch 27 iteration 800 with loss 0.10410. Total time 8.41666 hours\n",
      "Training at Epoch 27 iteration 900 with loss 0.13302. Total time 8.42444 hours\n",
      "Training at Epoch 27 iteration 1000 with loss 0.08594. Total time 8.43222 hours\n",
      "Training at Epoch 27 iteration 1100 with loss 0.07486. Total time 8.44 hours\n",
      "Training at Epoch 27 iteration 1200 with loss 0.07807. Total time 8.44805 hours\n",
      "Training at Epoch 27 iteration 1300 with loss 0.08694. Total time 8.45583 hours\n",
      "Training at Epoch 27 iteration 1400 with loss 0.09474. Total time 8.46361 hours\n",
      "Training at Epoch 27 iteration 1500 with loss 0.08717. Total time 8.47138 hours\n",
      "Training at Epoch 27 iteration 1600 with loss 0.08502. Total time 8.47916 hours\n",
      "Training at Epoch 27 iteration 1700 with loss 0.05333. Total time 8.48694 hours\n",
      "Training at Epoch 27 iteration 1800 with loss 0.06743. Total time 8.49472 hours\n",
      "Training at Epoch 27 iteration 1900 with loss 0.09290. Total time 8.5025 hours\n",
      "Training at Epoch 27 iteration 2000 with loss 0.10219. Total time 8.51055 hours\n",
      "Training at Epoch 27 iteration 2100 with loss 0.09718. Total time 8.51833 hours\n",
      "Training at Epoch 27 iteration 2200 with loss 0.07269. Total time 8.52611 hours\n",
      "Training at Epoch 27 iteration 2300 with loss 0.13013. Total time 8.53388 hours\n",
      "Training at Epoch 27 iteration 2400 with loss 0.10462. Total time 8.54166 hours\n",
      "Training at Epoch 27 iteration 2500 with loss 0.10024. Total time 8.54944 hours\n",
      "Training at Epoch 27 iteration 2600 with loss 0.06576. Total time 8.55722 hours\n",
      "Training at Epoch 27 iteration 2700 with loss 0.11552. Total time 8.565 hours\n",
      "Training at Epoch 27 iteration 2800 with loss 0.06829. Total time 8.57305 hours\n",
      "Training at Epoch 27 iteration 2900 with loss 0.05436. Total time 8.58083 hours\n",
      "Training at Epoch 27 iteration 3000 with loss 0.10992. Total time 8.58861 hours\n",
      "Training at Epoch 27 iteration 3100 with loss 0.08424. Total time 8.59638 hours\n",
      "Training at Epoch 27 iteration 3200 with loss 0.08897. Total time 8.60416 hours\n",
      "Training at Epoch 27 iteration 3300 with loss 0.08326. Total time 8.61194 hours\n",
      "Training at Epoch 27 iteration 3400 with loss 0.12818. Total time 8.61972 hours\n",
      "Training at Epoch 27 iteration 3500 with loss 0.12006. Total time 8.6275 hours\n",
      "Validation at Epoch 27, AUROC: 0.93330 , AUPRC: 0.84088 , F1: 0.76546 , Cross-entropy Loss: 3.89510\n",
      "Training at Epoch 28 iteration 0 with loss 0.06923. Total time 8.675 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.04857. Total time 8.68277 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.05555. Total time 8.69055 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.09111. Total time 8.69833 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.08872. Total time 8.70611 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.06886. Total time 8.71388 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.09296. Total time 8.72194 hours\n",
      "Training at Epoch 28 iteration 700 with loss 0.06188. Total time 8.72972 hours\n",
      "Training at Epoch 28 iteration 800 with loss 0.06820. Total time 8.7375 hours\n",
      "Training at Epoch 28 iteration 900 with loss 0.10152. Total time 8.74527 hours\n",
      "Training at Epoch 28 iteration 1000 with loss 0.07629. Total time 8.75305 hours\n",
      "Training at Epoch 28 iteration 1100 with loss 0.09799. Total time 8.76111 hours\n",
      "Training at Epoch 28 iteration 1200 with loss 0.07349. Total time 8.76888 hours\n",
      "Training at Epoch 28 iteration 1300 with loss 0.10151. Total time 8.77666 hours\n",
      "Training at Epoch 28 iteration 1400 with loss 0.08029. Total time 8.78444 hours\n",
      "Training at Epoch 28 iteration 1500 with loss 0.10603. Total time 8.7925 hours\n",
      "Training at Epoch 28 iteration 1600 with loss 0.06381. Total time 8.80027 hours\n",
      "Training at Epoch 28 iteration 1700 with loss 0.05175. Total time 8.80805 hours\n",
      "Training at Epoch 28 iteration 1800 with loss 0.07610. Total time 8.81583 hours\n",
      "Training at Epoch 28 iteration 1900 with loss 0.07748. Total time 8.82361 hours\n",
      "Training at Epoch 28 iteration 2000 with loss 0.08624. Total time 8.83166 hours\n",
      "Training at Epoch 28 iteration 2100 with loss 0.05453. Total time 8.83944 hours\n",
      "Training at Epoch 28 iteration 2200 with loss 0.09650. Total time 8.84722 hours\n",
      "Training at Epoch 28 iteration 2300 with loss 0.09932. Total time 8.855 hours\n",
      "Training at Epoch 28 iteration 2400 with loss 0.09814. Total time 8.86305 hours\n",
      "Training at Epoch 28 iteration 2500 with loss 0.10401. Total time 8.87083 hours\n",
      "Training at Epoch 28 iteration 2600 with loss 0.06544. Total time 8.87861 hours\n",
      "Training at Epoch 28 iteration 2700 with loss 0.08271. Total time 8.88638 hours\n",
      "Training at Epoch 28 iteration 2800 with loss 0.10560. Total time 8.89444 hours\n",
      "Training at Epoch 28 iteration 2900 with loss 0.07769. Total time 8.90222 hours\n",
      "Training at Epoch 28 iteration 3000 with loss 0.08327. Total time 8.91 hours\n",
      "Training at Epoch 28 iteration 3100 with loss 0.09167. Total time 8.91805 hours\n",
      "Training at Epoch 28 iteration 3200 with loss 0.10050. Total time 8.92583 hours\n",
      "Training at Epoch 28 iteration 3300 with loss 0.07376. Total time 8.93361 hours\n",
      "Training at Epoch 28 iteration 3400 with loss 0.08585. Total time 8.94138 hours\n",
      "Training at Epoch 28 iteration 3500 with loss 0.14313. Total time 8.94944 hours\n",
      "Validation at Epoch 28, AUROC: 0.93248 , AUPRC: 0.84289 , F1: 0.77102 , Cross-entropy Loss: 3.86054\n",
      "Training at Epoch 29 iteration 0 with loss 0.05949. Total time 8.99722 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.06267. Total time 9.005 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.05425. Total time 9.01277 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.07788. Total time 9.02055 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.07085. Total time 9.02861 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.06941. Total time 9.03638 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.08831. Total time 9.04416 hours\n",
      "Training at Epoch 29 iteration 700 with loss 0.07397. Total time 9.05194 hours\n",
      "Training at Epoch 29 iteration 800 with loss 0.10948. Total time 9.05972 hours\n",
      "Training at Epoch 29 iteration 900 with loss 0.11045. Total time 9.06777 hours\n",
      "Training at Epoch 29 iteration 1000 with loss 0.06394. Total time 9.07555 hours\n",
      "Training at Epoch 29 iteration 1100 with loss 0.07930. Total time 9.08333 hours\n",
      "Training at Epoch 29 iteration 1200 with loss 0.05834. Total time 9.09111 hours\n",
      "Training at Epoch 29 iteration 1300 with loss 0.08252. Total time 9.09888 hours\n",
      "Training at Epoch 29 iteration 1400 with loss 0.09152. Total time 9.10694 hours\n",
      "Training at Epoch 29 iteration 1500 with loss 0.07401. Total time 9.11472 hours\n",
      "Training at Epoch 29 iteration 1600 with loss 0.07442. Total time 9.1225 hours\n",
      "Training at Epoch 29 iteration 1700 with loss 0.06095. Total time 9.13027 hours\n",
      "Training at Epoch 29 iteration 1800 with loss 0.07413. Total time 9.13805 hours\n",
      "Training at Epoch 29 iteration 1900 with loss 0.09181. Total time 9.14583 hours\n",
      "Training at Epoch 29 iteration 2000 with loss 0.11327. Total time 9.15388 hours\n",
      "Training at Epoch 29 iteration 2100 with loss 0.08186. Total time 9.16166 hours\n",
      "Training at Epoch 29 iteration 2200 with loss 0.08473. Total time 9.16944 hours\n",
      "Training at Epoch 29 iteration 2300 with loss 0.08774. Total time 9.17722 hours\n",
      "Training at Epoch 29 iteration 2400 with loss 0.08073. Total time 9.185 hours\n",
      "Training at Epoch 29 iteration 2500 with loss 0.08593. Total time 9.19305 hours\n",
      "Training at Epoch 29 iteration 2600 with loss 0.07900. Total time 9.20083 hours\n",
      "Training at Epoch 29 iteration 2700 with loss 0.05202. Total time 9.20861 hours\n",
      "Training at Epoch 29 iteration 2800 with loss 0.09540. Total time 9.21638 hours\n",
      "Training at Epoch 29 iteration 2900 with loss 0.12899. Total time 9.22416 hours\n",
      "Training at Epoch 29 iteration 3000 with loss 0.08041. Total time 9.23222 hours\n",
      "Training at Epoch 29 iteration 3100 with loss 0.08414. Total time 9.24 hours\n",
      "Training at Epoch 29 iteration 3200 with loss 0.11373. Total time 9.24777 hours\n",
      "Training at Epoch 29 iteration 3300 with loss 0.06886. Total time 9.25555 hours\n",
      "Training at Epoch 29 iteration 3400 with loss 0.07927. Total time 9.26333 hours\n",
      "Training at Epoch 29 iteration 3500 with loss 0.07427. Total time 9.27138 hours\n",
      "Validation at Epoch 29, AUROC: 0.93410 , AUPRC: 0.84245 , F1: 0.77269 , Cross-entropy Loss: 3.87083\n",
      "Training at Epoch 30 iteration 0 with loss 0.05573. Total time 9.31861 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.05771. Total time 9.32666 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.08420. Total time 9.33444 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.09921. Total time 9.34222 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.09873. Total time 9.35 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.07143. Total time 9.35805 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.09355. Total time 9.36583 hours\n",
      "Training at Epoch 30 iteration 700 with loss 0.04665. Total time 9.37361 hours\n",
      "Training at Epoch 30 iteration 800 with loss 0.12518. Total time 9.38166 hours\n",
      "Training at Epoch 30 iteration 900 with loss 0.08553. Total time 9.38972 hours\n",
      "Training at Epoch 30 iteration 1000 with loss 0.10499. Total time 9.39777 hours\n",
      "Training at Epoch 30 iteration 1100 with loss 0.06798. Total time 9.40583 hours\n",
      "Training at Epoch 30 iteration 1200 with loss 0.09914. Total time 9.41388 hours\n",
      "Training at Epoch 30 iteration 1300 with loss 0.10704. Total time 9.42166 hours\n",
      "Training at Epoch 30 iteration 1400 with loss 0.07614. Total time 9.42944 hours\n",
      "Training at Epoch 30 iteration 1500 with loss 0.09709. Total time 9.43722 hours\n",
      "Training at Epoch 30 iteration 1600 with loss 0.10409. Total time 9.44527 hours\n",
      "Training at Epoch 30 iteration 1700 with loss 0.08691. Total time 9.45305 hours\n",
      "Training at Epoch 30 iteration 1800 with loss 0.07680. Total time 9.46083 hours\n",
      "Training at Epoch 30 iteration 1900 with loss 0.09030. Total time 9.46861 hours\n",
      "Training at Epoch 30 iteration 2000 with loss 0.04966. Total time 9.47666 hours\n",
      "Training at Epoch 30 iteration 2100 with loss 0.10255. Total time 9.48444 hours\n",
      "Training at Epoch 30 iteration 2200 with loss 0.06728. Total time 9.4925 hours\n",
      "Training at Epoch 30 iteration 2300 with loss 0.05092. Total time 9.50027 hours\n",
      "Training at Epoch 30 iteration 2400 with loss 0.10348. Total time 9.50833 hours\n",
      "Training at Epoch 30 iteration 2500 with loss 0.14652. Total time 9.51638 hours\n",
      "Training at Epoch 30 iteration 2600 with loss 0.06128. Total time 9.52416 hours\n",
      "Training at Epoch 30 iteration 2700 with loss 0.05259. Total time 9.53222 hours\n",
      "Training at Epoch 30 iteration 2800 with loss 0.11887. Total time 9.54 hours\n",
      "Training at Epoch 30 iteration 2900 with loss 0.07887. Total time 9.54777 hours\n",
      "Training at Epoch 30 iteration 3000 with loss 0.07603. Total time 9.55555 hours\n",
      "Training at Epoch 30 iteration 3100 with loss 0.09656. Total time 9.56361 hours\n",
      "Training at Epoch 30 iteration 3200 with loss 0.11423. Total time 9.57138 hours\n",
      "Training at Epoch 30 iteration 3300 with loss 0.08540. Total time 9.57916 hours\n",
      "Training at Epoch 30 iteration 3400 with loss 0.11624. Total time 9.58722 hours\n",
      "Training at Epoch 30 iteration 3500 with loss 0.08636. Total time 9.595 hours\n",
      "Validation at Epoch 30, AUROC: 0.93234 , AUPRC: 0.84089 , F1: 0.76764 , Cross-entropy Loss: 3.92465\n",
      "--- Go for Testing ---\n",
      "Validation at Epoch 30 , AUROC: 0.93524 , AUPRC: 0.84453 , F1: 0.76133 , Cross-entropy Loss: 4.03345\n",
      "--- Training Finished ---\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h3d5MbqOGG98"
   },
   "source": [
    "net.save_model('/content/drive/MyDrive/Morgan_AAC')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aPZqwmyISUP"
   },
   "source": [
    "### Loading BindingDB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_4BeXL5jISUP"
   },
   "source": [
    "import os\n",
    "os.chdir('../')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OwUdxW-FISUQ"
   },
   "source": [
    "def download_BindingDB_edited(path = './data'):\n",
    "\n",
    "\tprint('Beginning to download dataset...')\n",
    "\n",
    "\tif not os.path.exists(path):\n",
    "\t    os.makedirs(path)\n",
    "\n",
    "\turl = 'https://www.bindingdb.org/bind/downloads/BindingDB_All_2021m4.tsv.zip'\n",
    "\tsaved_path = wget.download(url, path)\n",
    "\n",
    "\tprint('Beginning to extract zip file...')\n",
    "\twith ZipFile(saved_path, 'r') as zip:\n",
    "\t    zip.extractall(path = path)\n",
    "\t    print('Done!')\n",
    "\tpath = path + '/BindingDB_All.tsv'\n",
    "\treturn path"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i71kQM6TISUQ"
   },
   "source": [
    "X_drug, X_target, y  = process_BindingDB(download_BindingDB_edited('../data/BindingDB_All.tsv'),\n",
    "\t\t\t\t\t y = 'IC50', \n",
    "\t\t\t\t\t binary = True, \n",
    "\t\t\t\t\t convert_to_log = False,\n",
    "           threshold=30)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icAg8ubRGfE7"
   },
   "source": [
    "### CNN-CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-N0zzznQRiey"
   },
   "source": [
    "drug_encoding, target_encoding = 'CNN', 'CNN'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfHfC7fpRiey",
    "outputId": "ae661af1-6ef5-4615-9048-afa03d36e5e4"
   },
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random', \n",
    "                                frac=[0.7,0.1,0.2],\n",
    "                                random_seed=1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 1309264 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 650166\n",
      "encoding protein...\n",
      "unique target sequence: 5789\n",
      "splitting dataset...\n",
      "Done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9tAl3055Riez"
   },
   "source": [
    "config = generate_config(drug_encoding, \n",
    "                         target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 30, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xQNVVWLYRiez"
   },
   "source": [
    "net = models.model_initialize(**config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AjpwFTxxRiez",
    "outputId": "47cd7ac3-6ac7-41cc-bc0d-a54e512c78e9"
   },
   "source": [
    "net.train(train, val, test)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 0.69559. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.50111. Total time 0.01194 hours\n",
      "Training at Epoch 1 iteration 200 with loss 0.57017. Total time 0.02361 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.43401. Total time 0.03555 hours\n",
      "Training at Epoch 1 iteration 400 with loss 0.46720. Total time 0.04722 hours\n",
      "Training at Epoch 1 iteration 500 with loss 0.42075. Total time 0.05916 hours\n",
      "Training at Epoch 1 iteration 600 with loss 0.41822. Total time 0.07083 hours\n",
      "Training at Epoch 1 iteration 700 with loss 0.39700. Total time 0.08277 hours\n",
      "Training at Epoch 1 iteration 800 with loss 0.54949. Total time 0.09444 hours\n",
      "Training at Epoch 1 iteration 900 with loss 0.41839. Total time 0.10638 hours\n",
      "Training at Epoch 1 iteration 1000 with loss 0.46206. Total time 0.11833 hours\n",
      "Training at Epoch 1 iteration 1100 with loss 0.47110. Total time 0.13027 hours\n",
      "Training at Epoch 1 iteration 1200 with loss 0.42785. Total time 0.14194 hours\n",
      "Training at Epoch 1 iteration 1300 with loss 0.42059. Total time 0.15388 hours\n",
      "Training at Epoch 1 iteration 1400 with loss 0.41686. Total time 0.16583 hours\n",
      "Training at Epoch 1 iteration 1500 with loss 0.49083. Total time 0.17777 hours\n",
      "Training at Epoch 1 iteration 1600 with loss 0.34652. Total time 0.18972 hours\n",
      "Training at Epoch 1 iteration 1700 with loss 0.42273. Total time 0.20166 hours\n",
      "Training at Epoch 1 iteration 1800 with loss 0.40529. Total time 0.21361 hours\n",
      "Training at Epoch 1 iteration 1900 with loss 0.38004. Total time 0.22527 hours\n",
      "Training at Epoch 1 iteration 2000 with loss 0.46707. Total time 0.23722 hours\n",
      "Training at Epoch 1 iteration 2100 with loss 0.42502. Total time 0.24916 hours\n",
      "Training at Epoch 1 iteration 2200 with loss 0.44749. Total time 0.26111 hours\n",
      "Training at Epoch 1 iteration 2300 with loss 0.39297. Total time 0.27277 hours\n",
      "Training at Epoch 1 iteration 2400 with loss 0.42265. Total time 0.28472 hours\n",
      "Training at Epoch 1 iteration 2500 with loss 0.43235. Total time 0.29666 hours\n",
      "Training at Epoch 1 iteration 2600 with loss 0.44651. Total time 0.30861 hours\n",
      "Training at Epoch 1 iteration 2700 with loss 0.38754. Total time 0.32055 hours\n",
      "Training at Epoch 1 iteration 2800 with loss 0.44852. Total time 0.33222 hours\n",
      "Training at Epoch 1 iteration 2900 with loss 0.39881. Total time 0.34416 hours\n",
      "Training at Epoch 1 iteration 3000 with loss 0.39060. Total time 0.35611 hours\n",
      "Training at Epoch 1 iteration 3100 with loss 0.40203. Total time 0.36805 hours\n",
      "Training at Epoch 1 iteration 3200 with loss 0.44130. Total time 0.37972 hours\n",
      "Training at Epoch 1 iteration 3300 with loss 0.37440. Total time 0.39166 hours\n",
      "Training at Epoch 1 iteration 3400 with loss 0.34993. Total time 0.40361 hours\n",
      "Training at Epoch 1 iteration 3500 with loss 0.42141. Total time 0.41555 hours\n",
      "Validation at Epoch 1, AUROC: 0.84384 , AUPRC: 0.66467 , F1: 0.60571 , Cross-entropy Loss: 7.15155\n",
      "Training at Epoch 2 iteration 0 with loss 0.45619. Total time 0.48694 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.34494. Total time 0.49888 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.37286. Total time 0.51083 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.44442. Total time 0.52277 hours\n",
      "Training at Epoch 2 iteration 400 with loss 0.42533. Total time 0.53472 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.36557. Total time 0.54666 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.37868. Total time 0.55861 hours\n",
      "Training at Epoch 2 iteration 700 with loss 0.38827. Total time 0.57027 hours\n",
      "Training at Epoch 2 iteration 800 with loss 0.42031. Total time 0.58222 hours\n",
      "Training at Epoch 2 iteration 900 with loss 0.49789. Total time 0.59416 hours\n",
      "Training at Epoch 2 iteration 1000 with loss 0.44163. Total time 0.60611 hours\n",
      "Training at Epoch 2 iteration 1100 with loss 0.41867. Total time 0.61805 hours\n",
      "Training at Epoch 2 iteration 1200 with loss 0.41043. Total time 0.63 hours\n",
      "Training at Epoch 2 iteration 1300 with loss 0.39160. Total time 0.64194 hours\n",
      "Training at Epoch 2 iteration 1400 with loss 0.32988. Total time 0.65388 hours\n",
      "Training at Epoch 2 iteration 1500 with loss 0.38750. Total time 0.66583 hours\n",
      "Training at Epoch 2 iteration 1600 with loss 0.36187. Total time 0.67777 hours\n",
      "Training at Epoch 2 iteration 1700 with loss 0.38347. Total time 0.68972 hours\n",
      "Training at Epoch 2 iteration 1800 with loss 0.41540. Total time 0.70138 hours\n",
      "Training at Epoch 2 iteration 1900 with loss 0.40706. Total time 0.71333 hours\n",
      "Training at Epoch 2 iteration 2000 with loss 0.41708. Total time 0.72527 hours\n",
      "Training at Epoch 2 iteration 2100 with loss 0.30928. Total time 0.73722 hours\n",
      "Training at Epoch 2 iteration 2200 with loss 0.38562. Total time 0.74916 hours\n",
      "Training at Epoch 2 iteration 2300 with loss 0.35073. Total time 0.76083 hours\n",
      "Training at Epoch 2 iteration 2400 with loss 0.43414. Total time 0.77277 hours\n",
      "Training at Epoch 2 iteration 2500 with loss 0.32258. Total time 0.78444 hours\n",
      "Training at Epoch 2 iteration 2600 with loss 0.41820. Total time 0.79611 hours\n",
      "Training at Epoch 2 iteration 2700 with loss 0.37064. Total time 0.80805 hours\n",
      "Training at Epoch 2 iteration 2800 with loss 0.33687. Total time 0.82 hours\n",
      "Training at Epoch 2 iteration 2900 with loss 0.37307. Total time 0.83166 hours\n",
      "Training at Epoch 2 iteration 3000 with loss 0.37284. Total time 0.84361 hours\n",
      "Training at Epoch 2 iteration 3100 with loss 0.33973. Total time 0.85527 hours\n",
      "Training at Epoch 2 iteration 3200 with loss 0.38475. Total time 0.86722 hours\n",
      "Training at Epoch 2 iteration 3300 with loss 0.37172. Total time 0.87888 hours\n",
      "Training at Epoch 2 iteration 3400 with loss 0.40884. Total time 0.89083 hours\n",
      "Training at Epoch 2 iteration 3500 with loss 0.40479. Total time 0.90277 hours\n",
      "Validation at Epoch 2, AUROC: 0.86764 , AUPRC: 0.70490 , F1: 0.63549 , Cross-entropy Loss: 6.19919\n",
      "Training at Epoch 3 iteration 0 with loss 0.40287. Total time 0.97388 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.42093. Total time 0.98583 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.38736. Total time 0.9975 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.29545. Total time 1.00944 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.37543. Total time 1.02138 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.34487. Total time 1.03305 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.44744. Total time 1.045 hours\n",
      "Training at Epoch 3 iteration 700 with loss 0.38947. Total time 1.05666 hours\n",
      "Training at Epoch 3 iteration 800 with loss 0.37287. Total time 1.06861 hours\n",
      "Training at Epoch 3 iteration 900 with loss 0.39255. Total time 1.08027 hours\n",
      "Training at Epoch 3 iteration 1000 with loss 0.40627. Total time 1.09222 hours\n",
      "Training at Epoch 3 iteration 1100 with loss 0.39947. Total time 1.10416 hours\n",
      "Training at Epoch 3 iteration 1200 with loss 0.39094. Total time 1.11583 hours\n",
      "Training at Epoch 3 iteration 1300 with loss 0.43909. Total time 1.12777 hours\n",
      "Training at Epoch 3 iteration 1400 with loss 0.36645. Total time 1.13944 hours\n",
      "Training at Epoch 3 iteration 1500 with loss 0.38683. Total time 1.15138 hours\n",
      "Training at Epoch 3 iteration 1600 with loss 0.41803. Total time 1.16333 hours\n",
      "Training at Epoch 3 iteration 1700 with loss 0.41678. Total time 1.175 hours\n",
      "Training at Epoch 3 iteration 1800 with loss 0.34655. Total time 1.18694 hours\n",
      "Training at Epoch 3 iteration 1900 with loss 0.34208. Total time 1.19861 hours\n",
      "Training at Epoch 3 iteration 2000 with loss 0.32439. Total time 1.21055 hours\n",
      "Training at Epoch 3 iteration 2100 with loss 0.37985. Total time 1.22222 hours\n",
      "Training at Epoch 3 iteration 2200 with loss 0.29482. Total time 1.23416 hours\n",
      "Training at Epoch 3 iteration 2300 with loss 0.37562. Total time 1.24583 hours\n",
      "Training at Epoch 3 iteration 2400 with loss 0.35978. Total time 1.25777 hours\n",
      "Training at Epoch 3 iteration 2500 with loss 0.32368. Total time 1.26972 hours\n",
      "Training at Epoch 3 iteration 2600 with loss 0.34295. Total time 1.28138 hours\n",
      "Training at Epoch 3 iteration 2700 with loss 0.38840. Total time 1.29333 hours\n",
      "Training at Epoch 3 iteration 2800 with loss 0.39306. Total time 1.305 hours\n",
      "Training at Epoch 3 iteration 2900 with loss 0.38198. Total time 1.31694 hours\n",
      "Training at Epoch 3 iteration 3000 with loss 0.34339. Total time 1.32888 hours\n",
      "Training at Epoch 3 iteration 3100 with loss 0.34142. Total time 1.34055 hours\n",
      "Training at Epoch 3 iteration 3200 with loss 0.43665. Total time 1.3525 hours\n",
      "Training at Epoch 3 iteration 3300 with loss 0.36356. Total time 1.36444 hours\n",
      "Training at Epoch 3 iteration 3400 with loss 0.38614. Total time 1.37611 hours\n",
      "Training at Epoch 3 iteration 3500 with loss 0.36263. Total time 1.38805 hours\n",
      "Validation at Epoch 3, AUROC: 0.88194 , AUPRC: 0.73046 , F1: 0.65662 , Cross-entropy Loss: 5.71062\n",
      "Training at Epoch 4 iteration 0 with loss 0.39096. Total time 1.45888 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.36764. Total time 1.47083 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.38794. Total time 1.4825 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.35589. Total time 1.49444 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.34605. Total time 1.50611 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.36916. Total time 1.51805 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.36682. Total time 1.53 hours\n",
      "Training at Epoch 4 iteration 700 with loss 0.42272. Total time 1.54166 hours\n",
      "Training at Epoch 4 iteration 800 with loss 0.42040. Total time 1.55361 hours\n",
      "Training at Epoch 4 iteration 900 with loss 0.42310. Total time 1.56555 hours\n",
      "Training at Epoch 4 iteration 1000 with loss 0.38087. Total time 1.57722 hours\n",
      "Training at Epoch 4 iteration 1100 with loss 0.39407. Total time 1.58916 hours\n",
      "Training at Epoch 4 iteration 1200 with loss 0.38039. Total time 1.60083 hours\n",
      "Training at Epoch 4 iteration 1300 with loss 0.34896. Total time 1.61277 hours\n",
      "Training at Epoch 4 iteration 1400 with loss 0.33673. Total time 1.62472 hours\n",
      "Training at Epoch 4 iteration 1500 with loss 0.38998. Total time 1.63638 hours\n",
      "Training at Epoch 4 iteration 1600 with loss 0.40610. Total time 1.64833 hours\n",
      "Training at Epoch 4 iteration 1700 with loss 0.35611. Total time 1.66 hours\n",
      "Training at Epoch 4 iteration 1800 with loss 0.36224. Total time 1.67194 hours\n",
      "Training at Epoch 4 iteration 1900 with loss 0.38381. Total time 1.68388 hours\n",
      "Training at Epoch 4 iteration 2000 with loss 0.36801. Total time 1.69555 hours\n",
      "Training at Epoch 4 iteration 2100 with loss 0.34277. Total time 1.70722 hours\n",
      "Training at Epoch 4 iteration 2200 with loss 0.35501. Total time 1.71916 hours\n",
      "Training at Epoch 4 iteration 2300 with loss 0.40820. Total time 1.73111 hours\n",
      "Training at Epoch 4 iteration 2400 with loss 0.39834. Total time 1.74277 hours\n",
      "Training at Epoch 4 iteration 2500 with loss 0.37293. Total time 1.75472 hours\n",
      "Training at Epoch 4 iteration 2600 with loss 0.33190. Total time 1.76638 hours\n",
      "Training at Epoch 4 iteration 2700 with loss 0.29321. Total time 1.77833 hours\n",
      "Training at Epoch 4 iteration 2800 with loss 0.31608. Total time 1.79 hours\n",
      "Training at Epoch 4 iteration 2900 with loss 0.38576. Total time 1.80194 hours\n",
      "Training at Epoch 4 iteration 3000 with loss 0.34431. Total time 1.81388 hours\n",
      "Training at Epoch 4 iteration 3100 with loss 0.33989. Total time 1.82555 hours\n",
      "Training at Epoch 4 iteration 3200 with loss 0.33575. Total time 1.8375 hours\n",
      "Training at Epoch 4 iteration 3300 with loss 0.30934. Total time 1.84944 hours\n",
      "Training at Epoch 4 iteration 3400 with loss 0.29446. Total time 1.86111 hours\n",
      "Training at Epoch 4 iteration 3500 with loss 0.32686. Total time 1.87305 hours\n",
      "Validation at Epoch 4, AUROC: 0.88380 , AUPRC: 0.73481 , F1: 0.65469 , Cross-entropy Loss: 5.68212\n",
      "Training at Epoch 5 iteration 0 with loss 0.29318. Total time 1.94416 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.35690. Total time 1.95583 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.38058. Total time 1.96777 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.35385. Total time 1.97944 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.36544. Total time 1.99138 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.35982. Total time 2.00333 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.32527. Total time 2.015 hours\n",
      "Training at Epoch 5 iteration 700 with loss 0.37765. Total time 2.02694 hours\n",
      "Training at Epoch 5 iteration 800 with loss 0.44318. Total time 2.03861 hours\n",
      "Training at Epoch 5 iteration 900 with loss 0.40428. Total time 2.05055 hours\n",
      "Training at Epoch 5 iteration 1000 with loss 0.34087. Total time 2.06222 hours\n",
      "Training at Epoch 5 iteration 1100 with loss 0.30840. Total time 2.07416 hours\n",
      "Training at Epoch 5 iteration 1200 with loss 0.37894. Total time 2.08583 hours\n",
      "Training at Epoch 5 iteration 1300 with loss 0.29925. Total time 2.09777 hours\n",
      "Training at Epoch 5 iteration 1400 with loss 0.31344. Total time 2.10944 hours\n",
      "Training at Epoch 5 iteration 1500 with loss 0.30360. Total time 2.12138 hours\n",
      "Training at Epoch 5 iteration 1600 with loss 0.37044. Total time 2.13305 hours\n",
      "Training at Epoch 5 iteration 1700 with loss 0.35969. Total time 2.14472 hours\n",
      "Training at Epoch 5 iteration 1800 with loss 0.31155. Total time 2.15666 hours\n",
      "Training at Epoch 5 iteration 1900 with loss 0.31469. Total time 2.16833 hours\n",
      "Training at Epoch 5 iteration 2000 with loss 0.31276. Total time 2.18 hours\n",
      "Training at Epoch 5 iteration 2100 with loss 0.32272. Total time 2.19194 hours\n",
      "Training at Epoch 5 iteration 2200 with loss 0.33826. Total time 2.20361 hours\n",
      "Training at Epoch 5 iteration 2300 with loss 0.34884. Total time 2.21555 hours\n",
      "Training at Epoch 5 iteration 2400 with loss 0.31057. Total time 2.22722 hours\n",
      "Training at Epoch 5 iteration 2500 with loss 0.32784. Total time 2.23916 hours\n",
      "Training at Epoch 5 iteration 2600 with loss 0.30874. Total time 2.25083 hours\n",
      "Training at Epoch 5 iteration 2700 with loss 0.35340. Total time 2.26277 hours\n",
      "Training at Epoch 5 iteration 2800 with loss 0.36768. Total time 2.27444 hours\n",
      "Training at Epoch 5 iteration 2900 with loss 0.38175. Total time 2.28638 hours\n",
      "Training at Epoch 5 iteration 3000 with loss 0.33345. Total time 2.29805 hours\n",
      "Training at Epoch 5 iteration 3100 with loss 0.36546. Total time 2.31 hours\n",
      "Training at Epoch 5 iteration 3200 with loss 0.36797. Total time 2.32166 hours\n",
      "Training at Epoch 5 iteration 3300 with loss 0.39701. Total time 2.33333 hours\n",
      "Training at Epoch 5 iteration 3400 with loss 0.33879. Total time 2.34527 hours\n",
      "Training at Epoch 5 iteration 3500 with loss 0.31315. Total time 2.35694 hours\n",
      "Validation at Epoch 5, AUROC: 0.88996 , AUPRC: 0.74651 , F1: 0.63225 , Cross-entropy Loss: 5.39033\n",
      "Training at Epoch 6 iteration 0 with loss 0.34751. Total time 2.42777 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.32557. Total time 2.43972 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.34203. Total time 2.45166 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.40069. Total time 2.46361 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.33674. Total time 2.47527 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.38949. Total time 2.48722 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.32962. Total time 2.49888 hours\n",
      "Training at Epoch 6 iteration 700 with loss 0.38206. Total time 2.51083 hours\n",
      "Training at Epoch 6 iteration 800 with loss 0.34692. Total time 2.5225 hours\n",
      "Training at Epoch 6 iteration 900 with loss 0.32977. Total time 2.53416 hours\n",
      "Training at Epoch 6 iteration 1000 with loss 0.34310. Total time 2.54611 hours\n",
      "Training at Epoch 6 iteration 1100 with loss 0.31914. Total time 2.55777 hours\n",
      "Training at Epoch 6 iteration 1200 with loss 0.32875. Total time 2.56972 hours\n",
      "Training at Epoch 6 iteration 1300 with loss 0.31702. Total time 2.58138 hours\n",
      "Training at Epoch 6 iteration 1400 with loss 0.28850. Total time 2.59333 hours\n",
      "Training at Epoch 6 iteration 1500 with loss 0.31592. Total time 2.605 hours\n",
      "Training at Epoch 6 iteration 1600 with loss 0.39014. Total time 2.61666 hours\n",
      "Training at Epoch 6 iteration 1700 with loss 0.32736. Total time 2.62861 hours\n",
      "Training at Epoch 6 iteration 1800 with loss 0.30694. Total time 2.64055 hours\n",
      "Training at Epoch 6 iteration 1900 with loss 0.33730. Total time 2.65222 hours\n",
      "Training at Epoch 6 iteration 2000 with loss 0.36710. Total time 2.66416 hours\n",
      "Training at Epoch 6 iteration 2100 with loss 0.28317. Total time 2.67583 hours\n",
      "Training at Epoch 6 iteration 2200 with loss 0.35919. Total time 2.6875 hours\n",
      "Training at Epoch 6 iteration 2300 with loss 0.32197. Total time 2.69944 hours\n",
      "Training at Epoch 6 iteration 2400 with loss 0.36958. Total time 2.71111 hours\n",
      "Training at Epoch 6 iteration 2500 with loss 0.38030. Total time 2.72305 hours\n",
      "Training at Epoch 6 iteration 2600 with loss 0.31910. Total time 2.735 hours\n",
      "Training at Epoch 6 iteration 2700 with loss 0.35577. Total time 2.74666 hours\n",
      "Training at Epoch 6 iteration 2800 with loss 0.34986. Total time 2.75833 hours\n",
      "Training at Epoch 6 iteration 2900 with loss 0.31348. Total time 2.77027 hours\n",
      "Training at Epoch 6 iteration 3000 with loss 0.36844. Total time 2.78194 hours\n",
      "Training at Epoch 6 iteration 3100 with loss 0.33374. Total time 2.79388 hours\n",
      "Training at Epoch 6 iteration 3200 with loss 0.36625. Total time 2.80555 hours\n",
      "Training at Epoch 6 iteration 3300 with loss 0.34921. Total time 2.8175 hours\n",
      "Training at Epoch 6 iteration 3400 with loss 0.31250. Total time 2.82916 hours\n",
      "Training at Epoch 6 iteration 3500 with loss 0.35286. Total time 2.84083 hours\n",
      "Validation at Epoch 6, AUROC: 0.89353 , AUPRC: 0.75301 , F1: 0.65691 , Cross-entropy Loss: 5.30724\n",
      "Training at Epoch 7 iteration 0 with loss 0.26640. Total time 2.91166 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.28305. Total time 2.92333 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.30650. Total time 2.93527 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.34225. Total time 2.94694 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.35518. Total time 2.95861 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.32831. Total time 2.97055 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.28752. Total time 2.98222 hours\n",
      "Training at Epoch 7 iteration 700 with loss 0.29100. Total time 2.99416 hours\n",
      "Training at Epoch 7 iteration 800 with loss 0.30778. Total time 3.00583 hours\n",
      "Training at Epoch 7 iteration 900 with loss 0.29688. Total time 3.01777 hours\n",
      "Training at Epoch 7 iteration 1000 with loss 0.30957. Total time 3.02972 hours\n",
      "Training at Epoch 7 iteration 1100 with loss 0.34840. Total time 3.04138 hours\n",
      "Training at Epoch 7 iteration 1200 with loss 0.30038. Total time 3.05333 hours\n",
      "Training at Epoch 7 iteration 1300 with loss 0.34667. Total time 3.065 hours\n",
      "Training at Epoch 7 iteration 1400 with loss 0.31730. Total time 3.07694 hours\n",
      "Training at Epoch 7 iteration 1500 with loss 0.28582. Total time 3.08861 hours\n",
      "Training at Epoch 7 iteration 1600 with loss 0.32688. Total time 3.10055 hours\n",
      "Training at Epoch 7 iteration 1700 with loss 0.30918. Total time 3.11222 hours\n",
      "Training at Epoch 7 iteration 1800 with loss 0.35319. Total time 3.12416 hours\n",
      "Training at Epoch 7 iteration 1900 with loss 0.33929. Total time 3.13611 hours\n",
      "Training at Epoch 7 iteration 2000 with loss 0.26240. Total time 3.14805 hours\n",
      "Training at Epoch 7 iteration 2100 with loss 0.29810. Total time 3.15972 hours\n",
      "Training at Epoch 7 iteration 2200 with loss 0.36522. Total time 3.17166 hours\n",
      "Training at Epoch 7 iteration 2300 with loss 0.32208. Total time 3.18333 hours\n",
      "Training at Epoch 7 iteration 2400 with loss 0.26534. Total time 3.19527 hours\n",
      "Training at Epoch 7 iteration 2500 with loss 0.26205. Total time 3.20694 hours\n",
      "Training at Epoch 7 iteration 2600 with loss 0.28430. Total time 3.21888 hours\n",
      "Training at Epoch 7 iteration 2700 with loss 0.40730. Total time 3.23055 hours\n",
      "Training at Epoch 7 iteration 2800 with loss 0.38294. Total time 3.2425 hours\n",
      "Training at Epoch 7 iteration 2900 with loss 0.32065. Total time 3.25416 hours\n",
      "Training at Epoch 7 iteration 3000 with loss 0.34277. Total time 3.26611 hours\n",
      "Training at Epoch 7 iteration 3100 with loss 0.32733. Total time 3.27777 hours\n",
      "Training at Epoch 7 iteration 3200 with loss 0.30653. Total time 3.28972 hours\n",
      "Training at Epoch 7 iteration 3300 with loss 0.32670. Total time 3.30138 hours\n",
      "Training at Epoch 7 iteration 3400 with loss 0.31075. Total time 3.31333 hours\n",
      "Training at Epoch 7 iteration 3500 with loss 0.32656. Total time 3.32527 hours\n",
      "Validation at Epoch 7, AUROC: 0.89696 , AUPRC: 0.76118 , F1: 0.64385 , Cross-entropy Loss: 5.23944\n",
      "Training at Epoch 8 iteration 0 with loss 0.34601. Total time 3.39611 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.27055. Total time 3.40805 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.32109. Total time 3.41972 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.28149. Total time 3.43166 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.31977. Total time 3.44333 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.33837. Total time 3.455 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.34431. Total time 3.46694 hours\n",
      "Training at Epoch 8 iteration 700 with loss 0.30625. Total time 3.47861 hours\n",
      "Training at Epoch 8 iteration 800 with loss 0.35749. Total time 3.49055 hours\n",
      "Training at Epoch 8 iteration 900 with loss 0.33124. Total time 3.50222 hours\n",
      "Training at Epoch 8 iteration 1000 with loss 0.34353. Total time 3.51416 hours\n",
      "Training at Epoch 8 iteration 1100 with loss 0.28207. Total time 3.52583 hours\n",
      "Training at Epoch 8 iteration 1200 with loss 0.28506. Total time 3.5375 hours\n",
      "Training at Epoch 8 iteration 1300 with loss 0.27260. Total time 3.54916 hours\n",
      "Training at Epoch 8 iteration 1400 with loss 0.30089. Total time 3.56083 hours\n",
      "Training at Epoch 8 iteration 1500 with loss 0.31039. Total time 3.57277 hours\n",
      "Training at Epoch 8 iteration 1600 with loss 0.34804. Total time 3.58444 hours\n",
      "Training at Epoch 8 iteration 1700 with loss 0.32839. Total time 3.59611 hours\n",
      "Training at Epoch 8 iteration 1800 with loss 0.31994. Total time 3.60805 hours\n",
      "Training at Epoch 8 iteration 1900 with loss 0.26248. Total time 3.61972 hours\n",
      "Training at Epoch 8 iteration 2000 with loss 0.32052. Total time 3.63166 hours\n",
      "Training at Epoch 8 iteration 2100 with loss 0.29185. Total time 3.64333 hours\n",
      "Training at Epoch 8 iteration 2200 with loss 0.34470. Total time 3.65527 hours\n",
      "Training at Epoch 8 iteration 2300 with loss 0.34925. Total time 3.66694 hours\n",
      "Training at Epoch 8 iteration 2400 with loss 0.34244. Total time 3.67888 hours\n",
      "Training at Epoch 8 iteration 2500 with loss 0.39877. Total time 3.69055 hours\n",
      "Training at Epoch 8 iteration 2600 with loss 0.36336. Total time 3.70222 hours\n",
      "Training at Epoch 8 iteration 2700 with loss 0.29330. Total time 3.71416 hours\n",
      "Training at Epoch 8 iteration 2800 with loss 0.33372. Total time 3.72583 hours\n",
      "Training at Epoch 8 iteration 2900 with loss 0.34576. Total time 3.7375 hours\n",
      "Training at Epoch 8 iteration 3000 with loss 0.31507. Total time 3.74944 hours\n",
      "Training at Epoch 8 iteration 3100 with loss 0.37620. Total time 3.76111 hours\n",
      "Training at Epoch 8 iteration 3200 with loss 0.33936. Total time 3.77277 hours\n",
      "Training at Epoch 8 iteration 3300 with loss 0.31519. Total time 3.78472 hours\n",
      "Training at Epoch 8 iteration 3400 with loss 0.36687. Total time 3.79638 hours\n",
      "Training at Epoch 8 iteration 3500 with loss 0.27421. Total time 3.80805 hours\n",
      "Validation at Epoch 8, AUROC: 0.90042 , AUPRC: 0.76580 , F1: 0.65906 , Cross-entropy Loss: 5.14790\n",
      "Training at Epoch 9 iteration 0 with loss 0.31539. Total time 3.87888 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.35144. Total time 3.89083 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.31930. Total time 3.9025 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.33957. Total time 3.91416 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.26615. Total time 3.92611 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.34445. Total time 3.93777 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.28409. Total time 3.94972 hours\n",
      "Training at Epoch 9 iteration 700 with loss 0.26893. Total time 3.96138 hours\n",
      "Training at Epoch 9 iteration 800 with loss 0.31302. Total time 3.97305 hours\n",
      "Training at Epoch 9 iteration 900 with loss 0.30373. Total time 3.985 hours\n",
      "Training at Epoch 9 iteration 1000 with loss 0.28363. Total time 3.99666 hours\n",
      "Training at Epoch 9 iteration 1100 with loss 0.33368. Total time 4.00833 hours\n",
      "Training at Epoch 9 iteration 1200 with loss 0.27463. Total time 4.02027 hours\n",
      "Training at Epoch 9 iteration 1300 with loss 0.31030. Total time 4.03194 hours\n",
      "Training at Epoch 9 iteration 1400 with loss 0.23919. Total time 4.04361 hours\n",
      "Training at Epoch 9 iteration 1500 with loss 0.33187. Total time 4.05555 hours\n",
      "Training at Epoch 9 iteration 1600 with loss 0.29571. Total time 4.06722 hours\n",
      "Training at Epoch 9 iteration 1700 with loss 0.37177. Total time 4.07916 hours\n",
      "Training at Epoch 9 iteration 1800 with loss 0.29203. Total time 4.09083 hours\n",
      "Training at Epoch 9 iteration 1900 with loss 0.32874. Total time 4.10277 hours\n",
      "Training at Epoch 9 iteration 2000 with loss 0.35756. Total time 4.11444 hours\n",
      "Training at Epoch 9 iteration 2100 with loss 0.35202. Total time 4.12638 hours\n",
      "Training at Epoch 9 iteration 2200 with loss 0.34860. Total time 4.13805 hours\n",
      "Training at Epoch 9 iteration 2300 with loss 0.29424. Total time 4.15 hours\n",
      "Training at Epoch 9 iteration 2400 with loss 0.39646. Total time 4.16166 hours\n",
      "Training at Epoch 9 iteration 2500 with loss 0.34043. Total time 4.17333 hours\n",
      "Training at Epoch 9 iteration 2600 with loss 0.39909. Total time 4.185 hours\n",
      "Training at Epoch 9 iteration 2700 with loss 0.34955. Total time 4.19694 hours\n",
      "Training at Epoch 9 iteration 2800 with loss 0.31418. Total time 4.20861 hours\n",
      "Training at Epoch 9 iteration 2900 with loss 0.38892. Total time 4.22027 hours\n",
      "Training at Epoch 9 iteration 3000 with loss 0.36091. Total time 4.23222 hours\n",
      "Training at Epoch 9 iteration 3100 with loss 0.30030. Total time 4.24388 hours\n",
      "Training at Epoch 9 iteration 3200 with loss 0.29222. Total time 4.25555 hours\n",
      "Training at Epoch 9 iteration 3300 with loss 0.31849. Total time 4.26722 hours\n",
      "Training at Epoch 9 iteration 3400 with loss 0.33147. Total time 4.27916 hours\n",
      "Training at Epoch 9 iteration 3500 with loss 0.31623. Total time 4.29083 hours\n",
      "Validation at Epoch 9, AUROC: 0.90237 , AUPRC: 0.76849 , F1: 0.66842 , Cross-entropy Loss: 5.10438\n",
      "Training at Epoch 10 iteration 0 with loss 0.33379. Total time 4.36138 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.28202. Total time 4.37333 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.32060. Total time 4.385 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.33590. Total time 4.39694 hours\n",
      "Training at Epoch 10 iteration 400 with loss 0.32354. Total time 4.40861 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.33421. Total time 4.42055 hours\n",
      "Training at Epoch 10 iteration 600 with loss 0.38094. Total time 4.43222 hours\n",
      "Training at Epoch 10 iteration 700 with loss 0.36749. Total time 4.44416 hours\n",
      "Training at Epoch 10 iteration 800 with loss 0.36823. Total time 4.45583 hours\n",
      "Training at Epoch 10 iteration 900 with loss 0.34694. Total time 4.4675 hours\n",
      "Training at Epoch 10 iteration 1000 with loss 0.30614. Total time 4.47944 hours\n",
      "Training at Epoch 10 iteration 1100 with loss 0.34808. Total time 4.49111 hours\n",
      "Training at Epoch 10 iteration 1200 with loss 0.31213. Total time 4.50305 hours\n",
      "Training at Epoch 10 iteration 1300 with loss 0.28693. Total time 4.51472 hours\n",
      "Training at Epoch 10 iteration 1400 with loss 0.28250. Total time 4.52638 hours\n",
      "Training at Epoch 10 iteration 1500 with loss 0.32738. Total time 4.53833 hours\n",
      "Training at Epoch 10 iteration 1600 with loss 0.32846. Total time 4.55 hours\n",
      "Training at Epoch 10 iteration 1700 with loss 0.34309. Total time 4.56194 hours\n",
      "Training at Epoch 10 iteration 1800 with loss 0.30963. Total time 4.57361 hours\n",
      "Training at Epoch 10 iteration 1900 with loss 0.33655. Total time 4.58555 hours\n",
      "Training at Epoch 10 iteration 2000 with loss 0.34080. Total time 4.59722 hours\n",
      "Training at Epoch 10 iteration 2100 with loss 0.34393. Total time 4.60916 hours\n",
      "Training at Epoch 10 iteration 2200 with loss 0.34481. Total time 4.62083 hours\n",
      "Training at Epoch 10 iteration 2300 with loss 0.33238. Total time 4.63277 hours\n",
      "Training at Epoch 10 iteration 2400 with loss 0.34801. Total time 4.64444 hours\n",
      "Training at Epoch 10 iteration 2500 with loss 0.31291. Total time 4.65638 hours\n",
      "Training at Epoch 10 iteration 2600 with loss 0.30770. Total time 4.66805 hours\n",
      "Training at Epoch 10 iteration 2700 with loss 0.34155. Total time 4.67972 hours\n",
      "Training at Epoch 10 iteration 2800 with loss 0.35230. Total time 4.69166 hours\n",
      "Training at Epoch 10 iteration 2900 with loss 0.28264. Total time 4.70333 hours\n",
      "Training at Epoch 10 iteration 3000 with loss 0.30580. Total time 4.71527 hours\n",
      "Training at Epoch 10 iteration 3100 with loss 0.27773. Total time 4.72694 hours\n",
      "Training at Epoch 10 iteration 3200 with loss 0.30917. Total time 4.73888 hours\n",
      "Training at Epoch 10 iteration 3300 with loss 0.32331. Total time 4.75055 hours\n",
      "Training at Epoch 10 iteration 3400 with loss 0.33789. Total time 4.76222 hours\n",
      "Training at Epoch 10 iteration 3500 with loss 0.30878. Total time 4.77416 hours\n",
      "Validation at Epoch 10, AUROC: 0.90339 , AUPRC: 0.77168 , F1: 0.69095 , Cross-entropy Loss: 5.19672\n",
      "Training at Epoch 11 iteration 0 with loss 0.29824. Total time 4.845 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.31217. Total time 4.85666 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.26333. Total time 4.86833 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.34759. Total time 4.88027 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.32772. Total time 4.89194 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.33382. Total time 4.90388 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.33367. Total time 4.91555 hours\n",
      "Training at Epoch 11 iteration 700 with loss 0.30829. Total time 4.92722 hours\n",
      "Training at Epoch 11 iteration 800 with loss 0.36976. Total time 4.93888 hours\n",
      "Training at Epoch 11 iteration 900 with loss 0.28135. Total time 4.95055 hours\n",
      "Training at Epoch 11 iteration 1000 with loss 0.27733. Total time 4.96222 hours\n",
      "Training at Epoch 11 iteration 1100 with loss 0.34190. Total time 4.97416 hours\n",
      "Training at Epoch 11 iteration 1200 with loss 0.30602. Total time 4.98583 hours\n",
      "Training at Epoch 11 iteration 1300 with loss 0.30884. Total time 4.9975 hours\n",
      "Training at Epoch 11 iteration 1400 with loss 0.35014. Total time 5.00916 hours\n",
      "Training at Epoch 11 iteration 1500 with loss 0.28809. Total time 5.02083 hours\n",
      "Training at Epoch 11 iteration 1600 with loss 0.32409. Total time 5.03277 hours\n",
      "Training at Epoch 11 iteration 1700 with loss 0.32524. Total time 5.04444 hours\n",
      "Training at Epoch 11 iteration 1800 with loss 0.29300. Total time 5.05638 hours\n",
      "Training at Epoch 11 iteration 1900 with loss 0.27303. Total time 5.06805 hours\n",
      "Training at Epoch 11 iteration 2000 with loss 0.33661. Total time 5.08 hours\n",
      "Training at Epoch 11 iteration 2100 with loss 0.31108. Total time 5.09194 hours\n",
      "Training at Epoch 11 iteration 2200 with loss 0.29952. Total time 5.10361 hours\n",
      "Training at Epoch 11 iteration 2300 with loss 0.32230. Total time 5.11527 hours\n",
      "Training at Epoch 11 iteration 2400 with loss 0.31627. Total time 5.12722 hours\n",
      "Training at Epoch 11 iteration 2500 with loss 0.34092. Total time 5.13916 hours\n",
      "Training at Epoch 11 iteration 2600 with loss 0.37275. Total time 5.15083 hours\n",
      "Training at Epoch 11 iteration 2700 with loss 0.27237. Total time 5.1625 hours\n",
      "Training at Epoch 11 iteration 2800 with loss 0.34431. Total time 5.17444 hours\n",
      "Training at Epoch 11 iteration 2900 with loss 0.27651. Total time 5.18611 hours\n",
      "Training at Epoch 11 iteration 3000 with loss 0.34429. Total time 5.19777 hours\n",
      "Training at Epoch 11 iteration 3100 with loss 0.35338. Total time 5.20972 hours\n",
      "Training at Epoch 11 iteration 3200 with loss 0.33081. Total time 5.22138 hours\n",
      "Training at Epoch 11 iteration 3300 with loss 0.34312. Total time 5.23333 hours\n",
      "Training at Epoch 11 iteration 3400 with loss 0.28316. Total time 5.245 hours\n",
      "Training at Epoch 11 iteration 3500 with loss 0.31270. Total time 5.25666 hours\n",
      "Validation at Epoch 11, AUROC: 0.90523 , AUPRC: 0.77527 , F1: 0.65759 , Cross-entropy Loss: 5.07746\n",
      "Training at Epoch 12 iteration 0 with loss 0.31595. Total time 5.32805 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.32658. Total time 5.33972 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.35275. Total time 5.35138 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.28219. Total time 5.36333 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.29920. Total time 5.375 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.23068. Total time 5.38694 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.30885. Total time 5.39861 hours\n",
      "Training at Epoch 12 iteration 700 with loss 0.32002. Total time 5.41027 hours\n",
      "Training at Epoch 12 iteration 800 with loss 0.29468. Total time 5.42222 hours\n",
      "Training at Epoch 12 iteration 900 with loss 0.26618. Total time 5.43388 hours\n",
      "Training at Epoch 12 iteration 1000 with loss 0.34949. Total time 5.44555 hours\n",
      "Training at Epoch 12 iteration 1100 with loss 0.25703. Total time 5.4575 hours\n",
      "Training at Epoch 12 iteration 1200 with loss 0.34445. Total time 5.46916 hours\n",
      "Training at Epoch 12 iteration 1300 with loss 0.28914. Total time 5.48111 hours\n",
      "Training at Epoch 12 iteration 1400 with loss 0.29966. Total time 5.49277 hours\n",
      "Training at Epoch 12 iteration 1500 with loss 0.25009. Total time 5.50444 hours\n",
      "Training at Epoch 12 iteration 1600 with loss 0.29732. Total time 5.51638 hours\n",
      "Training at Epoch 12 iteration 1700 with loss 0.26846. Total time 5.52805 hours\n",
      "Training at Epoch 12 iteration 1800 with loss 0.32116. Total time 5.53972 hours\n",
      "Training at Epoch 12 iteration 1900 with loss 0.24895. Total time 5.55166 hours\n",
      "Training at Epoch 12 iteration 2000 with loss 0.28262. Total time 5.56333 hours\n",
      "Training at Epoch 12 iteration 2100 with loss 0.26517. Total time 5.57527 hours\n",
      "Training at Epoch 12 iteration 2200 with loss 0.30600. Total time 5.58694 hours\n",
      "Training at Epoch 12 iteration 2300 with loss 0.33635. Total time 5.59861 hours\n",
      "Training at Epoch 12 iteration 2400 with loss 0.30647. Total time 5.61027 hours\n",
      "Training at Epoch 12 iteration 2500 with loss 0.29188. Total time 5.62222 hours\n",
      "Training at Epoch 12 iteration 2600 with loss 0.32466. Total time 5.63388 hours\n",
      "Training at Epoch 12 iteration 2700 with loss 0.38208. Total time 5.64555 hours\n",
      "Training at Epoch 12 iteration 2800 with loss 0.30270. Total time 5.65722 hours\n",
      "Training at Epoch 12 iteration 2900 with loss 0.31424. Total time 5.66888 hours\n",
      "Training at Epoch 12 iteration 3000 with loss 0.31275. Total time 5.68083 hours\n",
      "Training at Epoch 12 iteration 3100 with loss 0.29828. Total time 5.6925 hours\n",
      "Training at Epoch 12 iteration 3200 with loss 0.30284. Total time 5.70416 hours\n",
      "Training at Epoch 12 iteration 3300 with loss 0.32041. Total time 5.71583 hours\n",
      "Training at Epoch 12 iteration 3400 with loss 0.28550. Total time 5.7275 hours\n",
      "Training at Epoch 12 iteration 3500 with loss 0.35099. Total time 5.73916 hours\n",
      "Validation at Epoch 12, AUROC: 0.90696 , AUPRC: 0.77855 , F1: 0.69349 , Cross-entropy Loss: 5.04767\n",
      "Training at Epoch 13 iteration 0 with loss 0.27373. Total time 5.80972 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.26889. Total time 5.82138 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.25767. Total time 5.83305 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.24479. Total time 5.84472 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.32788. Total time 5.85638 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.32779. Total time 5.86805 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.31250. Total time 5.88 hours\n",
      "Training at Epoch 13 iteration 700 with loss 0.25909. Total time 5.89166 hours\n",
      "Training at Epoch 13 iteration 800 with loss 0.29514. Total time 5.90333 hours\n",
      "Training at Epoch 13 iteration 900 with loss 0.27328. Total time 5.915 hours\n",
      "Training at Epoch 13 iteration 1000 with loss 0.32672. Total time 5.92666 hours\n",
      "Training at Epoch 13 iteration 1100 with loss 0.32519. Total time 5.93833 hours\n",
      "Training at Epoch 13 iteration 1200 with loss 0.26612. Total time 5.95027 hours\n",
      "Training at Epoch 13 iteration 1300 with loss 0.26346. Total time 5.96194 hours\n",
      "Training at Epoch 13 iteration 1400 with loss 0.28961. Total time 5.97361 hours\n",
      "Training at Epoch 13 iteration 1500 with loss 0.29535. Total time 5.98555 hours\n",
      "Training at Epoch 13 iteration 1600 with loss 0.28777. Total time 5.99722 hours\n",
      "Training at Epoch 13 iteration 1700 with loss 0.28222. Total time 6.00888 hours\n",
      "Training at Epoch 13 iteration 1800 with loss 0.26032. Total time 6.02055 hours\n",
      "Training at Epoch 13 iteration 1900 with loss 0.26833. Total time 6.03222 hours\n",
      "Training at Epoch 13 iteration 2000 with loss 0.31997. Total time 6.04388 hours\n",
      "Training at Epoch 13 iteration 2100 with loss 0.36121. Total time 6.05555 hours\n",
      "Training at Epoch 13 iteration 2200 with loss 0.33711. Total time 6.06722 hours\n",
      "Training at Epoch 13 iteration 2300 with loss 0.33250. Total time 6.07888 hours\n",
      "Training at Epoch 13 iteration 2400 with loss 0.31623. Total time 6.09055 hours\n",
      "Training at Epoch 13 iteration 2500 with loss 0.27882. Total time 6.10222 hours\n",
      "Training at Epoch 13 iteration 2600 with loss 0.25478. Total time 6.11388 hours\n",
      "Training at Epoch 13 iteration 2700 with loss 0.29964. Total time 6.12555 hours\n",
      "Training at Epoch 13 iteration 2800 with loss 0.26527. Total time 6.13722 hours\n",
      "Training at Epoch 13 iteration 2900 with loss 0.26279. Total time 6.14888 hours\n",
      "Training at Epoch 13 iteration 3000 with loss 0.31532. Total time 6.16083 hours\n",
      "Training at Epoch 13 iteration 3100 with loss 0.28884. Total time 6.1725 hours\n",
      "Training at Epoch 13 iteration 3200 with loss 0.24177. Total time 6.18416 hours\n",
      "Training at Epoch 13 iteration 3300 with loss 0.34847. Total time 6.19583 hours\n",
      "Training at Epoch 13 iteration 3400 with loss 0.31606. Total time 6.2075 hours\n",
      "Training at Epoch 13 iteration 3500 with loss 0.32363. Total time 6.21916 hours\n",
      "Validation at Epoch 13, AUROC: 0.90770 , AUPRC: 0.77947 , F1: 0.67642 , Cross-entropy Loss: 4.96456\n",
      "Training at Epoch 14 iteration 0 with loss 0.26797. Total time 6.28944 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.30275. Total time 6.30111 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.33429. Total time 6.31277 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.31568. Total time 6.32472 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.27400. Total time 6.33638 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.31758. Total time 6.34805 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.30856. Total time 6.35972 hours\n",
      "Training at Epoch 14 iteration 700 with loss 0.32123. Total time 6.37138 hours\n",
      "Training at Epoch 14 iteration 800 with loss 0.29389. Total time 6.38305 hours\n",
      "Training at Epoch 14 iteration 900 with loss 0.29145. Total time 6.39472 hours\n",
      "Training at Epoch 14 iteration 1000 with loss 0.27520. Total time 6.40638 hours\n",
      "Training at Epoch 14 iteration 1100 with loss 0.25904. Total time 6.41805 hours\n",
      "Training at Epoch 14 iteration 1200 with loss 0.30373. Total time 6.42972 hours\n",
      "Training at Epoch 14 iteration 1300 with loss 0.36179. Total time 6.44138 hours\n",
      "Training at Epoch 14 iteration 1400 with loss 0.28361. Total time 6.45305 hours\n",
      "Training at Epoch 14 iteration 1500 with loss 0.25906. Total time 6.46472 hours\n",
      "Training at Epoch 14 iteration 1600 with loss 0.28416. Total time 6.47638 hours\n",
      "Training at Epoch 14 iteration 1700 with loss 0.31959. Total time 6.48805 hours\n",
      "Training at Epoch 14 iteration 1800 with loss 0.31285. Total time 6.49972 hours\n",
      "Training at Epoch 14 iteration 1900 with loss 0.30621. Total time 6.51138 hours\n",
      "Training at Epoch 14 iteration 2000 with loss 0.31013. Total time 6.52305 hours\n",
      "Training at Epoch 14 iteration 2100 with loss 0.25395. Total time 6.535 hours\n",
      "Training at Epoch 14 iteration 2200 with loss 0.31492. Total time 6.54638 hours\n",
      "Training at Epoch 14 iteration 2300 with loss 0.29473. Total time 6.55805 hours\n",
      "Training at Epoch 14 iteration 2400 with loss 0.28451. Total time 6.56972 hours\n",
      "Training at Epoch 14 iteration 2500 with loss 0.31657. Total time 6.58138 hours\n",
      "Training at Epoch 14 iteration 2600 with loss 0.29692. Total time 6.59305 hours\n",
      "Training at Epoch 14 iteration 2700 with loss 0.26202. Total time 6.60472 hours\n",
      "Training at Epoch 14 iteration 2800 with loss 0.28577. Total time 6.61638 hours\n",
      "Training at Epoch 14 iteration 2900 with loss 0.28564. Total time 6.62833 hours\n",
      "Training at Epoch 14 iteration 3000 with loss 0.29991. Total time 6.63972 hours\n",
      "Training at Epoch 14 iteration 3100 with loss 0.29524. Total time 6.65166 hours\n",
      "Training at Epoch 14 iteration 3200 with loss 0.31410. Total time 6.66333 hours\n",
      "Training at Epoch 14 iteration 3300 with loss 0.33076. Total time 6.675 hours\n",
      "Training at Epoch 14 iteration 3400 with loss 0.33669. Total time 6.68666 hours\n",
      "Training at Epoch 14 iteration 3500 with loss 0.35995. Total time 6.69833 hours\n",
      "Validation at Epoch 14, AUROC: 0.90986 , AUPRC: 0.78265 , F1: 0.67519 , Cross-entropy Loss: 4.95216\n",
      "Training at Epoch 15 iteration 0 with loss 0.23839. Total time 6.76833 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.26919. Total time 6.78027 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.32055. Total time 6.79194 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.30463. Total time 6.80361 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.26290. Total time 6.81527 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.31203. Total time 6.82694 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.27744. Total time 6.83861 hours\n",
      "Training at Epoch 15 iteration 700 with loss 0.30217. Total time 6.85027 hours\n",
      "Training at Epoch 15 iteration 800 with loss 0.26951. Total time 6.86194 hours\n",
      "Training at Epoch 15 iteration 900 with loss 0.23717. Total time 6.87361 hours\n",
      "Training at Epoch 15 iteration 1000 with loss 0.28052. Total time 6.88527 hours\n",
      "Training at Epoch 15 iteration 1100 with loss 0.26705. Total time 6.89694 hours\n",
      "Training at Epoch 15 iteration 1200 with loss 0.25176. Total time 6.90861 hours\n",
      "Training at Epoch 15 iteration 1300 with loss 0.29688. Total time 6.92027 hours\n",
      "Training at Epoch 15 iteration 1400 with loss 0.23385. Total time 6.93194 hours\n",
      "Training at Epoch 15 iteration 1500 with loss 0.27944. Total time 6.94361 hours\n",
      "Training at Epoch 15 iteration 1600 with loss 0.30596. Total time 6.95527 hours\n",
      "Training at Epoch 15 iteration 1700 with loss 0.28702. Total time 6.96694 hours\n",
      "Training at Epoch 15 iteration 1800 with loss 0.25309. Total time 6.97861 hours\n",
      "Training at Epoch 15 iteration 1900 with loss 0.30304. Total time 6.99027 hours\n",
      "Training at Epoch 15 iteration 2000 with loss 0.32427. Total time 7.00194 hours\n",
      "Training at Epoch 15 iteration 2100 with loss 0.33413. Total time 7.01361 hours\n",
      "Training at Epoch 15 iteration 2200 with loss 0.26843. Total time 7.02527 hours\n",
      "Training at Epoch 15 iteration 2300 with loss 0.31044. Total time 7.03694 hours\n",
      "Training at Epoch 15 iteration 2400 with loss 0.24081. Total time 7.04861 hours\n",
      "Training at Epoch 15 iteration 2500 with loss 0.30897. Total time 7.06027 hours\n",
      "Training at Epoch 15 iteration 2600 with loss 0.32659. Total time 7.07194 hours\n",
      "Training at Epoch 15 iteration 2700 with loss 0.35831. Total time 7.08361 hours\n",
      "Training at Epoch 15 iteration 2800 with loss 0.33959. Total time 7.09555 hours\n",
      "Training at Epoch 15 iteration 2900 with loss 0.31720. Total time 7.10722 hours\n",
      "Training at Epoch 15 iteration 3000 with loss 0.28611. Total time 7.11888 hours\n",
      "Training at Epoch 15 iteration 3100 with loss 0.25245. Total time 7.13055 hours\n",
      "Training at Epoch 15 iteration 3200 with loss 0.32267. Total time 7.14222 hours\n",
      "Training at Epoch 15 iteration 3300 with loss 0.25313. Total time 7.15388 hours\n",
      "Training at Epoch 15 iteration 3400 with loss 0.28234. Total time 7.16555 hours\n",
      "Training at Epoch 15 iteration 3500 with loss 0.37159. Total time 7.17722 hours\n",
      "Validation at Epoch 15, AUROC: 0.91082 , AUPRC: 0.78588 , F1: 0.70297 , Cross-entropy Loss: 4.94373\n",
      "Training at Epoch 16 iteration 0 with loss 0.36504. Total time 7.24777 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.28489. Total time 7.25916 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.29641. Total time 7.27083 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.29864. Total time 7.2825 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.25215. Total time 7.29416 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.27316. Total time 7.30611 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.30186. Total time 7.3175 hours\n",
      "Training at Epoch 16 iteration 700 with loss 0.27947. Total time 7.32916 hours\n",
      "Training at Epoch 16 iteration 800 with loss 0.31269. Total time 7.34111 hours\n",
      "Training at Epoch 16 iteration 900 with loss 0.30436. Total time 7.35277 hours\n",
      "Training at Epoch 16 iteration 1000 with loss 0.32354. Total time 7.36416 hours\n",
      "Training at Epoch 16 iteration 1100 with loss 0.29110. Total time 7.37583 hours\n",
      "Training at Epoch 16 iteration 1200 with loss 0.25605. Total time 7.38777 hours\n",
      "Training at Epoch 16 iteration 1300 with loss 0.34017. Total time 7.39916 hours\n",
      "Training at Epoch 16 iteration 1400 with loss 0.30491. Total time 7.41083 hours\n",
      "Training at Epoch 16 iteration 1500 with loss 0.31453. Total time 7.4225 hours\n",
      "Training at Epoch 16 iteration 1600 with loss 0.27214. Total time 7.43416 hours\n",
      "Training at Epoch 16 iteration 1700 with loss 0.27794. Total time 7.44583 hours\n",
      "Training at Epoch 16 iteration 1800 with loss 0.27492. Total time 7.45777 hours\n",
      "Training at Epoch 16 iteration 1900 with loss 0.28824. Total time 7.46944 hours\n",
      "Training at Epoch 16 iteration 2000 with loss 0.25592. Total time 7.48111 hours\n",
      "Training at Epoch 16 iteration 2100 with loss 0.34616. Total time 7.49277 hours\n",
      "Training at Epoch 16 iteration 2200 with loss 0.26675. Total time 7.50444 hours\n",
      "Training at Epoch 16 iteration 2300 with loss 0.32117. Total time 7.51611 hours\n",
      "Training at Epoch 16 iteration 2400 with loss 0.25304. Total time 7.52777 hours\n",
      "Training at Epoch 16 iteration 2500 with loss 0.30069. Total time 7.53944 hours\n",
      "Training at Epoch 16 iteration 2600 with loss 0.31856. Total time 7.55111 hours\n",
      "Training at Epoch 16 iteration 2700 with loss 0.28768. Total time 7.56277 hours\n",
      "Training at Epoch 16 iteration 2800 with loss 0.29577. Total time 7.57444 hours\n",
      "Training at Epoch 16 iteration 2900 with loss 0.28254. Total time 7.58611 hours\n",
      "Training at Epoch 16 iteration 3000 with loss 0.30021. Total time 7.59777 hours\n",
      "Training at Epoch 16 iteration 3100 with loss 0.31360. Total time 7.60944 hours\n",
      "Training at Epoch 16 iteration 3200 with loss 0.26660. Total time 7.62111 hours\n",
      "Training at Epoch 16 iteration 3300 with loss 0.28350. Total time 7.63277 hours\n",
      "Training at Epoch 16 iteration 3400 with loss 0.27774. Total time 7.64444 hours\n",
      "Training at Epoch 16 iteration 3500 with loss 0.34235. Total time 7.65611 hours\n",
      "Validation at Epoch 16, AUROC: 0.91150 , AUPRC: 0.78717 , F1: 0.67966 , Cross-entropy Loss: 4.91760\n",
      "Training at Epoch 17 iteration 0 with loss 0.29173. Total time 7.72638 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.24828. Total time 7.73805 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.28298. Total time 7.74972 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.23385. Total time 7.76138 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.22709. Total time 7.77305 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.31402. Total time 7.78472 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.28709. Total time 7.79638 hours\n",
      "Training at Epoch 17 iteration 700 with loss 0.24604. Total time 7.80805 hours\n",
      "Training at Epoch 17 iteration 800 with loss 0.25762. Total time 7.81972 hours\n",
      "Training at Epoch 17 iteration 900 with loss 0.28465. Total time 7.83138 hours\n",
      "Training at Epoch 17 iteration 1000 with loss 0.26989. Total time 7.84305 hours\n",
      "Training at Epoch 17 iteration 1100 with loss 0.33038. Total time 7.85472 hours\n",
      "Training at Epoch 17 iteration 1200 with loss 0.26937. Total time 7.86638 hours\n",
      "Training at Epoch 17 iteration 1300 with loss 0.25945. Total time 7.87777 hours\n",
      "Training at Epoch 17 iteration 1400 with loss 0.30419. Total time 7.88944 hours\n",
      "Training at Epoch 17 iteration 1500 with loss 0.27026. Total time 7.90138 hours\n",
      "Training at Epoch 17 iteration 1600 with loss 0.35416. Total time 7.91277 hours\n",
      "Training at Epoch 17 iteration 1700 with loss 0.25728. Total time 7.92472 hours\n",
      "Training at Epoch 17 iteration 1800 with loss 0.23082. Total time 7.93611 hours\n",
      "Training at Epoch 17 iteration 1900 with loss 0.25994. Total time 7.94805 hours\n",
      "Training at Epoch 17 iteration 2000 with loss 0.30218. Total time 7.95972 hours\n",
      "Training at Epoch 17 iteration 2100 with loss 0.26339. Total time 7.97138 hours\n",
      "Training at Epoch 17 iteration 2200 with loss 0.26102. Total time 7.98305 hours\n",
      "Training at Epoch 17 iteration 2300 with loss 0.26621. Total time 7.99472 hours\n",
      "Training at Epoch 17 iteration 2400 with loss 0.30526. Total time 8.00638 hours\n",
      "Training at Epoch 17 iteration 2500 with loss 0.31099. Total time 8.01805 hours\n",
      "Training at Epoch 17 iteration 2600 with loss 0.36064. Total time 8.02972 hours\n",
      "Training at Epoch 17 iteration 2700 with loss 0.29379. Total time 8.04138 hours\n",
      "Training at Epoch 17 iteration 2800 with loss 0.31751. Total time 8.05305 hours\n",
      "Training at Epoch 17 iteration 2900 with loss 0.33909. Total time 8.06472 hours\n",
      "Training at Epoch 17 iteration 3000 with loss 0.35796. Total time 8.07638 hours\n",
      "Training at Epoch 17 iteration 3100 with loss 0.26711. Total time 8.08805 hours\n",
      "Training at Epoch 17 iteration 3200 with loss 0.34287. Total time 8.09972 hours\n",
      "Training at Epoch 17 iteration 3300 with loss 0.27385. Total time 8.11138 hours\n",
      "Training at Epoch 17 iteration 3400 with loss 0.26760. Total time 8.12305 hours\n",
      "Training at Epoch 17 iteration 3500 with loss 0.29035. Total time 8.13472 hours\n",
      "Validation at Epoch 17, AUROC: 0.91145 , AUPRC: 0.78808 , F1: 0.69480 , Cross-entropy Loss: 4.86696\n",
      "Training at Epoch 18 iteration 0 with loss 0.31311. Total time 8.205 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.27159. Total time 8.21666 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.30508. Total time 8.22833 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.26360. Total time 8.24 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.27628. Total time 8.25166 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.33709. Total time 8.26333 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.31210. Total time 8.275 hours\n",
      "Training at Epoch 18 iteration 700 with loss 0.26349. Total time 8.28666 hours\n",
      "Training at Epoch 18 iteration 800 with loss 0.27846. Total time 8.29833 hours\n",
      "Training at Epoch 18 iteration 900 with loss 0.24094. Total time 8.31 hours\n",
      "Training at Epoch 18 iteration 1000 with loss 0.27393. Total time 8.32166 hours\n",
      "Training at Epoch 18 iteration 1100 with loss 0.29485. Total time 8.33333 hours\n",
      "Training at Epoch 18 iteration 1200 with loss 0.32977. Total time 8.345 hours\n",
      "Training at Epoch 18 iteration 1300 with loss 0.24730. Total time 8.35666 hours\n",
      "Training at Epoch 18 iteration 1400 with loss 0.25533. Total time 8.36833 hours\n",
      "Training at Epoch 18 iteration 1500 with loss 0.26396. Total time 8.38 hours\n",
      "Training at Epoch 18 iteration 1600 with loss 0.25730. Total time 8.39166 hours\n",
      "Training at Epoch 18 iteration 1700 with loss 0.25450. Total time 8.40333 hours\n",
      "Training at Epoch 18 iteration 1800 with loss 0.30626. Total time 8.415 hours\n",
      "Training at Epoch 18 iteration 1900 with loss 0.30638. Total time 8.42666 hours\n",
      "Training at Epoch 18 iteration 2000 with loss 0.26231. Total time 8.43833 hours\n",
      "Training at Epoch 18 iteration 2100 with loss 0.32343. Total time 8.45 hours\n",
      "Training at Epoch 18 iteration 2200 with loss 0.35624. Total time 8.46194 hours\n",
      "Training at Epoch 18 iteration 2300 with loss 0.27941. Total time 8.47361 hours\n",
      "Training at Epoch 18 iteration 2400 with loss 0.33395. Total time 8.48527 hours\n",
      "Training at Epoch 18 iteration 2500 with loss 0.30030. Total time 8.49694 hours\n",
      "Training at Epoch 18 iteration 2600 with loss 0.26454. Total time 8.50861 hours\n",
      "Training at Epoch 18 iteration 2700 with loss 0.29568. Total time 8.52027 hours\n",
      "Training at Epoch 18 iteration 2800 with loss 0.27430. Total time 8.53194 hours\n",
      "Training at Epoch 18 iteration 2900 with loss 0.23122. Total time 8.54361 hours\n",
      "Training at Epoch 18 iteration 3000 with loss 0.29135. Total time 8.55527 hours\n",
      "Training at Epoch 18 iteration 3100 with loss 0.30718. Total time 8.56694 hours\n",
      "Training at Epoch 18 iteration 3200 with loss 0.37531. Total time 8.57861 hours\n",
      "Training at Epoch 18 iteration 3300 with loss 0.30815. Total time 8.59027 hours\n",
      "Training at Epoch 18 iteration 3400 with loss 0.25140. Total time 8.60194 hours\n",
      "Training at Epoch 18 iteration 3500 with loss 0.29375. Total time 8.61361 hours\n",
      "Validation at Epoch 18, AUROC: 0.91322 , AUPRC: 0.79109 , F1: 0.66093 , Cross-entropy Loss: 4.92867\n",
      "Training at Epoch 19 iteration 0 with loss 0.27300. Total time 8.68416 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.29176. Total time 8.69583 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.27859. Total time 8.7075 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.25828. Total time 8.71916 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.33183. Total time 8.73083 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.23682. Total time 8.7425 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.27143. Total time 8.75416 hours\n",
      "Training at Epoch 19 iteration 700 with loss 0.25603. Total time 8.76583 hours\n",
      "Training at Epoch 19 iteration 800 with loss 0.29243. Total time 8.7775 hours\n",
      "Training at Epoch 19 iteration 900 with loss 0.25643. Total time 8.78916 hours\n",
      "Training at Epoch 19 iteration 1000 with loss 0.30255. Total time 8.80083 hours\n",
      "Training at Epoch 19 iteration 1100 with loss 0.30564. Total time 8.8125 hours\n",
      "Training at Epoch 19 iteration 1200 with loss 0.26301. Total time 8.82416 hours\n",
      "Training at Epoch 19 iteration 1300 with loss 0.27015. Total time 8.83555 hours\n",
      "Training at Epoch 19 iteration 1400 with loss 0.25905. Total time 8.8475 hours\n",
      "Training at Epoch 19 iteration 1500 with loss 0.24227. Total time 8.85916 hours\n",
      "Training at Epoch 19 iteration 1600 with loss 0.27867. Total time 8.87083 hours\n",
      "Training at Epoch 19 iteration 1700 with loss 0.29116. Total time 8.8825 hours\n",
      "Training at Epoch 19 iteration 1800 with loss 0.27114. Total time 8.89416 hours\n",
      "Training at Epoch 19 iteration 1900 with loss 0.28579. Total time 8.90583 hours\n",
      "Training at Epoch 19 iteration 2000 with loss 0.29596. Total time 8.9175 hours\n",
      "Training at Epoch 19 iteration 2100 with loss 0.28301. Total time 8.92916 hours\n",
      "Training at Epoch 19 iteration 2200 with loss 0.26087. Total time 8.94083 hours\n",
      "Training at Epoch 19 iteration 2300 with loss 0.31709. Total time 8.9525 hours\n",
      "Training at Epoch 19 iteration 2400 with loss 0.26208. Total time 8.96416 hours\n",
      "Training at Epoch 19 iteration 2500 with loss 0.28949. Total time 8.97583 hours\n",
      "Training at Epoch 19 iteration 2600 with loss 0.24606. Total time 8.9875 hours\n",
      "Training at Epoch 19 iteration 2700 with loss 0.29872. Total time 8.99916 hours\n",
      "Training at Epoch 19 iteration 2800 with loss 0.28103. Total time 9.01083 hours\n",
      "Training at Epoch 19 iteration 2900 with loss 0.26983. Total time 9.0225 hours\n",
      "Training at Epoch 19 iteration 3000 with loss 0.34313. Total time 9.03416 hours\n",
      "Training at Epoch 19 iteration 3100 with loss 0.25881. Total time 9.04583 hours\n",
      "Training at Epoch 19 iteration 3200 with loss 0.26611. Total time 9.05777 hours\n",
      "Training at Epoch 19 iteration 3300 with loss 0.29084. Total time 9.06944 hours\n",
      "Training at Epoch 19 iteration 3400 with loss 0.28989. Total time 9.08083 hours\n",
      "Training at Epoch 19 iteration 3500 with loss 0.29785. Total time 9.0925 hours\n",
      "Validation at Epoch 19, AUROC: 0.91359 , AUPRC: 0.79138 , F1: 0.69983 , Cross-entropy Loss: 4.83609\n",
      "Training at Epoch 20 iteration 0 with loss 0.24194. Total time 9.16277 hours\n",
      "Training at Epoch 20 iteration 100 with loss 0.26582. Total time 9.17416 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.29472. Total time 9.18583 hours\n",
      "Training at Epoch 20 iteration 300 with loss 0.27912. Total time 9.1975 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.26225. Total time 9.20916 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.26100. Total time 9.22083 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.27136. Total time 9.2325 hours\n",
      "Training at Epoch 20 iteration 700 with loss 0.26680. Total time 9.24416 hours\n",
      "Training at Epoch 20 iteration 800 with loss 0.34217. Total time 9.25583 hours\n",
      "Training at Epoch 20 iteration 900 with loss 0.23850. Total time 9.2675 hours\n",
      "Training at Epoch 20 iteration 1000 with loss 0.23182. Total time 9.27916 hours\n",
      "Training at Epoch 20 iteration 1100 with loss 0.26446. Total time 9.29083 hours\n",
      "Training at Epoch 20 iteration 1200 with loss 0.37183. Total time 9.3025 hours\n",
      "Training at Epoch 20 iteration 1300 with loss 0.30461. Total time 9.31416 hours\n",
      "Training at Epoch 20 iteration 1400 with loss 0.32841. Total time 9.32583 hours\n",
      "Training at Epoch 20 iteration 1500 with loss 0.30236. Total time 9.3375 hours\n",
      "Training at Epoch 20 iteration 1600 with loss 0.34326. Total time 9.34916 hours\n",
      "Training at Epoch 20 iteration 1700 with loss 0.30637. Total time 9.36083 hours\n",
      "Training at Epoch 20 iteration 1800 with loss 0.29775. Total time 9.3725 hours\n",
      "Training at Epoch 20 iteration 1900 with loss 0.29481. Total time 9.38416 hours\n",
      "Training at Epoch 20 iteration 2000 with loss 0.29951. Total time 9.39583 hours\n",
      "Training at Epoch 20 iteration 2100 with loss 0.27673. Total time 9.4075 hours\n",
      "Training at Epoch 20 iteration 2200 with loss 0.23521. Total time 9.41888 hours\n",
      "Training at Epoch 20 iteration 2300 with loss 0.30097. Total time 9.43055 hours\n",
      "Training at Epoch 20 iteration 2400 with loss 0.34654. Total time 9.44222 hours\n",
      "Training at Epoch 20 iteration 2500 with loss 0.29455. Total time 9.45388 hours\n",
      "Training at Epoch 20 iteration 2600 with loss 0.27094. Total time 9.46555 hours\n",
      "Training at Epoch 20 iteration 2700 with loss 0.27284. Total time 9.47722 hours\n",
      "Training at Epoch 20 iteration 2800 with loss 0.30287. Total time 9.48888 hours\n",
      "Training at Epoch 20 iteration 2900 with loss 0.33585. Total time 9.50055 hours\n",
      "Training at Epoch 20 iteration 3000 with loss 0.34673. Total time 9.51222 hours\n",
      "Training at Epoch 20 iteration 3100 with loss 0.31443. Total time 9.52388 hours\n",
      "Training at Epoch 20 iteration 3200 with loss 0.26466. Total time 9.53555 hours\n",
      "Training at Epoch 20 iteration 3300 with loss 0.26976. Total time 9.54722 hours\n",
      "Training at Epoch 20 iteration 3400 with loss 0.26056. Total time 9.55888 hours\n",
      "Training at Epoch 20 iteration 3500 with loss 0.32380. Total time 9.57055 hours\n",
      "Validation at Epoch 20, AUROC: 0.91500 , AUPRC: 0.79343 , F1: 0.69519 , Cross-entropy Loss: 4.79256\n",
      "Training at Epoch 21 iteration 0 with loss 0.24854. Total time 9.64083 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.34036. Total time 9.6525 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.30364. Total time 9.66416 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.27978. Total time 9.67583 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.30394. Total time 9.6875 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.29549. Total time 9.69916 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.21949. Total time 9.71083 hours\n",
      "Training at Epoch 21 iteration 700 with loss 0.32978. Total time 9.7225 hours\n",
      "Training at Epoch 21 iteration 800 with loss 0.27024. Total time 9.73416 hours\n",
      "Training at Epoch 21 iteration 900 with loss 0.27411. Total time 9.74583 hours\n",
      "Training at Epoch 21 iteration 1000 with loss 0.31143. Total time 9.7575 hours\n",
      "Training at Epoch 21 iteration 1100 with loss 0.26313. Total time 9.76916 hours\n",
      "Training at Epoch 21 iteration 1200 with loss 0.25115. Total time 9.78083 hours\n",
      "Training at Epoch 21 iteration 1300 with loss 0.28637. Total time 9.79277 hours\n",
      "Training at Epoch 21 iteration 1400 with loss 0.27678. Total time 9.80444 hours\n",
      "Training at Epoch 21 iteration 1500 with loss 0.24042. Total time 9.81611 hours\n",
      "Training at Epoch 21 iteration 1600 with loss 0.27618. Total time 9.82777 hours\n",
      "Training at Epoch 21 iteration 1700 with loss 0.24876. Total time 9.83944 hours\n",
      "Training at Epoch 21 iteration 1800 with loss 0.28067. Total time 9.85111 hours\n",
      "Training at Epoch 21 iteration 1900 with loss 0.27394. Total time 9.86277 hours\n",
      "Training at Epoch 21 iteration 2000 with loss 0.32352. Total time 9.87444 hours\n",
      "Training at Epoch 21 iteration 2100 with loss 0.31645. Total time 9.88611 hours\n",
      "Training at Epoch 21 iteration 2200 with loss 0.36084. Total time 9.89777 hours\n",
      "Training at Epoch 21 iteration 2300 with loss 0.30142. Total time 9.90944 hours\n",
      "Training at Epoch 21 iteration 2400 with loss 0.27204. Total time 9.92111 hours\n",
      "Training at Epoch 21 iteration 2500 with loss 0.29540. Total time 9.93277 hours\n",
      "Training at Epoch 21 iteration 2600 with loss 0.33567. Total time 9.94444 hours\n",
      "Training at Epoch 21 iteration 2700 with loss 0.20867. Total time 9.95611 hours\n",
      "Training at Epoch 21 iteration 2800 with loss 0.24177. Total time 9.96777 hours\n",
      "Training at Epoch 21 iteration 2900 with loss 0.26698. Total time 9.97944 hours\n",
      "Training at Epoch 21 iteration 3000 with loss 0.37643. Total time 9.99111 hours\n",
      "Training at Epoch 21 iteration 3100 with loss 0.28951. Total time 10.0027 hours\n",
      "Training at Epoch 21 iteration 3200 with loss 0.23402. Total time 10.0144 hours\n",
      "Training at Epoch 21 iteration 3300 with loss 0.29717. Total time 10.0261 hours\n",
      "Training at Epoch 21 iteration 3400 with loss 0.29147. Total time 10.0377 hours\n",
      "Training at Epoch 21 iteration 3500 with loss 0.24107. Total time 10.0494 hours\n",
      "Validation at Epoch 21, AUROC: 0.91489 , AUPRC: 0.79288 , F1: 0.70091 , Cross-entropy Loss: 4.78069\n",
      "Training at Epoch 22 iteration 0 with loss 0.25546. Total time 10.1197 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.30773. Total time 10.1313 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.32942. Total time 10.1430 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.26309. Total time 10.1547 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.26303. Total time 10.1663 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.28345. Total time 10.1780 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.28722. Total time 10.1897 hours\n",
      "Training at Epoch 22 iteration 700 with loss 0.22515. Total time 10.2013 hours\n",
      "Training at Epoch 22 iteration 800 with loss 0.24630. Total time 10.2130 hours\n",
      "Training at Epoch 22 iteration 900 with loss 0.31630. Total time 10.2247 hours\n",
      "Training at Epoch 22 iteration 1000 with loss 0.30561. Total time 10.2363 hours\n",
      "Training at Epoch 22 iteration 1100 with loss 0.33566. Total time 10.2480 hours\n",
      "Training at Epoch 22 iteration 1200 with loss 0.30006. Total time 10.2597 hours\n",
      "Training at Epoch 22 iteration 1300 with loss 0.24082. Total time 10.2713 hours\n",
      "Training at Epoch 22 iteration 1400 with loss 0.28854. Total time 10.2830 hours\n",
      "Training at Epoch 22 iteration 1500 with loss 0.29090. Total time 10.2947 hours\n",
      "Training at Epoch 22 iteration 1600 with loss 0.31944. Total time 10.3063 hours\n",
      "Training at Epoch 22 iteration 1700 with loss 0.31395. Total time 10.3180 hours\n",
      "Training at Epoch 22 iteration 1800 with loss 0.27026. Total time 10.3297 hours\n",
      "Training at Epoch 22 iteration 1900 with loss 0.23042. Total time 10.3413 hours\n",
      "Training at Epoch 22 iteration 2000 with loss 0.25364. Total time 10.3530 hours\n",
      "Training at Epoch 22 iteration 2100 with loss 0.28938. Total time 10.3647 hours\n",
      "Training at Epoch 22 iteration 2200 with loss 0.20780. Total time 10.3763 hours\n",
      "Training at Epoch 22 iteration 2300 with loss 0.23561. Total time 10.3880 hours\n",
      "Training at Epoch 22 iteration 2400 with loss 0.24274. Total time 10.3997 hours\n",
      "Training at Epoch 22 iteration 2500 with loss 0.24984. Total time 10.4113 hours\n",
      "Training at Epoch 22 iteration 2600 with loss 0.29180. Total time 10.4230 hours\n",
      "Training at Epoch 22 iteration 2700 with loss 0.26033. Total time 10.4347 hours\n",
      "Training at Epoch 22 iteration 2800 with loss 0.31818. Total time 10.4463 hours\n",
      "Training at Epoch 22 iteration 2900 with loss 0.28058. Total time 10.4580 hours\n",
      "Training at Epoch 22 iteration 3000 with loss 0.26841. Total time 10.4697 hours\n",
      "Training at Epoch 22 iteration 3100 with loss 0.23537. Total time 10.4813 hours\n",
      "Training at Epoch 22 iteration 3200 with loss 0.24701. Total time 10.4930 hours\n",
      "Training at Epoch 22 iteration 3300 with loss 0.26743. Total time 10.5047 hours\n",
      "Training at Epoch 22 iteration 3400 with loss 0.23643. Total time 10.5163 hours\n",
      "Training at Epoch 22 iteration 3500 with loss 0.28107. Total time 10.5280 hours\n",
      "Validation at Epoch 22, AUROC: 0.91560 , AUPRC: 0.79469 , F1: 0.70560 , Cross-entropy Loss: 4.80523\n",
      "Training at Epoch 23 iteration 0 with loss 0.31137. Total time 10.5986 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.27433. Total time 10.6102 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.26357. Total time 10.6219 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.31042. Total time 10.6336 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.30336. Total time 10.6452 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.28523. Total time 10.6569 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.23343. Total time 10.6686 hours\n",
      "Training at Epoch 23 iteration 700 with loss 0.25989. Total time 10.6802 hours\n",
      "Training at Epoch 23 iteration 800 with loss 0.28291. Total time 10.6919 hours\n",
      "Training at Epoch 23 iteration 900 with loss 0.23718. Total time 10.7036 hours\n",
      "Training at Epoch 23 iteration 1000 with loss 0.30485. Total time 10.7152 hours\n",
      "Training at Epoch 23 iteration 1100 with loss 0.31419. Total time 10.7269 hours\n",
      "Training at Epoch 23 iteration 1200 with loss 0.23047. Total time 10.7386 hours\n",
      "Training at Epoch 23 iteration 1300 with loss 0.23070. Total time 10.7502 hours\n",
      "Training at Epoch 23 iteration 1400 with loss 0.28287. Total time 10.7619 hours\n",
      "Training at Epoch 23 iteration 1500 with loss 0.20820. Total time 10.7736 hours\n",
      "Training at Epoch 23 iteration 1600 with loss 0.26791. Total time 10.7852 hours\n",
      "Training at Epoch 23 iteration 1700 with loss 0.27953. Total time 10.7969 hours\n",
      "Training at Epoch 23 iteration 1800 with loss 0.28361. Total time 10.8086 hours\n",
      "Training at Epoch 23 iteration 1900 with loss 0.27378. Total time 10.8202 hours\n",
      "Training at Epoch 23 iteration 2000 with loss 0.29332. Total time 10.8319 hours\n",
      "Training at Epoch 23 iteration 2100 with loss 0.29480. Total time 10.8436 hours\n",
      "Training at Epoch 23 iteration 2200 with loss 0.33103. Total time 10.8552 hours\n",
      "Training at Epoch 23 iteration 2300 with loss 0.36394. Total time 10.8669 hours\n",
      "Training at Epoch 23 iteration 2400 with loss 0.25878. Total time 10.8786 hours\n",
      "Training at Epoch 23 iteration 2500 with loss 0.29034. Total time 10.8902 hours\n",
      "Training at Epoch 23 iteration 2600 with loss 0.32025. Total time 10.9019 hours\n",
      "Training at Epoch 23 iteration 2700 with loss 0.28825. Total time 10.9136 hours\n",
      "Training at Epoch 23 iteration 2800 with loss 0.27299. Total time 10.9252 hours\n",
      "Training at Epoch 23 iteration 2900 with loss 0.28674. Total time 10.9369 hours\n",
      "Training at Epoch 23 iteration 3000 with loss 0.27314. Total time 10.9486 hours\n",
      "Training at Epoch 23 iteration 3100 with loss 0.30357. Total time 10.9602 hours\n",
      "Training at Epoch 23 iteration 3200 with loss 0.23795. Total time 10.9719 hours\n",
      "Training at Epoch 23 iteration 3300 with loss 0.32697. Total time 10.9836 hours\n",
      "Training at Epoch 23 iteration 3400 with loss 0.32725. Total time 10.9952 hours\n",
      "Training at Epoch 23 iteration 3500 with loss 0.28248. Total time 11.0069 hours\n",
      "Validation at Epoch 23, AUROC: 0.91652 , AUPRC: 0.79772 , F1: 0.70841 , Cross-entropy Loss: 4.71632\n",
      "Training at Epoch 24 iteration 0 with loss 0.29530. Total time 11.0772 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.24038. Total time 11.0891 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.23513. Total time 11.1008 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.25986. Total time 11.1125 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.33181. Total time 11.1241 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.21026. Total time 11.1358 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.25630. Total time 11.1475 hours\n",
      "Training at Epoch 24 iteration 700 with loss 0.29718. Total time 11.1588 hours\n",
      "Training at Epoch 24 iteration 800 with loss 0.26810. Total time 11.1705 hours\n",
      "Training at Epoch 24 iteration 900 with loss 0.28728. Total time 11.1822 hours\n",
      "Training at Epoch 24 iteration 1000 with loss 0.29785. Total time 11.1938 hours\n",
      "Training at Epoch 24 iteration 1100 with loss 0.31971. Total time 11.2055 hours\n",
      "Training at Epoch 24 iteration 1200 with loss 0.26691. Total time 11.2172 hours\n",
      "Training at Epoch 24 iteration 1300 with loss 0.29774. Total time 11.2288 hours\n",
      "Training at Epoch 24 iteration 1400 with loss 0.27162. Total time 11.2405 hours\n",
      "Training at Epoch 24 iteration 1500 with loss 0.28402. Total time 11.2522 hours\n",
      "Training at Epoch 24 iteration 1600 with loss 0.28944. Total time 11.2636 hours\n",
      "Training at Epoch 24 iteration 1700 with loss 0.27653. Total time 11.2752 hours\n",
      "Training at Epoch 24 iteration 1800 with loss 0.32358. Total time 11.2869 hours\n",
      "Training at Epoch 24 iteration 1900 with loss 0.36518. Total time 11.2986 hours\n",
      "Training at Epoch 24 iteration 2000 with loss 0.30353. Total time 11.3102 hours\n",
      "Training at Epoch 24 iteration 2100 with loss 0.26106. Total time 11.3219 hours\n",
      "Training at Epoch 24 iteration 2200 with loss 0.28660. Total time 11.3336 hours\n",
      "Training at Epoch 24 iteration 2300 with loss 0.27061. Total time 11.3452 hours\n",
      "Training at Epoch 24 iteration 2400 with loss 0.27109. Total time 11.3569 hours\n",
      "Training at Epoch 24 iteration 2500 with loss 0.25082. Total time 11.3683 hours\n",
      "Training at Epoch 24 iteration 2600 with loss 0.22828. Total time 11.38 hours\n",
      "Training at Epoch 24 iteration 2700 with loss 0.25217. Total time 11.3916 hours\n",
      "Training at Epoch 24 iteration 2800 with loss 0.29601. Total time 11.4033 hours\n",
      "Training at Epoch 24 iteration 2900 with loss 0.31957. Total time 11.415 hours\n",
      "Training at Epoch 24 iteration 3000 with loss 0.29276. Total time 11.4266 hours\n",
      "Training at Epoch 24 iteration 3100 with loss 0.21071. Total time 11.4383 hours\n",
      "Training at Epoch 24 iteration 3200 with loss 0.30101. Total time 11.45 hours\n",
      "Training at Epoch 24 iteration 3300 with loss 0.22649. Total time 11.4616 hours\n",
      "Training at Epoch 24 iteration 3400 with loss 0.33203. Total time 11.4733 hours\n",
      "Training at Epoch 24 iteration 3500 with loss 0.31448. Total time 11.485 hours\n",
      "Validation at Epoch 24, AUROC: 0.91684 , AUPRC: 0.79804 , F1: 0.71462 , Cross-entropy Loss: 4.80893\n",
      "Training at Epoch 25 iteration 0 with loss 0.25068. Total time 11.5547 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.19196. Total time 11.5663 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.23977. Total time 11.5780 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.30138. Total time 11.5897 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.30271. Total time 11.6013 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.24288. Total time 11.6130 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.26881. Total time 11.6247 hours\n",
      "Training at Epoch 25 iteration 700 with loss 0.24245. Total time 11.6363 hours\n",
      "Training at Epoch 25 iteration 800 with loss 0.26566. Total time 11.6480 hours\n",
      "Training at Epoch 25 iteration 900 with loss 0.26254. Total time 11.6597 hours\n",
      "Training at Epoch 25 iteration 1000 with loss 0.27799. Total time 11.6713 hours\n",
      "Training at Epoch 25 iteration 1100 with loss 0.23669. Total time 11.6830 hours\n",
      "Training at Epoch 25 iteration 1200 with loss 0.31519. Total time 11.6944 hours\n",
      "Training at Epoch 25 iteration 1300 with loss 0.22670. Total time 11.7061 hours\n",
      "Training at Epoch 25 iteration 1400 with loss 0.34043. Total time 11.7177 hours\n",
      "Training at Epoch 25 iteration 1500 with loss 0.30032. Total time 11.7294 hours\n",
      "Training at Epoch 25 iteration 1600 with loss 0.25829. Total time 11.7411 hours\n",
      "Training at Epoch 25 iteration 1700 with loss 0.25682. Total time 11.7527 hours\n",
      "Training at Epoch 25 iteration 1800 with loss 0.26451. Total time 11.7644 hours\n",
      "Training at Epoch 25 iteration 1900 with loss 0.26541. Total time 11.7761 hours\n",
      "Training at Epoch 25 iteration 2000 with loss 0.22809. Total time 11.7877 hours\n",
      "Training at Epoch 25 iteration 2100 with loss 0.27706. Total time 11.7994 hours\n",
      "Training at Epoch 25 iteration 2200 with loss 0.24279. Total time 11.8111 hours\n",
      "Training at Epoch 25 iteration 2300 with loss 0.29863. Total time 11.8225 hours\n",
      "Training at Epoch 25 iteration 2400 with loss 0.24748. Total time 11.8341 hours\n",
      "Training at Epoch 25 iteration 2500 with loss 0.30660. Total time 11.8458 hours\n",
      "Training at Epoch 25 iteration 2600 with loss 0.28559. Total time 11.8575 hours\n",
      "Training at Epoch 25 iteration 2700 with loss 0.25089. Total time 11.8691 hours\n",
      "Training at Epoch 25 iteration 2800 with loss 0.27737. Total time 11.8808 hours\n",
      "Training at Epoch 25 iteration 2900 with loss 0.32317. Total time 11.8925 hours\n",
      "Training at Epoch 25 iteration 3000 with loss 0.29361. Total time 11.9041 hours\n",
      "Training at Epoch 25 iteration 3100 with loss 0.29560. Total time 11.9158 hours\n",
      "Training at Epoch 25 iteration 3200 with loss 0.26082. Total time 11.9272 hours\n",
      "Training at Epoch 25 iteration 3300 with loss 0.28410. Total time 11.9388 hours\n",
      "Training at Epoch 25 iteration 3400 with loss 0.28153. Total time 11.9505 hours\n",
      "Training at Epoch 25 iteration 3500 with loss 0.27619. Total time 11.9622 hours\n",
      "Validation at Epoch 25, AUROC: 0.91679 , AUPRC: 0.79773 , F1: 0.69917 , Cross-entropy Loss: 4.72529\n",
      "Training at Epoch 26 iteration 0 with loss 0.25499. Total time 12.0325 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.27942. Total time 12.0441 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.25673. Total time 12.0558 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.26191. Total time 12.0675 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.21581. Total time 12.0791 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.25575. Total time 12.0905 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.29205. Total time 12.1022 hours\n",
      "Training at Epoch 26 iteration 700 with loss 0.24881. Total time 12.1138 hours\n",
      "Training at Epoch 26 iteration 800 with loss 0.27944. Total time 12.1255 hours\n",
      "Training at Epoch 26 iteration 900 with loss 0.20078. Total time 12.1372 hours\n",
      "Training at Epoch 26 iteration 1000 with loss 0.24892. Total time 12.1488 hours\n",
      "Training at Epoch 26 iteration 1100 with loss 0.28734. Total time 12.1605 hours\n",
      "Training at Epoch 26 iteration 1200 with loss 0.22487. Total time 12.1722 hours\n",
      "Training at Epoch 26 iteration 1300 with loss 0.20800. Total time 12.1838 hours\n",
      "Training at Epoch 26 iteration 1400 with loss 0.21178. Total time 12.1955 hours\n",
      "Training at Epoch 26 iteration 1500 with loss 0.24551. Total time 12.2069 hours\n",
      "Training at Epoch 26 iteration 1600 with loss 0.21734. Total time 12.2186 hours\n",
      "Training at Epoch 26 iteration 1700 with loss 0.27774. Total time 12.2302 hours\n",
      "Training at Epoch 26 iteration 1800 with loss 0.26365. Total time 12.2419 hours\n",
      "Training at Epoch 26 iteration 1900 with loss 0.29638. Total time 12.2536 hours\n",
      "Training at Epoch 26 iteration 2000 with loss 0.25210. Total time 12.2652 hours\n",
      "Training at Epoch 26 iteration 2100 with loss 0.22404. Total time 12.2766 hours\n",
      "Training at Epoch 26 iteration 2200 with loss 0.33671. Total time 12.2883 hours\n",
      "Training at Epoch 26 iteration 2300 with loss 0.28830. Total time 12.3 hours\n",
      "Training at Epoch 26 iteration 2400 with loss 0.28672. Total time 12.3116 hours\n",
      "Training at Epoch 26 iteration 2500 with loss 0.29239. Total time 12.3233 hours\n",
      "Training at Epoch 26 iteration 2600 with loss 0.28302. Total time 12.335 hours\n",
      "Training at Epoch 26 iteration 2700 with loss 0.31268. Total time 12.3466 hours\n",
      "Training at Epoch 26 iteration 2800 with loss 0.27337. Total time 12.3583 hours\n",
      "Training at Epoch 26 iteration 2900 with loss 0.29443. Total time 12.3697 hours\n",
      "Training at Epoch 26 iteration 3000 with loss 0.26723. Total time 12.3813 hours\n",
      "Training at Epoch 26 iteration 3100 with loss 0.31963. Total time 12.3930 hours\n",
      "Training at Epoch 26 iteration 3200 with loss 0.26647. Total time 12.4047 hours\n",
      "Training at Epoch 26 iteration 3300 with loss 0.27750. Total time 12.4163 hours\n",
      "Training at Epoch 26 iteration 3400 with loss 0.31155. Total time 12.4280 hours\n",
      "Training at Epoch 26 iteration 3500 with loss 0.27560. Total time 12.4397 hours\n",
      "Validation at Epoch 26, AUROC: 0.91812 , AUPRC: 0.80204 , F1: 0.70115 , Cross-entropy Loss: 4.67516\n",
      "Training at Epoch 27 iteration 0 with loss 0.28389. Total time 12.5097 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.24327. Total time 12.5213 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.32575. Total time 12.5330 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.29302. Total time 12.5447 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.22831. Total time 12.5563 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.25530. Total time 12.5680 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.23265. Total time 12.5797 hours\n",
      "Training at Epoch 27 iteration 700 with loss 0.25369. Total time 12.5913 hours\n",
      "Training at Epoch 27 iteration 800 with loss 0.29503. Total time 12.6030 hours\n",
      "Training at Epoch 27 iteration 900 with loss 0.20196. Total time 12.6144 hours\n",
      "Training at Epoch 27 iteration 1000 with loss 0.20818. Total time 12.6263 hours\n",
      "Training at Epoch 27 iteration 1100 with loss 0.24198. Total time 12.6377 hours\n",
      "Training at Epoch 27 iteration 1200 with loss 0.28538. Total time 12.6494 hours\n",
      "Training at Epoch 27 iteration 1300 with loss 0.31040. Total time 12.6611 hours\n",
      "Training at Epoch 27 iteration 1400 with loss 0.27230. Total time 12.6727 hours\n",
      "Training at Epoch 27 iteration 1500 with loss 0.24748. Total time 12.6844 hours\n",
      "Training at Epoch 27 iteration 1600 with loss 0.26622. Total time 12.6961 hours\n",
      "Training at Epoch 27 iteration 1700 with loss 0.22325. Total time 12.7077 hours\n",
      "Training at Epoch 27 iteration 1800 with loss 0.27876. Total time 12.7191 hours\n",
      "Training at Epoch 27 iteration 1900 with loss 0.33124. Total time 12.7311 hours\n",
      "Training at Epoch 27 iteration 2000 with loss 0.24225. Total time 12.7425 hours\n",
      "Training at Epoch 27 iteration 2100 with loss 0.25720. Total time 12.7541 hours\n",
      "Training at Epoch 27 iteration 2200 with loss 0.28110. Total time 12.7658 hours\n",
      "Training at Epoch 27 iteration 2300 with loss 0.28402. Total time 12.7775 hours\n",
      "Training at Epoch 27 iteration 2400 with loss 0.22150. Total time 12.7891 hours\n",
      "Training at Epoch 27 iteration 2500 with loss 0.24720. Total time 12.8008 hours\n",
      "Training at Epoch 27 iteration 2600 with loss 0.33944. Total time 12.8125 hours\n",
      "Training at Epoch 27 iteration 2700 with loss 0.23590. Total time 12.8241 hours\n",
      "Training at Epoch 27 iteration 2800 with loss 0.25050. Total time 12.8358 hours\n",
      "Training at Epoch 27 iteration 2900 with loss 0.30560. Total time 12.8475 hours\n",
      "Training at Epoch 27 iteration 3000 with loss 0.29337. Total time 12.8591 hours\n",
      "Training at Epoch 27 iteration 3100 with loss 0.28528. Total time 12.8708 hours\n",
      "Training at Epoch 27 iteration 3200 with loss 0.22184. Total time 12.8825 hours\n",
      "Training at Epoch 27 iteration 3300 with loss 0.23848. Total time 12.8941 hours\n",
      "Training at Epoch 27 iteration 3400 with loss 0.30178. Total time 12.9058 hours\n",
      "Training at Epoch 27 iteration 3500 with loss 0.24142. Total time 12.9172 hours\n",
      "Validation at Epoch 27, AUROC: 0.91820 , AUPRC: 0.80015 , F1: 0.70282 , Cross-entropy Loss: 4.67701\n",
      "Training at Epoch 28 iteration 0 with loss 0.31288. Total time 12.9875 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.31893. Total time 12.9991 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.25475. Total time 13.0108 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.25389. Total time 13.0225 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.29060. Total time 13.0341 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.25146. Total time 13.0458 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.21690. Total time 13.0575 hours\n",
      "Training at Epoch 28 iteration 700 with loss 0.25089. Total time 13.0691 hours\n",
      "Training at Epoch 28 iteration 800 with loss 0.25190. Total time 13.0808 hours\n",
      "Training at Epoch 28 iteration 900 with loss 0.21898. Total time 13.0925 hours\n",
      "Training at Epoch 28 iteration 1000 with loss 0.25245. Total time 13.1041 hours\n",
      "Training at Epoch 28 iteration 1100 with loss 0.30287. Total time 13.1158 hours\n",
      "Training at Epoch 28 iteration 1200 with loss 0.24593. Total time 13.1275 hours\n",
      "Training at Epoch 28 iteration 1300 with loss 0.26299. Total time 13.1391 hours\n",
      "Training at Epoch 28 iteration 1400 with loss 0.33221. Total time 13.1508 hours\n",
      "Training at Epoch 28 iteration 1500 with loss 0.26226. Total time 13.1625 hours\n",
      "Training at Epoch 28 iteration 1600 with loss 0.25574. Total time 13.1741 hours\n",
      "Training at Epoch 28 iteration 1700 with loss 0.33653. Total time 13.1858 hours\n",
      "Training at Epoch 28 iteration 1800 with loss 0.29167. Total time 13.1975 hours\n",
      "Training at Epoch 28 iteration 1900 with loss 0.23340. Total time 13.2088 hours\n",
      "Training at Epoch 28 iteration 2000 with loss 0.29882. Total time 13.2208 hours\n",
      "Training at Epoch 28 iteration 2100 with loss 0.26842. Total time 13.2325 hours\n",
      "Training at Epoch 28 iteration 2200 with loss 0.24705. Total time 13.2438 hours\n",
      "Training at Epoch 28 iteration 2300 with loss 0.28748. Total time 13.2555 hours\n",
      "Training at Epoch 28 iteration 2400 with loss 0.25555. Total time 13.2672 hours\n",
      "Training at Epoch 28 iteration 2500 with loss 0.28381. Total time 13.2788 hours\n",
      "Training at Epoch 28 iteration 2600 with loss 0.29490. Total time 13.2905 hours\n",
      "Training at Epoch 28 iteration 2700 with loss 0.30753. Total time 13.3022 hours\n",
      "Training at Epoch 28 iteration 2800 with loss 0.24943. Total time 13.3138 hours\n",
      "Training at Epoch 28 iteration 2900 with loss 0.24907. Total time 13.3255 hours\n",
      "Training at Epoch 28 iteration 3000 with loss 0.23007. Total time 13.3372 hours\n",
      "Training at Epoch 28 iteration 3100 with loss 0.31031. Total time 13.3488 hours\n",
      "Training at Epoch 28 iteration 3200 with loss 0.22622. Total time 13.3602 hours\n",
      "Training at Epoch 28 iteration 3300 with loss 0.28461. Total time 13.3719 hours\n",
      "Training at Epoch 28 iteration 3400 with loss 0.32863. Total time 13.3836 hours\n",
      "Training at Epoch 28 iteration 3500 with loss 0.23000. Total time 13.3952 hours\n",
      "Validation at Epoch 28, AUROC: 0.91849 , AUPRC: 0.80121 , F1: 0.71018 , Cross-entropy Loss: 4.68810\n",
      "Training at Epoch 29 iteration 0 with loss 0.26682. Total time 13.4652 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.24626. Total time 13.4769 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.23240. Total time 13.4886 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.29077. Total time 13.5002 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.25945. Total time 13.5119 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.20975. Total time 13.5236 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.34286. Total time 13.5355 hours\n",
      "Training at Epoch 29 iteration 700 with loss 0.31242. Total time 13.5472 hours\n",
      "Training at Epoch 29 iteration 800 with loss 0.31120. Total time 13.5588 hours\n",
      "Training at Epoch 29 iteration 900 with loss 0.24073. Total time 13.5705 hours\n",
      "Training at Epoch 29 iteration 1000 with loss 0.28225. Total time 13.5822 hours\n",
      "Training at Epoch 29 iteration 1100 with loss 0.30572. Total time 13.5938 hours\n",
      "Training at Epoch 29 iteration 1200 with loss 0.30326. Total time 13.6055 hours\n",
      "Training at Epoch 29 iteration 1300 with loss 0.25495. Total time 13.6172 hours\n",
      "Training at Epoch 29 iteration 1400 with loss 0.30306. Total time 13.6288 hours\n",
      "Training at Epoch 29 iteration 1500 with loss 0.27326. Total time 13.6405 hours\n",
      "Training at Epoch 29 iteration 1600 with loss 0.24889. Total time 13.6525 hours\n",
      "Training at Epoch 29 iteration 1700 with loss 0.29922. Total time 13.6638 hours\n",
      "Training at Epoch 29 iteration 1800 with loss 0.24238. Total time 13.6755 hours\n",
      "Training at Epoch 29 iteration 1900 with loss 0.23942. Total time 13.6872 hours\n",
      "Training at Epoch 29 iteration 2000 with loss 0.32940. Total time 13.6991 hours\n",
      "Training at Epoch 29 iteration 2100 with loss 0.29238. Total time 13.7108 hours\n",
      "Training at Epoch 29 iteration 2200 with loss 0.28296. Total time 13.7222 hours\n",
      "Training at Epoch 29 iteration 2300 with loss 0.28817. Total time 13.7338 hours\n",
      "Training at Epoch 29 iteration 2400 with loss 0.27899. Total time 13.7458 hours\n",
      "Training at Epoch 29 iteration 2500 with loss 0.26977. Total time 13.7575 hours\n",
      "Training at Epoch 29 iteration 2600 with loss 0.28133. Total time 13.7691 hours\n",
      "Training at Epoch 29 iteration 2700 with loss 0.25591. Total time 13.7808 hours\n",
      "Training at Epoch 29 iteration 2800 with loss 0.29103. Total time 13.7925 hours\n",
      "Training at Epoch 29 iteration 2900 with loss 0.21697. Total time 13.8041 hours\n",
      "Training at Epoch 29 iteration 3000 with loss 0.23869. Total time 13.8158 hours\n",
      "Training at Epoch 29 iteration 3100 with loss 0.25076. Total time 13.8275 hours\n",
      "Training at Epoch 29 iteration 3200 with loss 0.25908. Total time 13.8391 hours\n",
      "Training at Epoch 29 iteration 3300 with loss 0.26885. Total time 13.8508 hours\n",
      "Training at Epoch 29 iteration 3400 with loss 0.25426. Total time 13.8622 hours\n",
      "Training at Epoch 29 iteration 3500 with loss 0.22149. Total time 13.8738 hours\n",
      "Validation at Epoch 29, AUROC: 0.91974 , AUPRC: 0.80411 , F1: 0.72135 , Cross-entropy Loss: 4.67861\n",
      "Training at Epoch 30 iteration 0 with loss 0.25795. Total time 13.9441 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.23489. Total time 13.9558 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.26385. Total time 13.9675 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.25753. Total time 13.9791 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.21398. Total time 13.9908 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.27818. Total time 14.0025 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.30259. Total time 14.0141 hours\n",
      "Training at Epoch 30 iteration 700 with loss 0.24429. Total time 14.0258 hours\n",
      "Training at Epoch 30 iteration 800 with loss 0.27678. Total time 14.0375 hours\n",
      "Training at Epoch 30 iteration 900 with loss 0.25705. Total time 14.0491 hours\n",
      "Training at Epoch 30 iteration 1000 with loss 0.30609. Total time 14.0608 hours\n",
      "Training at Epoch 30 iteration 1100 with loss 0.31641. Total time 14.0725 hours\n",
      "Training at Epoch 30 iteration 1200 with loss 0.26482. Total time 14.0844 hours\n",
      "Training at Epoch 30 iteration 1300 with loss 0.20980. Total time 14.0961 hours\n",
      "Training at Epoch 30 iteration 1400 with loss 0.36368. Total time 14.1075 hours\n",
      "Training at Epoch 30 iteration 1500 with loss 0.28698. Total time 14.1191 hours\n",
      "Training at Epoch 30 iteration 1600 with loss 0.26442. Total time 14.1311 hours\n",
      "Training at Epoch 30 iteration 1700 with loss 0.28717. Total time 14.1427 hours\n",
      "Training at Epoch 30 iteration 1800 with loss 0.23154. Total time 14.1544 hours\n",
      "Training at Epoch 30 iteration 1900 with loss 0.22562. Total time 14.1661 hours\n",
      "Training at Epoch 30 iteration 2000 with loss 0.24222. Total time 14.1777 hours\n",
      "Training at Epoch 30 iteration 2100 with loss 0.23932. Total time 14.1894 hours\n",
      "Training at Epoch 30 iteration 2200 with loss 0.26728. Total time 14.2011 hours\n",
      "Training at Epoch 30 iteration 2300 with loss 0.25213. Total time 14.2127 hours\n",
      "Training at Epoch 30 iteration 2400 with loss 0.22479. Total time 14.2244 hours\n",
      "Training at Epoch 30 iteration 2500 with loss 0.25574. Total time 14.2361 hours\n",
      "Training at Epoch 30 iteration 2600 with loss 0.23374. Total time 14.2477 hours\n",
      "Training at Epoch 30 iteration 2700 with loss 0.27645. Total time 14.2594 hours\n",
      "Training at Epoch 30 iteration 2800 with loss 0.20083. Total time 14.2711 hours\n",
      "Training at Epoch 30 iteration 2900 with loss 0.24483. Total time 14.2827 hours\n",
      "Training at Epoch 30 iteration 3000 with loss 0.26318. Total time 14.2944 hours\n",
      "Training at Epoch 30 iteration 3100 with loss 0.31405. Total time 14.3061 hours\n",
      "Training at Epoch 30 iteration 3200 with loss 0.28933. Total time 14.3177 hours\n",
      "Training at Epoch 30 iteration 3300 with loss 0.26340. Total time 14.3294 hours\n",
      "Training at Epoch 30 iteration 3400 with loss 0.28142. Total time 14.3411 hours\n",
      "Training at Epoch 30 iteration 3500 with loss 0.29210. Total time 14.3527 hours\n",
      "Validation at Epoch 30, AUROC: 0.91897 , AUPRC: 0.80290 , F1: 0.71350 , Cross-entropy Loss: 4.64932\n",
      "--- Go for Testing ---\n",
      "Validation at Epoch 30 , AUROC: 0.91860 , AUPRC: 0.80164 , F1: 0.71902 , Cross-entropy Loss: 4.73992\n",
      "--- Training Finished ---\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qYP-pcmiRie0"
   },
   "source": [
    "net.save_model('/content/drive/MyDrive/CNN-CNN')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iKqev4jIZzJ"
   },
   "source": [
    "### Loading BindingDB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gPA9qtvkIZzJ"
   },
   "source": [
    "import os\n",
    "os.chdir('../')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ue1miHu-IZzJ"
   },
   "source": [
    "def download_BindingDB_edited(path = './data'):\n",
    "\n",
    "\tprint('Beginning to download dataset...')\n",
    "\n",
    "\tif not os.path.exists(path):\n",
    "\t    os.makedirs(path)\n",
    "\n",
    "\turl = 'https://www.bindingdb.org/bind/downloads/BindingDB_All_2021m4.tsv.zip'\n",
    "\tsaved_path = wget.download(url, path)\n",
    "\n",
    "\tprint('Beginning to extract zip file...')\n",
    "\twith ZipFile(saved_path, 'r') as zip:\n",
    "\t    zip.extractall(path = path)\n",
    "\t    print('Done!')\n",
    "\tpath = path + '/BindingDB_All.tsv'\n",
    "\treturn path"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4PAUHK_SIZzJ"
   },
   "source": [
    "X_drug, X_target, y  = process_BindingDB(download_BindingDB_edited('../data/BindingDB_All.tsv'),\n",
    "\t\t\t\t\t y = 'IC50', \n",
    "\t\t\t\t\t binary = True, \n",
    "\t\t\t\t\t convert_to_log = False,\n",
    "           threshold=30)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h7mA5fRH9i5"
   },
   "source": [
    "### Morgan-CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bzla7DI1IDZ7"
   },
   "source": [
    "drug_encoding, target_encoding = 'Morgan', 'CNN'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S-rWoG1PIDZ7"
   },
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random', \n",
    "                                frac=[0.7,0.1,0.2],\n",
    "                                random_seed=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TE6i5hVTIDZ8"
   },
   "source": [
    "config = generate_config(drug_encoding, \n",
    "                         target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 30, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OSD8ZGYsIDZ8"
   },
   "source": [
    "net = models.model_initialize(**config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ut68L6BIDZ9"
   },
   "source": [
    "net.train(train, val, test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CRPuFl36IDZ9"
   },
   "source": [
    "net.save_model('/content/drive/MyDrive/Morgan-CNN')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LMUBrO8LIot"
   },
   "source": [
    "### if you need to save the predictions, instead of using line  $net = models.model\\_initialize(**config)$ use code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KiT-U_h-LJT7"
   },
   "source": [
    "import pickle "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fHq2OsPiLQDH"
   },
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import SequentialSampler\n",
    "from torch import nn \n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, average_precision_score, f1_score, log_loss\n",
    "from lifelines.utils import concordance_index\n",
    "from scipy.stats import pearsonr\n",
    "import pickle \n",
    "torch.manual_seed(2)\n",
    "np.random.seed(3)\n",
    "import copy\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import os\n",
    "\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.model_helper import Encoder_MultipleLayers, Embeddings        \n",
    "from DeepPurpose.encoders import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class Classifier(nn.Sequential):\n",
    "\tdef __init__(self, model_drug, model_protein, **config):\n",
    "\t\tsuper(Classifier, self).__init__()\n",
    "\t\tself.input_dim_drug = config['hidden_dim_drug']\n",
    "\t\tself.input_dim_protein = config['hidden_dim_protein']\n",
    "\n",
    "\t\tself.model_drug = model_drug\n",
    "\t\tself.model_protein = model_protein\n",
    "\n",
    "\t\tself.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\t\tself.hidden_dims = config['cls_hidden_dims']\n",
    "\t\tlayer_size = len(self.hidden_dims) + 1\n",
    "\t\tdims = [self.input_dim_drug + self.input_dim_protein] + self.hidden_dims + [1]\n",
    "\t\t\n",
    "\t\tself.predictor = nn.ModuleList([nn.Linear(dims[i], dims[i+1]) for i in range(layer_size)])\n",
    "\n",
    "\tdef forward(self, v_D, v_P):\n",
    "\t\t# each encoding\n",
    "\t\tv_D = self.model_drug(v_D)\n",
    "\t\tv_P = self.model_protein(v_P)\n",
    "\t\t# concatenate and classify\n",
    "\t\tv_f = torch.cat((v_D, v_P), 1)\n",
    "\t\tfor i, l in enumerate(self.predictor):\n",
    "\t\t\tif i==(len(self.predictor)-1):\n",
    "\t\t\t\tv_f = l(v_f)\n",
    "\t\t\telse:\n",
    "\t\t\t\tv_f = F.relu(self.dropout(l(v_f)))\n",
    "\t\treturn v_f\n",
    "\n",
    "def model_initialize(**config):\n",
    "\tmodel = DBTA(**config)\n",
    "\treturn model\n",
    "\n",
    "def model_pretrained(path_dir = None, model = None):\n",
    "\tif model is not None:\n",
    "\t\tpath_dir = download_pretrained_model(model)\n",
    "\tconfig = load_dict(path_dir)\n",
    "\tmodel = DBTA(**config)\n",
    "\tmodel.load_pretrained(path_dir + '/model.pt')    \n",
    "\treturn model\n",
    "\n",
    "def repurpose(X_repurpose, target, model, drug_names = None, target_name = None, \n",
    "\t\t\t  result_folder = \"./result/\", convert_y = False, output_num_max = 10, verbose = True):\n",
    "\t# X_repurpose: a list of SMILES string\n",
    "\t# target: one target \n",
    "\t\n",
    "\tfo = os.path.join(result_folder, \"repurposing.txt\")\n",
    "\tprint_list = []\n",
    "\twith open(fo, 'w') as fout:\n",
    "\t\tprint('repurposing...')\n",
    "\t\tdf_data = data_process_repurpose_virtual_screening(X_repurpose, target, model.drug_encoding, model.target_encoding, 'repurposing')\n",
    "\t\ty_pred = model.predict(df_data)\n",
    "\n",
    "\t\tif convert_y:\n",
    "\t\t\ty_pred = convert_y_unit(np.array(y_pred), 'p', 'nM')\n",
    "\n",
    "\t\tprint('---------------')\n",
    "\t\tif target_name is not None:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint('Drug Repurposing Result for '+target_name)\n",
    "\t\tif model.binary:\n",
    "\t\t\ttable_header = [\"Rank\", \"Drug Name\", \"Target Name\", \"Interaction\", \"Probability\"]\n",
    "\t\telse:\n",
    "\t\t\t### regression \n",
    "\t\t\ttable_header = [\"Rank\", \"Drug Name\", \"Target Name\", \"Binding Score\"]\n",
    "\t\ttable = PrettyTable(table_header)\n",
    "\t\tif drug_names is None:\n",
    "\t\t\tdrug_names = ['Drug ' + str(i) for i in list(range(len(X_repurpose)))]\n",
    "\t\tif target_name is None:\n",
    "\t\t\ttarget_name = 'Target' \n",
    "\t\tif drug_names is not None:\n",
    "\t\t\tf_d = max([len(o) for o in drug_names]) + 1\n",
    "\t\t\tfor i in range(len(X_repurpose)):\n",
    "\t\t\t\tif model.binary:\n",
    "\t\t\t\t\tif y_pred[i] > 0.5:\n",
    "\t\t\t\t\t\tstring_lst = [drug_names[i], target_name, \"YES\", \"{0:.2f}\".format(y_pred[i])]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstring_lst = [drug_names[i], target_name, \"NO\", \"{0:.2f}\".format(y_pred[i])]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t#### regression \n",
    "\t\t\t\t\t#### Rank, Drug Name, Target Name, binding score \n",
    "\t\t\t\t\tstring_lst = [drug_names[i], target_name, \"{0:.2f}\".format(y_pred[i])]\n",
    "\t\t\t\t\tstring = 'Drug ' + '{:<{f_d}}'.format(drug_names[i], f_d =f_d) + \\\n",
    "\t\t\t\t\t\t' predicted to have binding affinity score ' + \"{0:.2f}\".format(y_pred[i])\n",
    "\t\t\t\t\t#print_list.append((string, y_pred[i]))\n",
    "\t\t\t\tprint_list.append((string_lst, y_pred[i]))\n",
    "\t\t\n",
    "\t\tif convert_y:\n",
    "\t\t\tprint_list.sort(key = lambda x:x[1])\n",
    "\t\telse:\n",
    "\t\t\tprint_list.sort(key = lambda x:x[1], reverse = True)\n",
    "\n",
    "\t\tprint_list = [i[0] for i in print_list]\n",
    "\t\tfor idx, lst in enumerate(print_list):\n",
    "\t\t\tlst = [str(idx + 1)] + lst \n",
    "\t\t\ttable.add_row(lst)\n",
    "\t\tfout.write(table.get_string())\n",
    "\tif verbose:\n",
    "\t\twith open(fo, 'r') as fin:\n",
    "\t\t\tlines = fin.readlines()\n",
    "\t\t\tfor idx, line in enumerate(lines):\n",
    "\t\t\t\tif idx < 13:\n",
    "\t\t\t\t\tprint(line, end = '')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint('checkout ' + fo + ' for the whole list')\n",
    "\t\t\t\t\tbreak\n",
    "\treturn y_pred\n",
    "\n",
    "def virtual_screening(X_repurpose, target, model, drug_names = None, target_names = None,\n",
    "\t\t\t\t\t  result_folder = \"./result/\", convert_y = False, output_num_max = 10, verbose = True):\n",
    "\t# X_repurpose: a list of SMILES string\n",
    "\t# target: a list of targets\n",
    "\tif isinstance(target, str):\n",
    "\t\ttarget = [target]\n",
    "\t\n",
    "\tfo = os.path.join(result_folder, \"virtual_screening.txt\")\n",
    "\t#if not model.binary:\n",
    "\t#\tprint_list = []\n",
    "\tprint_list = []\n",
    "\tif drug_names is None:\n",
    "\t\tdrug_names = ['Drug ' + str(i) for i in list(range(len(X_repurpose)))]\n",
    "\tif target_names is None:\n",
    "\t\ttarget_names = ['Target ' + str(i) for i in list(range(len(target)))]   \n",
    "\tif model.binary:\n",
    "\t\ttable_header = [\"Rank\", \"Drug Name\", \"Target Name\", \"Interaction\", \"Probability\"]\n",
    "\telse:\n",
    "\t\t### regression \n",
    "\t\ttable_header = [\"Rank\", \"Drug Name\", \"Target Name\", \"Binding Score\"]\n",
    "\ttable = PrettyTable(table_header)\n",
    "\n",
    "\twith open(fo,'w') as fout:\n",
    "\t\tprint('virtual screening...')\n",
    "\t\tdf_data = data_process_repurpose_virtual_screening(X_repurpose, target, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   model.drug_encoding, model.target_encoding, 'virtual screening')\n",
    "\t\ty_pred = model.predict(df_data)\n",
    "\n",
    "\t\tif convert_y:\n",
    "\t\t\ty_pred = convert_y_unit(np.array(y_pred), 'p', 'nM')\n",
    "\n",
    "\t\tprint('---------------')\n",
    "\t\tif drug_names is not None and target_names is not None:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint('Virtual Screening Result')\n",
    "\t\t\tf_d = max([len(o) for o in drug_names]) + 1\n",
    "\t\t\tf_p = max([len(o) for o in target_names]) + 1\n",
    "\t\t\tfor i in range(len(target)):\n",
    "\t\t\t\tif model.binary:\n",
    "\t\t\t\t\tif y_pred[i] > 0.5:\n",
    "\t\t\t\t\t\tstring_lst = [drug_names[i], target_names[i], \"YES\", \"{0:.2f}\".format(y_pred[i])]\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstring_lst = [drug_names[i], target_names[i], \"NO\", \"{0:.2f}\".format(y_pred[i])]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t### regression \n",
    "\t\t\t\t\tstring_lst = [drug_names[i], target_names[i], \"{0:.2f}\".format(y_pred[i])]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tprint_list.append((string_lst, y_pred[i]))\n",
    "\t\tif convert_y:\n",
    "\t\t\tprint_list.sort(key = lambda x:x[1])\n",
    "\t\telse:\n",
    "\t\t\tprint_list.sort(key = lambda x:x[1], reverse = True)\n",
    "\t\tprint_list = [i[0] for i in print_list]\n",
    "\t\tfor idx, lst in enumerate(print_list):\n",
    "\t\t\tlst = [str(idx+1)] + lst\n",
    "\t\t\ttable.add_row(lst)\n",
    "\t\tfout.write(table.get_string())\n",
    "\n",
    "\tif verbose:\n",
    "\t\twith open(fo, 'r') as fin:\n",
    "\t\t\tlines = fin.readlines()\n",
    "\t\t\tfor idx, line in enumerate(lines):\n",
    "\t\t\t\tif idx < 13:\n",
    "\t\t\t\t\tprint(line, end = '')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint('checkout ' + fo + ' for the whole list')\n",
    "\t\t\t\t\tbreak\n",
    "\t\tprint()\n",
    "\n",
    "\treturn y_pred\n",
    "\n",
    "def dgl_collate_func(x):\n",
    "\td, p, y = zip(*x)\n",
    "\timport dgl\n",
    "\td = dgl.batch(d)\n",
    "\treturn d, torch.tensor(p), torch.tensor(y)\n",
    "\n",
    "class DBTA:\n",
    "\t'''\n",
    "\t\tDrug Target Binding Affinity \n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, **config):\n",
    "\t\tdrug_encoding = config['drug_encoding']\n",
    "\t\ttarget_encoding = config['target_encoding']\n",
    "\n",
    "\t\tif drug_encoding == 'Morgan' or drug_encoding == 'ErG' or drug_encoding=='Pubchem' or drug_encoding=='Daylight' or drug_encoding=='rdkit_2d_normalized' or drug_encoding == 'ESPF':\n",
    "\t\t\t# Future TODO: support multiple encoding scheme for static input \n",
    "\t\t\tself.model_drug = MLP(config['input_dim_drug'], config['hidden_dim_drug'], config['mlp_hidden_dims_drug'])\n",
    "\t\telif drug_encoding == 'CNN':\n",
    "\t\t\tself.model_drug = CNN('drug', **config)\n",
    "\t\telif drug_encoding == 'CNN_RNN':\n",
    "\t\t\tself.model_drug = CNN_RNN('drug', **config)\n",
    "\t\telif drug_encoding == 'Transformer':\n",
    "\t\t\tself.model_drug = transformer('drug', **config)\n",
    "\t\telif drug_encoding == 'MPNN':\n",
    "\t\t\tself.model_drug = MPNN(config['hidden_dim_drug'], config['mpnn_depth'])\n",
    "\t\telif drug_encoding == 'DGL_GCN':\n",
    "\t\t\tself.model_drug = DGL_GCN(in_feats = 74, \n",
    "\t\t\t\t\t\t\t\t\thidden_feats = [config['gnn_hid_dim_drug']] * config['gnn_num_layers'], \n",
    "\t\t\t\t\t\t\t\t\tactivation = [config['gnn_activation']] * config['gnn_num_layers'], \n",
    "\t\t\t\t\t\t\t\t\tpredictor_dim = config['hidden_dim_drug'])\n",
    "\t\telif drug_encoding == 'DGL_NeuralFP':\n",
    "\t\t\tself.model_drug = DGL_NeuralFP(in_feats = 74, \n",
    "\t\t\t\t\t\t\t\t\thidden_feats = [config['gnn_hid_dim_drug']] * config['gnn_num_layers'], \n",
    "\t\t\t\t\t\t\t\t\tmax_degree = config['neuralfp_max_degree'],\n",
    "\t\t\t\t\t\t\t\t\tactivation = [config['gnn_activation']] * config['gnn_num_layers'], \n",
    "\t\t\t\t\t\t\t\t\tpredictor_hidden_size = config['neuralfp_predictor_hid_dim'],\n",
    "\t\t\t\t\t\t\t\t\tpredictor_dim = config['hidden_dim_drug'],\n",
    "\t\t\t\t\t\t\t\t\tpredictor_activation = config['neuralfp_predictor_activation'])\n",
    "\t\telif drug_encoding == 'DGL_GIN_AttrMasking':\n",
    "\t\t\tself.model_drug = DGL_GIN_AttrMasking(predictor_dim = config['hidden_dim_drug'])\n",
    "\t\telif drug_encoding == 'DGL_GIN_ContextPred':\n",
    "\t\t\tself.model_drug = DGL_GIN_ContextPred(predictor_dim = config['hidden_dim_drug'])\n",
    "\t\telif drug_encoding == 'DGL_AttentiveFP':\n",
    "\t\t\tself.model_drug = DGL_AttentiveFP(node_feat_size = 39, \n",
    "\t\t\t\t\t\t\t\t\t\t\tedge_feat_size = 11,  \n",
    "\t\t\t\t\t\t\t\t\t\t\tnum_layers = config['gnn_num_layers'], \n",
    "\t\t\t\t\t\t\t\t\t\t\tnum_timesteps = config['attentivefp_num_timesteps'], \n",
    "\t\t\t\t\t\t\t\t\t\t\tgraph_feat_size = config['gnn_hid_dim_drug'], \n",
    "\t\t\t\t\t\t\t\t\t\t\tpredictor_dim = config['hidden_dim_drug'])\n",
    "\t\telse:\n",
    "\t\t\traise AttributeError('Please use one of the available encoding method.')\n",
    "\n",
    "\t\tif target_encoding == 'AAC' or target_encoding == 'PseudoAAC' or  target_encoding == 'Conjoint_triad' or target_encoding == 'Quasi-seq' or target_encoding == 'ESPF':\n",
    "\t\t\tself.model_protein = MLP(config['input_dim_protein'], config['hidden_dim_protein'], config['mlp_hidden_dims_target'])\n",
    "\t\telif target_encoding == 'CNN':\n",
    "\t\t\tself.model_protein = CNN('protein', **config)\n",
    "\t\telif target_encoding == 'CNN_RNN':\n",
    "\t\t\tself.model_protein = CNN_RNN('protein', **config)\n",
    "\t\telif target_encoding == 'Transformer':\n",
    "\t\t\tself.model_protein = transformer('protein', **config)\n",
    "\t\telse:\n",
    "\t\t\traise AttributeError('Please use one of the available encoding method.')\n",
    "\n",
    "\t\tself.model = Classifier(self.model_drug, self.model_protein, **config)\n",
    "\t\tself.config = config\n",
    "\n",
    "\t\tif 'cuda_id' in self.config:\n",
    "\t\t\tif self.config['cuda_id'] is None:\n",
    "\t\t\t\tself.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.device = torch.device('cuda:' + str(self.config['cuda_id']) if torch.cuda.is_available() else 'cpu')\n",
    "\t\telse:\n",
    "\t\t\tself.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\t\t\n",
    "\t\tself.drug_encoding = drug_encoding\n",
    "\t\tself.target_encoding = target_encoding\n",
    "\t\tself.result_folder = config['result_folder']\n",
    "\t\tif not os.path.exists(self.result_folder):\n",
    "\t\t\tos.mkdir(self.result_folder)            \n",
    "\t\tself.binary = False\n",
    "\t\tif 'num_workers' not in self.config.keys():\n",
    "\t\t\tself.config['num_workers'] = 0\n",
    "\t\tif 'decay' not in self.config.keys():\n",
    "\t\t\tself.config['decay'] = 0\n",
    "\n",
    "\tdef test_(self, data_generator, model, repurposing_mode = False, test = False):\n",
    "\t\ty_pred = []\n",
    "\t\ty_label = []\n",
    "\t\tmodel.eval()\n",
    "\t\tfor i, (v_d, v_p, label) in enumerate(data_generator):\n",
    "\t\t\tif self.drug_encoding in [\"MPNN\", 'Transformer', 'DGL_GCN', 'DGL_NeuralFP', 'DGL_GIN_AttrMasking', 'DGL_GIN_ContextPred', 'DGL_AttentiveFP']:\n",
    "\t\t\t\tv_d = v_d\n",
    "\t\t\telse:\n",
    "\t\t\t\tv_d = v_d.float().to(self.device)                \n",
    "\t\t\tif self.target_encoding == 'Transformer':\n",
    "\t\t\t\tv_p = v_p\n",
    "\t\t\telse:\n",
    "\t\t\t\tv_p = v_p.float().to(self.device)                \n",
    "\t\t\tscore = self.model(v_d, v_p)\n",
    "\t\t\tif self.binary:\n",
    "\t\t\t\tm = torch.nn.Sigmoid()\n",
    "\t\t\t\tlogits = torch.squeeze(m(score)).detach().cpu().numpy()\n",
    "\t\t\telse:\n",
    "\t\t\t\tloss_fct = torch.nn.MSELoss()\n",
    "\t\t\t\tn = torch.squeeze(score, 1)\n",
    "\t\t\t\tloss = loss_fct(n, Variable(torch.from_numpy(np.array(label)).float()).to(self.device))\n",
    "\t\t\t\tlogits = torch.squeeze(score).detach().cpu().numpy()\n",
    "\t\t\tlabel_ids = label.to('cpu').numpy()\n",
    "\t\t\ty_label = y_label + label_ids.flatten().tolist()\n",
    "\t\t\ty_pred = y_pred + logits.flatten().tolist()\n",
    "\t\t\toutputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n",
    "\t\tmodel.train()\n",
    "\t\tif self.binary:\n",
    "\t\t\tif repurposing_mode:\n",
    "\t\t\t\treturn y_pred\n",
    "\t\t\t## ROC-AUC curve\n",
    "\t\t\tif test:\n",
    "\t\t\t\troc_auc_file = os.path.join(self.result_folder, \"roc-auc.jpg\")\n",
    "\t\t\t\tplt.figure(0)\n",
    "\t\t\t\troc_curve(y_pred, y_label, roc_auc_file, self.drug_encoding + '_' + self.target_encoding)\n",
    "\t\t\t\tplt.figure(1)\n",
    "\t\t\t\tpr_auc_file = os.path.join(self.result_folder, \"pr-auc.jpg\")\n",
    "\t\t\t\tprauc_curve(y_pred, y_label, pr_auc_file, self.drug_encoding + '_' + self.target_encoding)\n",
    "\t\t\t\tprint(\"aida test\")\n",
    "\t\t\t\tpickle.dump(y_pred,open(\"/content/drive/MyDrive/y_pred_saving.p\",\"wb\"))\n",
    "\t\t\t\tpickle.dump(y_label,open(\"/content/drive/MyDrive/y_label_saving.p\",\"wb\"))\n",
    "\n",
    "\t\t\treturn roc_auc_score(y_label, y_pred), average_precision_score(y_label, y_pred), f1_score(y_label, outputs), log_loss(y_label, outputs), y_pred\n",
    "\t\telse:\n",
    "\t\t\tif repurposing_mode:\n",
    "\t\t\t\treturn y_pred\n",
    "\t\t\treturn mean_squared_error(y_label, y_pred), pearsonr(y_label, y_pred)[0], pearsonr(y_label, y_pred)[1], concordance_index(y_label, y_pred), y_pred, loss\n",
    "\n",
    "\tdef train(self, train, val = None, test = None, verbose = True):\n",
    "\t\tif len(train.Label.unique()) == 2:\n",
    "\t\t\tself.binary = True\n",
    "\t\t\tself.config['binary'] = True\n",
    "\n",
    "\t\tlr = self.config['LR']\n",
    "\t\tdecay = self.config['decay']\n",
    "\t\tBATCH_SIZE = self.config['batch_size']\n",
    "\t\ttrain_epoch = self.config['train_epoch']\n",
    "\t\tif 'test_every_X_epoch' in self.config.keys():\n",
    "\t\t\ttest_every_X_epoch = self.config['test_every_X_epoch']\n",
    "\t\telse:     \n",
    "\t\t\ttest_every_X_epoch = 40\n",
    "\t\tloss_history = []\n",
    "\n",
    "\t\tself.model = self.model.to(self.device)\n",
    "\n",
    "\t\t# support multiple GPUs\n",
    "\t\tif torch.cuda.device_count() > 1:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(\"Let's use \" + str(torch.cuda.device_count()) + \" GPUs!\")\n",
    "\t\t\tself.model = nn.DataParallel(self.model, dim = 0)\n",
    "\t\telif torch.cuda.device_count() == 1:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(\"Let's use \" + str(torch.cuda.device_count()) + \" GPU!\")\n",
    "\t\telse:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(\"Let's use CPU/s!\")\n",
    "\t\t# Future TODO: support multiple optimizers with parameters\n",
    "\t\topt = torch.optim.Adam(self.model.parameters(), lr = lr, weight_decay = decay)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('--- Data Preparation ---')\n",
    "\n",
    "\t\tparams = {'batch_size': BATCH_SIZE,\n",
    "\t    \t\t'shuffle': True,\n",
    "\t    \t\t'num_workers': self.config['num_workers'],\n",
    "\t    \t\t'drop_last': False}\n",
    "\t\tif (self.drug_encoding == \"MPNN\"):\n",
    "\t\t\tparams['collate_fn'] = mpnn_collate_func\n",
    "\t\telif self.drug_encoding in ['DGL_GCN', 'DGL_NeuralFP', 'DGL_GIN_AttrMasking', 'DGL_GIN_ContextPred', 'DGL_AttentiveFP']:\n",
    "\t\t\tparams['collate_fn'] = dgl_collate_func\n",
    "\n",
    "\t\ttraining_generator = data.DataLoader(data_process_loader(train.index.values, train.Label.values, train, **self.config), **params)\n",
    "\t\tif val is not None:\n",
    "\t\t\tvalidation_generator = data.DataLoader(data_process_loader(val.index.values, val.Label.values, val, **self.config), **params)\n",
    "\t\t\n",
    "\t\tif test is not None:\n",
    "\t\t\tinfo = data_process_loader(test.index.values, test.Label.values, test, **self.config)\n",
    "\t\t\tparams_test = {'batch_size': BATCH_SIZE,\n",
    "\t\t\t\t\t'shuffle': False,\n",
    "\t\t\t\t\t'num_workers': self.config['num_workers'],\n",
    "\t\t\t\t\t'drop_last': False,\n",
    "\t\t\t\t\t'sampler':SequentialSampler(info)}\n",
    "        \n",
    "\t\t\tif (self.drug_encoding == \"MPNN\"):\n",
    "\t\t\t\tparams_test['collate_fn'] = mpnn_collate_func\n",
    "\t\t\telif self.drug_encoding in ['DGL_GCN', 'DGL_NeuralFP', 'DGL_GIN_AttrMasking', 'DGL_GIN_ContextPred', 'DGL_AttentiveFP']:\n",
    "\t\t\t\tparams_test['collate_fn'] = dgl_collate_func\n",
    "\t\t\ttesting_generator = data.DataLoader(data_process_loader(test.index.values, test.Label.values, test, **self.config), **params_test)\n",
    "\n",
    "\t\t# early stopping\n",
    "\t\tif self.binary:\n",
    "\t\t\tmax_auc = 0\n",
    "\t\telse:\n",
    "\t\t\tmax_MSE = 10000\n",
    "\t\tmodel_max = copy.deepcopy(self.model)\n",
    "\n",
    "\t\tvalid_metric_record = []\n",
    "\t\tvalid_metric_header = [\"# epoch\"] \n",
    "\t\tif self.binary:\n",
    "\t\t\tvalid_metric_header.extend([\"AUROC\", \"AUPRC\", \"F1\"])\n",
    "\t\telse:\n",
    "\t\t\tvalid_metric_header.extend([\"MSE\", \"Pearson Correlation\", \"with p-value\", \"Concordance Index\"])\n",
    "\t\ttable = PrettyTable(valid_metric_header)\n",
    "\t\tfloat2str = lambda x:'%0.4f'%x\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('--- Go for Training ---')\n",
    "\t\twriter = SummaryWriter()\n",
    "\t\tt_start = time() \n",
    "\t\titeration_loss = 0\n",
    "\t\tfor epo in range(train_epoch):\n",
    "\t\t\tfor i, (v_d, v_p, label) in enumerate(training_generator):\n",
    "\t\t\t\tif self.target_encoding == 'Transformer':\n",
    "\t\t\t\t\tv_p = v_p\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tv_p = v_p.float().to(self.device) \n",
    "\t\t\t\tif self.drug_encoding in [\"MPNN\", 'Transformer', 'DGL_GCN', 'DGL_NeuralFP', 'DGL_GIN_AttrMasking', 'DGL_GIN_ContextPred', 'DGL_AttentiveFP']:\n",
    "\t\t\t\t\tv_d = v_d\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tv_d = v_d.float().to(self.device)                \n",
    "\t\t\t\t\t#score = self.model(v_d, v_p.float().to(self.device))\n",
    "               \n",
    "\t\t\t\tscore = self.model(v_d, v_p)\n",
    "\t\t\t\tlabel = Variable(torch.from_numpy(np.array(label)).float()).to(self.device)\n",
    "\n",
    "\t\t\t\tif self.binary:\n",
    "\t\t\t\t\tloss_fct = torch.nn.BCELoss()\n",
    "\t\t\t\t\tm = torch.nn.Sigmoid()\n",
    "\t\t\t\t\tn = torch.squeeze(m(score), 1)\n",
    "\t\t\t\t\tloss = loss_fct(n, label)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tloss_fct = torch.nn.MSELoss()\n",
    "\t\t\t\t\tn = torch.squeeze(score, 1)\n",
    "\t\t\t\t\tloss = loss_fct(n, label)\n",
    "\t\t\t\tloss_history.append(loss.item())\n",
    "\t\t\t\twriter.add_scalar(\"Loss/train\", loss.item(), iteration_loss)\n",
    "\t\t\t\titeration_loss += 1\n",
    "\n",
    "\t\t\t\topt.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\topt.step()\n",
    "\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tif (i % 100 == 0):\n",
    "\t\t\t\t\t\tt_now = time()\n",
    "\t\t\t\t\t\tprint('Training at Epoch ' + str(epo + 1) + ' iteration ' + str(i) + \\\n",
    "\t\t\t\t\t\t\t' with loss ' + str(loss.cpu().detach().numpy())[:7] +\\\n",
    "\t\t\t\t\t\t\t\". Total time \" + str(int(t_now - t_start)/3600)[:7] + \" hours\") \n",
    "\t\t\t\t\t\t### record total run time\n",
    "\t\t\t\t\t\t\n",
    "\t\t\tif val is not None:\n",
    "\t\t\t\t##### validate, select the best model up to now \n",
    "\t\t\t\twith torch.set_grad_enabled(False):\n",
    "\t\t\t\t\tif self.binary:  \n",
    "\t\t\t\t\t\t## binary: ROC-AUC, PR-AUC, F1, cross-entropy loss\n",
    "\t\t\t\t\t\tauc, auprc, f1, loss, logits = self.test_(validation_generator, self.model)\n",
    "\t\t\t\t\t\tlst = [\"epoch \" + str(epo)] + list(map(float2str,[auc, auprc, f1]))\n",
    "\t\t\t\t\t\tvalid_metric_record.append(lst)\n",
    "\t\t\t\t\t\tif auc > max_auc:\n",
    "\t\t\t\t\t\t\tmodel_max = copy.deepcopy(self.model)\n",
    "\t\t\t\t\t\t\tmax_auc = auc   \n",
    "\t\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\t\tprint('Validation at Epoch '+ str(epo + 1) + ', AUROC: ' + str(auc)[:7] + \\\n",
    "\t\t\t\t\t\t\t  ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + \\\n",
    "\t\t\t\t\t\t\t  str(loss)[:7])\n",
    "\t\t\t\t\telse:  \n",
    "\t\t\t\t\t\t### regression: MSE, Pearson Correlation, with p-value, Concordance Index  \n",
    "\t\t\t\t\t\tmse, r2, p_val, CI, logits, loss_val = self.test_(validation_generator, self.model)\n",
    "\t\t\t\t\t\tlst = [\"epoch \" + str(epo)] + list(map(float2str,[mse, r2, p_val, CI]))\n",
    "\t\t\t\t\t\tvalid_metric_record.append(lst)\n",
    "\t\t\t\t\t\tif mse < max_MSE:\n",
    "\t\t\t\t\t\t\tmodel_max = copy.deepcopy(self.model)\n",
    "\t\t\t\t\t\t\tmax_MSE = mse\n",
    "\t\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\t\tprint('Validation at Epoch '+ str(epo + 1) + ' with loss:' + str(loss_val.item())[:7] +', MSE: ' + str(mse)[:7] + ' , Pearson Correlation: '\\\n",
    "\t\t\t\t\t\t\t + str(r2)[:7] + ' with p-value: ' + str(f\"{p_val:.2E}\") +' , Concordance Index: '+str(CI)[:7])\n",
    "\t\t\t\t\t\t\twriter.add_scalar(\"valid/mse\", mse, epo)\n",
    "\t\t\t\t\t\t\twriter.add_scalar(\"valid/pearson_correlation\", r2, epo)\n",
    "\t\t\t\t\t\t\twriter.add_scalar(\"valid/concordance_index\", CI, epo)\n",
    "\t\t\t\t\t\t\twriter.add_scalar(\"Loss/valid\", loss_val.item(), iteration_loss)\n",
    "\t\t\t\ttable.add_row(lst)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmodel_max = copy.deepcopy(self.model)\n",
    "\n",
    "\t\t# load early stopped model\n",
    "\t\tself.model = model_max\n",
    "\n",
    "\t\tif val is not None:\n",
    "\t\t\t#### after training \n",
    "\t\t\tprettytable_file = os.path.join(self.result_folder, \"valid_markdowntable.txt\")\n",
    "\t\t\twith open(prettytable_file, 'w') as fp:\n",
    "\t\t\t\tfp.write(table.get_string())\n",
    "\n",
    "\t\tif test is not None:\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint('--- Go for Testing ---')\n",
    "\t\t\tif self.binary:\n",
    "\t\t\t\tauc, auprc, f1, loss, logits = self.test_(testing_generator, model_max, test = True)\n",
    "\t\t\t\ttest_table = PrettyTable([\"AUROC\", \"AUPRC\", \"F1\"])\n",
    "\t\t\t\ttest_table.add_row(list(map(float2str, [auc, auprc, f1])))\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint('Validation at Epoch '+ str(epo + 1) + ' , AUROC: ' + str(auc)[:7] + \\\n",
    "\t\t\t\t\t  ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + \\\n",
    "\t\t\t\t\t  str(loss)[:7])\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tmse, r2, p_val, CI, logits, loss_test = self.test_(testing_generator, model_max)\n",
    "\t\t\t\ttest_table = PrettyTable([\"MSE\", \"Pearson Correlation\", \"with p-value\", \"Concordance Index\"])\n",
    "\t\t\t\ttest_table.add_row(list(map(float2str, [mse, r2, p_val, CI])))\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint('Testing MSE: ' + str(mse) + ' , Pearson Correlation: ' + str(r2) \n",
    "\t\t\t\t\t  + ' with p-value: ' + str(f\"{p_val:.2E}\") +' , Concordance Index: '+str(CI))\n",
    "\t\t\tnp.save(os.path.join(self.result_folder, str(self.drug_encoding) + '_' + str(self.target_encoding) \n",
    "\t\t\t\t     + '_logits.npy'), np.array(logits))                \n",
    "\t\n",
    "\t\t\t######### learning record ###########\n",
    "\n",
    "\t\t\t### 1. test results\n",
    "\t\t\tprettytable_file = os.path.join(self.result_folder, \"test_markdowntable.txt\")\n",
    "\t\t\twith open(prettytable_file, 'w') as fp:\n",
    "\t\t\t\tfp.write(test_table.get_string())\n",
    "\n",
    "\t\t### 2. learning curve \n",
    "\t\tfontsize = 16\n",
    "\t\titer_num = list(range(1,len(loss_history)+1))\n",
    "\t\tplt.figure(3)\n",
    "\t\tplt.plot(iter_num, loss_history, \"bo-\")\n",
    "\t\tplt.xlabel(\"iteration\", fontsize = fontsize)\n",
    "\t\tplt.ylabel(\"loss value\", fontsize = fontsize)\n",
    "\t\tpkl_file = os.path.join(self.result_folder, \"loss_curve_iter.pkl\")\n",
    "\t\twith open(pkl_file, 'wb') as pck:\n",
    "\t\t\tpickle.dump(loss_history, pck)\n",
    "\n",
    "\t\tfig_file = os.path.join(self.result_folder, \"loss_curve.png\")\n",
    "\t\tplt.savefig(fig_file)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('--- Training Finished ---')\n",
    "\t\t\twriter.flush()\n",
    "\t\t\twriter.close()\n",
    "          \n",
    "\n",
    "\tdef predict(self, df_data):\n",
    "\t\t'''\n",
    "\t\t\tutils.data_process_repurpose_virtual_screening \n",
    "\t\t\tpd.DataFrame\n",
    "\t\t'''\n",
    "\t\tprint('predicting...')\n",
    "\t\tinfo = data_process_loader(df_data.index.values, df_data.Label.values, df_data, **self.config)\n",
    "\t\tself.model.to(self.device)\n",
    "\t\tparams = {'batch_size': self.config['batch_size'],\n",
    "\t\t\t\t'shuffle': False,\n",
    "\t\t\t\t'num_workers': self.config['num_workers'],\n",
    "\t\t\t\t'drop_last': False,\n",
    "\t\t\t\t'sampler':SequentialSampler(info)}\n",
    "\n",
    "\t\tif (self.drug_encoding == \"MPNN\"):\n",
    "\t\t\tparams['collate_fn'] = mpnn_collate_func\n",
    "\t\telif self.drug_encoding in ['DGL_GCN', 'DGL_NeuralFP', 'DGL_GIN_AttrMasking', 'DGL_GIN_ContextPred', 'DGL_AttentiveFP']:\n",
    "\t\t\tparams['collate_fn'] = dgl_collate_func\n",
    "\n",
    "\t\tgenerator = data.DataLoader(info, **params)\n",
    "\n",
    "\t\tscore = self.test_(generator, self.model, repurposing_mode = True)\n",
    "\t\treturn score\n",
    "\n",
    "\tdef save_model(self, path_dir):\n",
    "\t\tif not os.path.exists(path_dir):\n",
    "\t\t\tos.makedirs(path_dir)\n",
    "\t\ttorch.save(self.model.state_dict(), path_dir + '/model.pt')\n",
    "\t\tsave_dict(path_dir, self.config)\n",
    "\n",
    "\tdef load_pretrained(self, path):\n",
    "\t\tif not os.path.exists(path):\n",
    "\t\t\tos.makedirs(path)\n",
    "\n",
    "\t\tstate_dict = torch.load(path, map_location = torch.device('cpu'))\n",
    "\t\t# to support training from multi-gpus data-parallel:\n",
    "        \n",
    "\t\tif next(iter(state_dict))[:7] == 'module.':\n",
    "\t\t\t# the pretrained model is from data-parallel module\n",
    "\t\t\tfrom collections import OrderedDict\n",
    "\t\t\tnew_state_dict = OrderedDict()\n",
    "\t\t\tfor k, v in state_dict.items():\n",
    "\t\t\t\tname = k[7:] # remove `module.`\n",
    "\t\t\t\tnew_state_dict[name] = v\n",
    "\t\t\tstate_dict = new_state_dict\n",
    "\n",
    "\t\tself.model.load_state_dict(state_dict)\n",
    "\n",
    "\t\tself.binary = self.config['binary']"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}