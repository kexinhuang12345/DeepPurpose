{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [13:24:18] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Done!\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_drug, X_target, y = load_process_KIBA('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 142.23532. Total time 0.001388888888888889 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.9404517. Total time 0.015277777777777777 hours\n",
      "Training at Epoch 1 iteration 200 with loss 0.6340587. Total time 0.029166666666666667 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.6004406. Total time 0.043055555555555555 hours\n",
      "Validation at Epoch 1 , MSE: 0.4772597502150917 , Pearson Correlation: 0.6046152120352799 with p-value: 0.0 , Concordance Index: 0.7179067245572882\n",
      "Training at Epoch 2 iteration 0 with loss 0.68283796. Total time 0.05361111111111111 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.7588134. Total time 0.0675 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.62654424. Total time 0.08138888888888889 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.41064706. Total time 0.09527777777777778 hours\n",
      "Validation at Epoch 2 , MSE: 0.3975326205917186 , Pearson Correlation: 0.6597945804299842 with p-value: 0.0 , Concordance Index: 0.7569214372821397\n",
      "Training at Epoch 3 iteration 0 with loss 0.54240036. Total time 0.10583333333333333 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.60198176. Total time 0.12 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.63948596. Total time 0.13416666666666666 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.5311142. Total time 0.14805555555555555 hours\n",
      "Validation at Epoch 3 , MSE: 0.5072459113225285 , Pearson Correlation: 0.6731897100171323 with p-value: 0.0 , Concordance Index: 0.7651234066760404\n",
      "Training at Epoch 4 iteration 0 with loss 0.6546687. Total time 0.15861111111111112 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.5178716. Total time 0.17277777777777778 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.43914706. Total time 0.18694444444444444 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.6344274. Total time 0.20083333333333334 hours\n",
      "Validation at Epoch 4 , MSE: 0.4378399459311358 , Pearson Correlation: 0.6762341309014038 with p-value: 0.0 , Concordance Index: 0.7680835765392795\n",
      "Training at Epoch 5 iteration 0 with loss 0.6268727. Total time 0.21138888888888888 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.5387401. Total time 0.22555555555555556 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.55998224. Total time 0.23944444444444443 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.523703. Total time 0.25333333333333335 hours\n",
      "Validation at Epoch 5 , MSE: 0.4320250092718285 , Pearson Correlation: 0.681285998158111 with p-value: 0.0 , Concordance Index: 0.7714687014811638\n",
      "Training at Epoch 6 iteration 0 with loss 0.48968476. Total time 0.26361111111111113 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.5930452. Total time 0.2777777777777778 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.45677137. Total time 0.29194444444444445 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.75531805. Total time 0.30722222222222223 hours\n",
      "Validation at Epoch 6 , MSE: 0.41555845499113925 , Pearson Correlation: 0.6806958385197729 with p-value: 0.0 , Concordance Index: 0.7714081083356349\n",
      "Training at Epoch 7 iteration 0 with loss 0.50352263. Total time 0.3175 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.61556673. Total time 0.33166666666666667 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.38061422. Total time 0.34555555555555556 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.44105774. Total time 0.3597222222222222 hours\n",
      "Validation at Epoch 7 , MSE: 0.417257627257141 , Pearson Correlation: 0.6830130985127045 with p-value: 0.0 , Concordance Index: 0.7729257931398801\n",
      "Training at Epoch 8 iteration 0 with loss 0.5151714. Total time 0.36972222222222223 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.50841993. Total time 0.3838888888888889 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.46923038. Total time 0.3977777777777778 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.6494567. Total time 0.4116666666666667 hours\n",
      "Validation at Epoch 8 , MSE: 0.3793269284739077 , Pearson Correlation: 0.6824860330390592 with p-value: 0.0 , Concordance Index: 0.7707604253393352\n",
      "Training at Epoch 9 iteration 0 with loss 0.51066476. Total time 0.4216666666666667 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.53950864. Total time 0.43583333333333335 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.4078983. Total time 0.44972222222222225 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.44712964. Total time 0.4633333333333333 hours\n",
      "Validation at Epoch 9 , MSE: 0.393751301082434 , Pearson Correlation: 0.6840961276241059 with p-value: 0.0 , Concordance Index: 0.7717791599095991\n",
      "Training at Epoch 10 iteration 0 with loss 0.5065906. Total time 0.4736111111111111 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.55432427. Total time 0.4880555555555556 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.65189385. Total time 0.5019444444444444 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.6325863. Total time 0.5161111111111111 hours\n",
      "Validation at Epoch 10 , MSE: 0.37773922395335824 , Pearson Correlation: 0.6822751864803925 with p-value: 0.0 , Concordance Index: 0.7727946898161272\n",
      "Training at Epoch 11 iteration 0 with loss 0.44107294. Total time 0.5263888888888889 hours\n"
     ]
    }
   ],
   "source": [
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_morgan_cnn_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_morgan_aac_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_daylight_aac_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
