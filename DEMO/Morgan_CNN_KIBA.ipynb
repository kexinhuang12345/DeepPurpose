{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:34:27] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Done!\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_drug, X_target, y = load_process_KIBA('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 142.235. Total time 0.00055 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.94045. Total time 0.01305 hours\n",
      "Training at Epoch 1 iteration 200 with loss 0.63405. Total time 0.025 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.60044. Total time 0.03694 hours\n",
      "Validation at Epoch 1 , MSE: 0.47725 , Pearson Correlation: 0.60461 with p-value: 0.0 , Concordance Index: 0.71790\n",
      "Training at Epoch 2 iteration 0 with loss 0.68283. Total time 0.04555 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.75881. Total time 0.05777 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.62654. Total time 0.07 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.41064. Total time 0.08222 hours\n",
      "Validation at Epoch 2 , MSE: 0.39753 , Pearson Correlation: 0.65979 with p-value: 0.0 , Concordance Index: 0.75692\n",
      "Training at Epoch 3 iteration 0 with loss 0.54240. Total time 0.09055 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.60198. Total time 0.10305 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.63948. Total time 0.11527 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.53111. Total time 0.1275 hours\n",
      "Validation at Epoch 3 , MSE: 0.50724 , Pearson Correlation: 0.67318 with p-value: 0.0 , Concordance Index: 0.76512\n",
      "Training at Epoch 4 iteration 0 with loss 0.65466. Total time 0.13583 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.51787. Total time 0.14833 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.43914. Total time 0.16027 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.63442. Total time 0.17277 hours\n",
      "Validation at Epoch 4 , MSE: 0.43783 , Pearson Correlation: 0.67623 with p-value: 0.0 , Concordance Index: 0.76808\n",
      "Training at Epoch 5 iteration 0 with loss 0.62687. Total time 0.18138 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.53874. Total time 0.19416 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.55998. Total time 0.20694 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.52370. Total time 0.21944 hours\n",
      "Validation at Epoch 5 , MSE: 0.43202 , Pearson Correlation: 0.68128 with p-value: 0.0 , Concordance Index: 0.77146\n",
      "Training at Epoch 6 iteration 0 with loss 0.48968. Total time 0.22833 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.59304. Total time 0.24083 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.45677. Total time 0.25333 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.75531. Total time 0.26555 hours\n",
      "Validation at Epoch 6 , MSE: 0.41555 , Pearson Correlation: 0.68069 with p-value: 0.0 , Concordance Index: 0.77140\n",
      "Training at Epoch 7 iteration 0 with loss 0.50352. Total time 0.27416 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.61556. Total time 0.28666 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.38061. Total time 0.29916 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.44105. Total time 0.31138 hours\n",
      "Validation at Epoch 7 , MSE: 0.41725 , Pearson Correlation: 0.68301 with p-value: 0.0 , Concordance Index: 0.77292\n",
      "Training at Epoch 8 iteration 0 with loss 0.51517. Total time 0.31972 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.50841. Total time 0.33277 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.46923. Total time 0.34555 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.64945. Total time 0.35833 hours\n",
      "Validation at Epoch 8 , MSE: 0.37932 , Pearson Correlation: 0.68248 with p-value: 0.0 , Concordance Index: 0.77076\n",
      "Training at Epoch 9 iteration 0 with loss 0.51066. Total time 0.36722 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.53950. Total time 0.37972 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.40789. Total time 0.39194 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.44712. Total time 0.40416 hours\n",
      "Validation at Epoch 9 , MSE: 0.39375 , Pearson Correlation: 0.68409 with p-value: 0.0 , Concordance Index: 0.77177\n",
      "Training at Epoch 10 iteration 0 with loss 0.50659. Total time 0.41277 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.55432. Total time 0.42527 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.65189. Total time 0.4375 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.63270. Total time 0.45 hours\n",
      "Validation at Epoch 10 , MSE: 0.37784 , Pearson Correlation: 0.68217 with p-value: 0.0 , Concordance Index: 0.77257\n",
      "Training at Epoch 11 iteration 0 with loss 0.44117. Total time 0.45833 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.43851. Total time 0.47111 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.53032. Total time 0.48333 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.49034. Total time 0.49555 hours\n",
      "Validation at Epoch 11 , MSE: 0.37928 , Pearson Correlation: 0.68479 with p-value: 0.0 , Concordance Index: 0.77371\n",
      "Training at Epoch 12 iteration 0 with loss 0.45177. Total time 0.50416 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.51149. Total time 0.51666 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.67271. Total time 0.52888 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.43067. Total time 0.54111 hours\n",
      "Validation at Epoch 12 , MSE: 0.38338 , Pearson Correlation: 0.68669 with p-value: 0.0 , Concordance Index: 0.77842\n",
      "Training at Epoch 13 iteration 0 with loss 0.49098. Total time 0.54972 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.55358. Total time 0.56222 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.52704. Total time 0.57416 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.40064. Total time 0.58638 hours\n",
      "Validation at Epoch 13 , MSE: 0.35583 , Pearson Correlation: 0.71362 with p-value: 0.0 , Concordance Index: 0.78512\n",
      "Training at Epoch 14 iteration 0 with loss 0.38204. Total time 0.595 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.43559. Total time 0.6075 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.53430. Total time 0.61972 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.53650. Total time 0.63194 hours\n",
      "Validation at Epoch 14 , MSE: 0.33676 , Pearson Correlation: 0.72565 with p-value: 0.0 , Concordance Index: 0.78215\n",
      "Training at Epoch 15 iteration 0 with loss 0.52765. Total time 0.64027 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.36429. Total time 0.65305 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.44191. Total time 0.66527 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.51651. Total time 0.6775 hours\n",
      "Validation at Epoch 15 , MSE: 0.33698 , Pearson Correlation: 0.73467 with p-value: 0.0 , Concordance Index: 0.79324\n",
      "Training at Epoch 16 iteration 0 with loss 0.37593. Total time 0.68611 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.57813. Total time 0.69861 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.58615. Total time 0.71055 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.36974. Total time 0.72277 hours\n",
      "Validation at Epoch 16 , MSE: 0.36325 , Pearson Correlation: 0.73725 with p-value: 0.0 , Concordance Index: 0.79126\n",
      "Training at Epoch 17 iteration 0 with loss 0.42159. Total time 0.73138 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.37390. Total time 0.74388 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.56896. Total time 0.75611 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.39031. Total time 0.76861 hours\n",
      "Validation at Epoch 17 , MSE: 0.31397 , Pearson Correlation: 0.74458 with p-value: 0.0 , Concordance Index: 0.79580\n",
      "Training at Epoch 18 iteration 0 with loss 0.49368. Total time 0.77694 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.35921. Total time 0.78972 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.38002. Total time 0.80194 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.54702. Total time 0.81416 hours\n",
      "Validation at Epoch 18 , MSE: 0.30907 , Pearson Correlation: 0.74916 with p-value: 0.0 , Concordance Index: 0.80035\n",
      "Training at Epoch 19 iteration 0 with loss 0.39410. Total time 0.82277 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.40456. Total time 0.83527 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.50752. Total time 0.8475 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.38820. Total time 0.85972 hours\n",
      "Validation at Epoch 19 , MSE: 0.52840 , Pearson Correlation: 0.75290 with p-value: 0.0 , Concordance Index: 0.79735\n",
      "Training at Epoch 20 iteration 0 with loss 0.61908. Total time 0.86805 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 20 iteration 100 with loss 0.44241. Total time 0.88083 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.48267. Total time 0.89305 hours\n",
      "Training at Epoch 20 iteration 300 with loss 0.33817. Total time 0.905 hours\n",
      "Validation at Epoch 20 , MSE: 0.36211 , Pearson Correlation: 0.75598 with p-value: 0.0 , Concordance Index: 0.80399\n",
      "Training at Epoch 21 iteration 0 with loss 0.33789. Total time 0.91361 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.33211. Total time 0.92611 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.52422. Total time 0.93833 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.61085. Total time 0.95027 hours\n",
      "Validation at Epoch 21 , MSE: 0.30611 , Pearson Correlation: 0.75267 with p-value: 0.0 , Concordance Index: 0.80361\n",
      "--- Go for Testing ---\n",
      "Up to Epoch 20 Testing MSE: 0.4131461040234822 , Pearson Correlation: 0.6731547084722148 with p-value: 0.0 , Concordance Index: 0.7431750429162699\n",
      "Training at Epoch 22 iteration 0 with loss 0.35602. Total time 0.96944 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.38856. Total time 0.98194 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.33634. Total time 0.99416 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.40616. Total time 1.00638 hours\n",
      "Validation at Epoch 22 , MSE: 0.37762 , Pearson Correlation: 0.75044 with p-value: 0.0 , Concordance Index: 0.80505\n",
      "Training at Epoch 23 iteration 0 with loss 0.40540. Total time 1.015 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.37408. Total time 1.02722 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.33696. Total time 1.03944 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.37845. Total time 1.05166 hours\n",
      "Validation at Epoch 23 , MSE: 0.29121 , Pearson Correlation: 0.76943 with p-value: 0.0 , Concordance Index: 0.80868\n",
      "Training at Epoch 24 iteration 0 with loss 0.45560. Total time 1.06 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.31497. Total time 1.0725 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.27467. Total time 1.08472 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.42311. Total time 1.09694 hours\n",
      "Validation at Epoch 24 , MSE: 0.28796 , Pearson Correlation: 0.77413 with p-value: 0.0 , Concordance Index: 0.80929\n",
      "Training at Epoch 25 iteration 0 with loss 0.33458. Total time 1.10555 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.37277. Total time 1.11805 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.43361. Total time 1.13027 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.29570. Total time 1.1425 hours\n",
      "Validation at Epoch 25 , MSE: 0.29138 , Pearson Correlation: 0.76657 with p-value: 0.0 , Concordance Index: 0.80347\n",
      "Training at Epoch 26 iteration 0 with loss 0.39262. Total time 1.15083 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.32376. Total time 1.16361 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.28363. Total time 1.17611 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.45162. Total time 1.18861 hours\n",
      "Validation at Epoch 26 , MSE: 0.33628 , Pearson Correlation: 0.77623 with p-value: 0.0 , Concordance Index: 0.81052\n",
      "Training at Epoch 27 iteration 0 with loss 0.32667. Total time 1.19777 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.35965. Total time 1.21 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.26597. Total time 1.22222 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.38679. Total time 1.23416 hours\n",
      "Validation at Epoch 27 , MSE: 0.30443 , Pearson Correlation: 0.78507 with p-value: 0.0 , Concordance Index: 0.81610\n",
      "Training at Epoch 28 iteration 0 with loss 0.40618. Total time 1.24333 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.38928. Total time 1.25555 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.29831. Total time 1.26777 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.44613. Total time 1.27972 hours\n",
      "Validation at Epoch 28 , MSE: 0.26992 , Pearson Correlation: 0.78769 with p-value: 0.0 , Concordance Index: 0.81924\n",
      "Training at Epoch 29 iteration 0 with loss 0.28347. Total time 1.28861 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.37317. Total time 1.30111 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.35352. Total time 1.31305 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.35006. Total time 1.325 hours\n",
      "Validation at Epoch 29 , MSE: 0.28265 , Pearson Correlation: 0.79636 with p-value: 0.0 , Concordance Index: 0.81891\n",
      "Training at Epoch 30 iteration 0 with loss 0.28800. Total time 1.33361 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.29237. Total time 1.34638 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.25865. Total time 1.35861 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.27363. Total time 1.37083 hours\n",
      "Validation at Epoch 30 , MSE: 0.28378 , Pearson Correlation: 0.79635 with p-value: 0.0 , Concordance Index: 0.81906\n",
      "Training at Epoch 31 iteration 0 with loss 0.36418. Total time 1.37944 hours\n",
      "Training at Epoch 31 iteration 100 with loss 0.32274. Total time 1.39166 hours\n",
      "Training at Epoch 31 iteration 200 with loss 0.32263. Total time 1.40388 hours\n",
      "Training at Epoch 31 iteration 300 with loss 0.29581. Total time 1.41583 hours\n",
      "Validation at Epoch 31 , MSE: 0.25164 , Pearson Correlation: 0.80216 with p-value: 0.0 , Concordance Index: 0.82479\n",
      "Training at Epoch 32 iteration 0 with loss 0.32310. Total time 1.42444 hours\n",
      "Training at Epoch 32 iteration 100 with loss 0.24243. Total time 1.43666 hours\n",
      "Training at Epoch 32 iteration 200 with loss 0.25189. Total time 1.44861 hours\n",
      "Training at Epoch 32 iteration 300 with loss 0.30749. Total time 1.46083 hours\n",
      "Validation at Epoch 32 , MSE: 0.24432 , Pearson Correlation: 0.80916 with p-value: 0.0 , Concordance Index: 0.82520\n",
      "Training at Epoch 33 iteration 0 with loss 0.20599. Total time 1.46916 hours\n",
      "Training at Epoch 33 iteration 100 with loss 0.39203. Total time 1.48194 hours\n",
      "Training at Epoch 33 iteration 200 with loss 0.35323. Total time 1.49444 hours\n",
      "Training at Epoch 33 iteration 300 with loss 0.35685. Total time 1.50694 hours\n",
      "Validation at Epoch 33 , MSE: 0.27000 , Pearson Correlation: 0.80468 with p-value: 0.0 , Concordance Index: 0.82471\n",
      "Training at Epoch 34 iteration 0 with loss 0.26189. Total time 1.51611 hours\n",
      "Training at Epoch 34 iteration 100 with loss 0.35037. Total time 1.52833 hours\n",
      "Training at Epoch 34 iteration 200 with loss 0.35269. Total time 1.54027 hours\n",
      "Training at Epoch 34 iteration 300 with loss 0.34905. Total time 1.55222 hours\n",
      "Validation at Epoch 34 , MSE: 0.24204 , Pearson Correlation: 0.82320 with p-value: 0.0 , Concordance Index: 0.84027\n",
      "Training at Epoch 35 iteration 0 with loss 0.33272. Total time 1.56055 hours\n",
      "Training at Epoch 35 iteration 100 with loss 0.25225. Total time 1.57277 hours\n",
      "Training at Epoch 35 iteration 200 with loss 0.25119. Total time 1.585 hours\n",
      "Training at Epoch 35 iteration 300 with loss 0.27280. Total time 1.59722 hours\n",
      "Validation at Epoch 35 , MSE: 0.23484 , Pearson Correlation: 0.81961 with p-value: 0.0 , Concordance Index: 0.83725\n",
      "Training at Epoch 36 iteration 0 with loss 0.27690. Total time 1.60583 hours\n",
      "Training at Epoch 36 iteration 100 with loss 0.32997. Total time 1.61805 hours\n",
      "Training at Epoch 36 iteration 200 with loss 0.28946. Total time 1.63 hours\n",
      "Training at Epoch 36 iteration 300 with loss 0.32728. Total time 1.64194 hours\n",
      "Validation at Epoch 36 , MSE: 0.22622 , Pearson Correlation: 0.82399 with p-value: 0.0 , Concordance Index: 0.83818\n",
      "Training at Epoch 37 iteration 0 with loss 0.28403. Total time 1.65027 hours\n",
      "Training at Epoch 37 iteration 100 with loss 0.29014. Total time 1.66277 hours\n",
      "Training at Epoch 37 iteration 200 with loss 0.23702. Total time 1.675 hours\n",
      "Training at Epoch 37 iteration 300 with loss 0.26102. Total time 1.6875 hours\n",
      "Validation at Epoch 37 , MSE: 0.24917 , Pearson Correlation: 0.82502 with p-value: 0.0 , Concordance Index: 0.83525\n",
      "Training at Epoch 38 iteration 0 with loss 0.35937. Total time 1.69638 hours\n",
      "Training at Epoch 38 iteration 100 with loss 0.24386. Total time 1.70861 hours\n",
      "Training at Epoch 38 iteration 200 with loss 0.30235. Total time 1.72083 hours\n",
      "Training at Epoch 38 iteration 300 with loss 0.25676. Total time 1.73305 hours\n",
      "Validation at Epoch 38 , MSE: 0.22608 , Pearson Correlation: 0.82723 with p-value: 0.0 , Concordance Index: 0.84117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 39 iteration 0 with loss 0.23972. Total time 1.74138 hours\n",
      "Training at Epoch 39 iteration 100 with loss 0.32811. Total time 1.75361 hours\n",
      "Training at Epoch 39 iteration 200 with loss 0.28620. Total time 1.76583 hours\n",
      "Training at Epoch 39 iteration 300 with loss 0.29245. Total time 1.77777 hours\n",
      "Validation at Epoch 39 , MSE: 0.22666 , Pearson Correlation: 0.82984 with p-value: 0.0 , Concordance Index: 0.84352\n",
      "Training at Epoch 40 iteration 0 with loss 0.22158. Total time 1.78666 hours\n",
      "Training at Epoch 40 iteration 100 with loss 0.23753. Total time 1.79861 hours\n",
      "Training at Epoch 40 iteration 200 with loss 0.22566. Total time 1.81083 hours\n",
      "Training at Epoch 40 iteration 300 with loss 0.25036. Total time 1.8225 hours\n",
      "Validation at Epoch 40 , MSE: 0.24893 , Pearson Correlation: 0.83433 with p-value: 0.0 , Concordance Index: 0.84639\n",
      "Training at Epoch 41 iteration 0 with loss 0.24484. Total time 1.83138 hours\n",
      "Training at Epoch 41 iteration 100 with loss 0.20085. Total time 1.84388 hours\n",
      "Training at Epoch 41 iteration 200 with loss 0.21223. Total time 1.85638 hours\n",
      "Training at Epoch 41 iteration 300 with loss 0.26932. Total time 1.86888 hours\n",
      "Validation at Epoch 41 , MSE: 0.21428 , Pearson Correlation: 0.83846 with p-value: 0.0 , Concordance Index: 0.84458\n",
      "--- Go for Testing ---\n",
      "Up to Epoch 40 Testing MSE: 0.29874085638201586 , Pearson Correlation: 0.7838779135409092 with p-value: 0.0 , Concordance Index: 0.787685654657913\n",
      "Training at Epoch 42 iteration 0 with loss 0.26496. Total time 1.88861 hours\n",
      "Training at Epoch 42 iteration 100 with loss 0.29321. Total time 1.90055 hours\n",
      "Training at Epoch 42 iteration 200 with loss 0.18268. Total time 1.9125 hours\n",
      "Training at Epoch 42 iteration 300 with loss 0.23029. Total time 1.92472 hours\n",
      "Validation at Epoch 42 , MSE: 0.22700 , Pearson Correlation: 0.83606 with p-value: 0.0 , Concordance Index: 0.84796\n",
      "Training at Epoch 43 iteration 0 with loss 0.23266. Total time 1.93333 hours\n",
      "Training at Epoch 43 iteration 100 with loss 0.26386. Total time 1.94555 hours\n",
      "Training at Epoch 43 iteration 200 with loss 0.25301. Total time 1.95777 hours\n",
      "Training at Epoch 43 iteration 300 with loss 0.20905. Total time 1.96972 hours\n",
      "Validation at Epoch 43 , MSE: 0.21152 , Pearson Correlation: 0.83967 with p-value: 0.0 , Concordance Index: 0.84755\n",
      "Training at Epoch 44 iteration 0 with loss 0.25211. Total time 1.97833 hours\n",
      "Training at Epoch 44 iteration 100 with loss 0.18451. Total time 1.99083 hours\n",
      "Training at Epoch 44 iteration 200 with loss 0.22059. Total time 2.00277 hours\n",
      "Training at Epoch 44 iteration 300 with loss 0.26569. Total time 2.015 hours\n",
      "Validation at Epoch 44 , MSE: 0.23574 , Pearson Correlation: 0.83728 with p-value: 0.0 , Concordance Index: 0.84729\n",
      "Training at Epoch 45 iteration 0 with loss 0.33796. Total time 2.02361 hours\n",
      "Training at Epoch 45 iteration 100 with loss 0.31126. Total time 2.03638 hours\n",
      "Training at Epoch 45 iteration 200 with loss 0.22966. Total time 2.04833 hours\n",
      "Training at Epoch 45 iteration 300 with loss 0.23172. Total time 2.06027 hours\n",
      "Validation at Epoch 45 , MSE: 0.21428 , Pearson Correlation: 0.83505 with p-value: 0.0 , Concordance Index: 0.84654\n",
      "Training at Epoch 46 iteration 0 with loss 0.17460. Total time 2.06888 hours\n",
      "Training at Epoch 46 iteration 100 with loss 0.22140. Total time 2.08166 hours\n",
      "Training at Epoch 46 iteration 200 with loss 0.20552. Total time 2.095 hours\n",
      "Training at Epoch 46 iteration 300 with loss 0.26057. Total time 2.10972 hours\n"
     ]
    }
   ],
   "source": [
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_morgan_cnn_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_morgan_aac_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Morgan'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 1)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 2)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 3)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_daylight_aac_kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 4)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding = 'Daylight'\n",
    "target_encoding = 'AAC'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2], random_seed = 5)\n",
    "\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
