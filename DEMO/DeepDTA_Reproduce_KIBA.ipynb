{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [16:50:46] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Done!\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_drug, X_target, y = load_process_KIBA('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU/s!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 139.46227\n",
      "Training at Epoch 1 iteration 100 with loss 0.8524759\n",
      "Training at Epoch 1 iteration 200 with loss 0.7659789\n",
      "Training at Epoch 1 iteration 300 with loss 0.77633584\n",
      "Validation at Epoch 1 , MSE: 0.6252079559108886 , Pearson Correlation: 0.37120514588057757 with p-value: 0.0 , Concordance Index: 0.6476415418668936\n",
      "Training at Epoch 2 iteration 0 with loss 0.6057545\n",
      "Training at Epoch 2 iteration 100 with loss 0.7182188\n",
      "Training at Epoch 2 iteration 200 with loss 0.5523121\n",
      "Training at Epoch 2 iteration 300 with loss 0.7289833\n",
      "Validation at Epoch 2 , MSE: 0.5057249716094536 , Pearson Correlation: 0.5271302441704545 with p-value: 0.0 , Concordance Index: 0.7108944244194332\n",
      "Training at Epoch 3 iteration 0 with loss 0.3336088\n",
      "Training at Epoch 3 iteration 100 with loss 0.55122924\n",
      "Training at Epoch 3 iteration 200 with loss 0.9139983\n",
      "Training at Epoch 3 iteration 300 with loss 0.3553281\n",
      "Validation at Epoch 3 , MSE: 0.43898317224256905 , Pearson Correlation: 0.6078014781089629 with p-value: 0.0 , Concordance Index: 0.7420012120873392\n",
      "Training at Epoch 4 iteration 0 with loss 0.6549053\n",
      "Training at Epoch 4 iteration 100 with loss 0.28032207\n",
      "Training at Epoch 4 iteration 200 with loss 0.5554817\n",
      "Training at Epoch 4 iteration 300 with loss 0.4001999\n",
      "Validation at Epoch 4 , MSE: 0.517115460522088 , Pearson Correlation: 0.6388425484955205 with p-value: 0.0 , Concordance Index: 0.7548923258982349\n",
      "Training at Epoch 5 iteration 0 with loss 0.3249922\n",
      "Training at Epoch 5 iteration 100 with loss 0.49228954\n",
      "Training at Epoch 5 iteration 200 with loss 0.53248477\n",
      "Training at Epoch 5 iteration 300 with loss 0.35868204\n",
      "Validation at Epoch 5 , MSE: 0.43980806543009365 , Pearson Correlation: 0.6566629620181142 with p-value: 0.0 , Concordance Index: 0.7574936859223567\n",
      "Training at Epoch 6 iteration 0 with loss 0.33518466\n",
      "Training at Epoch 6 iteration 100 with loss 0.4694142\n",
      "Training at Epoch 6 iteration 200 with loss 0.43182057\n",
      "Training at Epoch 6 iteration 300 with loss 0.27362764\n",
      "Validation at Epoch 6 , MSE: 0.40906901873856194 , Pearson Correlation: 0.6642595221495057 with p-value: 0.0 , Concordance Index: 0.7633581128907642\n",
      "Training at Epoch 7 iteration 0 with loss 0.4240064\n",
      "Training at Epoch 7 iteration 100 with loss 0.579832\n",
      "Training at Epoch 7 iteration 200 with loss 0.29981527\n",
      "Training at Epoch 7 iteration 300 with loss 0.37393552\n",
      "Validation at Epoch 7 , MSE: 0.4669870538496263 , Pearson Correlation: 0.6709961444282361 with p-value: 0.0 , Concordance Index: 0.7629225786099979\n",
      "Training at Epoch 8 iteration 0 with loss 0.49253836\n",
      "Training at Epoch 8 iteration 100 with loss 0.43154156\n",
      "Training at Epoch 8 iteration 200 with loss 0.8942315\n",
      "Training at Epoch 8 iteration 300 with loss 0.36026978\n",
      "Validation at Epoch 8 , MSE: 0.40576572643883924 , Pearson Correlation: 0.6698314683974463 with p-value: 0.0 , Concordance Index: 0.7633775503707003\n",
      "Training at Epoch 9 iteration 0 with loss 0.54117924\n",
      "Training at Epoch 9 iteration 100 with loss 0.4534474\n",
      "Training at Epoch 9 iteration 200 with loss 0.2908664\n",
      "Training at Epoch 9 iteration 300 with loss 0.40684277\n",
      "Validation at Epoch 9 , MSE: 0.3866416384830573 , Pearson Correlation: 0.6740064110006907 with p-value: 0.0 , Concordance Index: 0.7670906313072465\n",
      "Training at Epoch 10 iteration 0 with loss 0.5149473\n",
      "Training at Epoch 10 iteration 100 with loss 0.3061192\n",
      "Training at Epoch 10 iteration 200 with loss 0.39455894\n",
      "Training at Epoch 10 iteration 300 with loss 0.41524413\n",
      "Validation at Epoch 10 , MSE: 0.5004661130110899 , Pearson Correlation: 0.6746381122340862 with p-value: 0.0 , Concordance Index: 0.7636888073994913\n",
      "Training at Epoch 11 iteration 0 with loss 0.50837636\n",
      "Training at Epoch 11 iteration 100 with loss 0.34029388\n",
      "Training at Epoch 11 iteration 200 with loss 0.4000504\n",
      "Training at Epoch 11 iteration 300 with loss 0.43241504\n",
      "Validation at Epoch 11 , MSE: 0.687117328399177 , Pearson Correlation: 0.6775114338921054 with p-value: 0.0 , Concordance Index: 0.768135395853816\n",
      "Training at Epoch 12 iteration 0 with loss 0.61384964\n",
      "Training at Epoch 12 iteration 100 with loss 0.4489369\n",
      "Training at Epoch 12 iteration 200 with loss 0.41723198\n",
      "Training at Epoch 12 iteration 300 with loss 0.52659756\n",
      "Validation at Epoch 12 , MSE: 0.44284007519234136 , Pearson Correlation: 0.6815251759494406 with p-value: 0.0 , Concordance Index: 0.7671332681158448\n",
      "Training at Epoch 13 iteration 0 with loss 0.4339065\n",
      "Training at Epoch 13 iteration 100 with loss 0.43391797\n",
      "Training at Epoch 13 iteration 200 with loss 0.44804138\n",
      "Training at Epoch 13 iteration 300 with loss 0.29588428\n",
      "Validation at Epoch 13 , MSE: 0.3794264554744155 , Pearson Correlation: 0.6824709263168197 with p-value: 0.0 , Concordance Index: 0.7648438539097174\n",
      "Training at Epoch 14 iteration 0 with loss 0.35877725\n",
      "Training at Epoch 14 iteration 100 with loss 0.40320885\n",
      "Training at Epoch 14 iteration 200 with loss 0.6108784\n",
      "Training at Epoch 14 iteration 300 with loss 0.4231795\n",
      "Validation at Epoch 14 , MSE: 0.37035736481551695 , Pearson Correlation: 0.6886761842378898 with p-value: 0.0 , Concordance Index: 0.769635147299312\n",
      "Training at Epoch 15 iteration 0 with loss 0.28133658\n",
      "Training at Epoch 15 iteration 100 with loss 0.2723529\n",
      "Training at Epoch 15 iteration 200 with loss 0.37842792\n",
      "Training at Epoch 15 iteration 300 with loss 0.42256156\n",
      "Validation at Epoch 15 , MSE: 0.39174580991934793 , Pearson Correlation: 0.6980164319885487 with p-value: 0.0 , Concordance Index: 0.7729698407516334\n",
      "Training at Epoch 16 iteration 0 with loss 0.442822\n",
      "Training at Epoch 16 iteration 100 with loss 0.29855317\n",
      "Training at Epoch 16 iteration 200 with loss 0.44767448\n",
      "Training at Epoch 16 iteration 300 with loss 0.3829686\n",
      "Validation at Epoch 16 , MSE: 0.3587687227351904 , Pearson Correlation: 0.7275656094433479 with p-value: 0.0 , Concordance Index: 0.7817976053933012\n",
      "Training at Epoch 17 iteration 0 with loss 0.39717722\n",
      "Training at Epoch 17 iteration 100 with loss 0.34678438\n",
      "Training at Epoch 17 iteration 200 with loss 0.30226183\n",
      "Training at Epoch 17 iteration 300 with loss 0.42329437\n",
      "Validation at Epoch 17 , MSE: 0.4687368140248108 , Pearson Correlation: 0.7304166804308427 with p-value: 0.0 , Concordance Index: 0.7828565923015529\n",
      "Training at Epoch 18 iteration 0 with loss 0.3633739\n",
      "Training at Epoch 18 iteration 100 with loss 0.28657123\n",
      "Training at Epoch 18 iteration 200 with loss 0.32053304\n",
      "Training at Epoch 18 iteration 300 with loss 0.32039723\n",
      "Validation at Epoch 18 , MSE: 0.3276044065524828 , Pearson Correlation: 0.7382404349298669 with p-value: 0.0 , Concordance Index: 0.7846119602326115\n",
      "Training at Epoch 19 iteration 0 with loss 0.17331107\n",
      "Training at Epoch 19 iteration 100 with loss 0.43098885\n",
      "Training at Epoch 19 iteration 200 with loss 0.34547406\n",
      "Training at Epoch 19 iteration 300 with loss 0.29107505\n",
      "Validation at Epoch 19 , MSE: 0.3122119465124941 , Pearson Correlation: 0.7406594366731748 with p-value: 0.0 , Concordance Index: 0.7859064449263984\n",
      "Training at Epoch 20 iteration 0 with loss 0.3300522\n",
      "Training at Epoch 20 iteration 100 with loss 0.23845857\n",
      "Training at Epoch 20 iteration 200 with loss 0.3112779\n",
      "Training at Epoch 20 iteration 300 with loss 0.2908824\n",
      "Validation at Epoch 20 , MSE: 0.332362568609342 , Pearson Correlation: 0.7433144190944236 with p-value: 0.0 , Concordance Index: 0.779341019776788\n",
      "Training at Epoch 21 iteration 0 with loss 0.21694058\n",
      "Training at Epoch 21 iteration 100 with loss 0.31264272\n",
      "Training at Epoch 21 iteration 200 with loss 0.291134\n",
      "Training at Epoch 21 iteration 300 with loss 0.2443328\n",
      "Validation at Epoch 21 , MSE: 0.32488440260458695 , Pearson Correlation: 0.7549241003756116 with p-value: 0.0 , Concordance Index: 0.7905469464642452\n",
      "Training at Epoch 22 iteration 0 with loss 0.296259\n",
      "Training at Epoch 22 iteration 100 with loss 0.32945767\n",
      "Training at Epoch 22 iteration 200 with loss 0.28351027\n",
      "Training at Epoch 22 iteration 300 with loss 0.27165496\n",
      "Validation at Epoch 22 , MSE: 0.3556623065139081 , Pearson Correlation: 0.7558565473223899 with p-value: 0.0 , Concordance Index: 0.7933693699770804\n",
      "Training at Epoch 23 iteration 0 with loss 0.3517964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 23 iteration 100 with loss 0.21723273\n",
      "Training at Epoch 23 iteration 200 with loss 0.3215351\n",
      "Training at Epoch 23 iteration 300 with loss 0.37353116\n",
      "Validation at Epoch 23 , MSE: 0.2904944052104942 , Pearson Correlation: 0.7605299689697724 with p-value: 0.0 , Concordance Index: 0.7966217114894854\n",
      "Training at Epoch 24 iteration 0 with loss 0.2798943\n",
      "Training at Epoch 24 iteration 100 with loss 0.39643136\n",
      "Training at Epoch 24 iteration 200 with loss 0.4295775\n",
      "Training at Epoch 24 iteration 300 with loss 0.24249879\n",
      "Validation at Epoch 24 , MSE: 0.3018565196551627 , Pearson Correlation: 0.7695774972212105 with p-value: 0.0 , Concordance Index: 0.7993369790819714\n",
      "Training at Epoch 25 iteration 0 with loss 0.22099498\n",
      "Training at Epoch 25 iteration 100 with loss 0.26581356\n",
      "Training at Epoch 25 iteration 200 with loss 0.31408113\n",
      "Training at Epoch 25 iteration 300 with loss 0.31087956\n",
      "Validation at Epoch 25 , MSE: 0.28863161072602156 , Pearson Correlation: 0.762775379909726 with p-value: 0.0 , Concordance Index: 0.8012207040164403\n",
      "Training at Epoch 26 iteration 0 with loss 0.2655613\n",
      "Training at Epoch 26 iteration 100 with loss 0.25201494\n",
      "Training at Epoch 26 iteration 200 with loss 0.2319586\n",
      "Training at Epoch 26 iteration 300 with loss 0.2557767\n",
      "Validation at Epoch 26 , MSE: 0.4930393249311044 , Pearson Correlation: 0.7699562360525237 with p-value: 0.0 , Concordance Index: 0.7963000393624107\n",
      "Training at Epoch 27 iteration 0 with loss 0.44117013\n",
      "Training at Epoch 27 iteration 100 with loss 0.3273319\n",
      "Training at Epoch 27 iteration 200 with loss 0.26239604\n",
      "Training at Epoch 27 iteration 300 with loss 0.2871576\n",
      "Validation at Epoch 27 , MSE: 0.2763490526371625 , Pearson Correlation: 0.7732378079725977 with p-value: 0.0 , Concordance Index: 0.8040261651490042\n",
      "Training at Epoch 28 iteration 0 with loss 0.2402317\n",
      "Training at Epoch 28 iteration 100 with loss 0.2201614\n",
      "Training at Epoch 28 iteration 200 with loss 0.29813662\n",
      "Training at Epoch 28 iteration 300 with loss 0.36932343\n",
      "Validation at Epoch 28 , MSE: 0.3163570835376237 , Pearson Correlation: 0.7757515692799253 with p-value: 0.0 , Concordance Index: 0.7992013178853609\n",
      "Training at Epoch 29 iteration 0 with loss 0.30585524\n",
      "Training at Epoch 29 iteration 100 with loss 0.29580683\n",
      "Training at Epoch 29 iteration 200 with loss 0.26298445\n",
      "Training at Epoch 29 iteration 300 with loss 0.29019976\n",
      "Validation at Epoch 29 , MSE: 0.27718322610610213 , Pearson Correlation: 0.7781347032430801 with p-value: 0.0 , Concordance Index: 0.8021961809106205\n",
      "Training at Epoch 30 iteration 0 with loss 0.2829763\n",
      "Training at Epoch 30 iteration 100 with loss 0.28772902\n",
      "Training at Epoch 30 iteration 200 with loss 0.2438101\n",
      "Training at Epoch 30 iteration 300 with loss 0.2709101\n",
      "Validation at Epoch 30 , MSE: 0.3025488108277402 , Pearson Correlation: 0.7766137013109087 with p-value: 0.0 , Concordance Index: 0.7978011305407529\n",
      "Training at Epoch 31 iteration 0 with loss 0.2151288\n",
      "Training at Epoch 31 iteration 100 with loss 0.27977476\n",
      "Training at Epoch 31 iteration 200 with loss 0.32945055\n",
      "Training at Epoch 31 iteration 300 with loss 0.30322352\n",
      "Validation at Epoch 31 , MSE: 0.27950626900433845 , Pearson Correlation: 0.7768095876580197 with p-value: 0.0 , Concordance Index: 0.809581908586743\n",
      "Training at Epoch 32 iteration 0 with loss 0.30916905\n",
      "Training at Epoch 32 iteration 100 with loss 0.35691962\n",
      "Training at Epoch 32 iteration 200 with loss 0.30594778\n",
      "Training at Epoch 32 iteration 300 with loss 0.25673822\n",
      "Validation at Epoch 32 , MSE: 0.28392810687019493 , Pearson Correlation: 0.7884139492934661 with p-value: 0.0 , Concordance Index: 0.8080715906607208\n",
      "Training at Epoch 33 iteration 0 with loss 0.24682216\n",
      "Training at Epoch 33 iteration 100 with loss 0.32019353\n",
      "Training at Epoch 33 iteration 200 with loss 0.26248968\n",
      "Training at Epoch 33 iteration 300 with loss 0.23284283\n",
      "Validation at Epoch 33 , MSE: 0.28147583151983824 , Pearson Correlation: 0.7912324256450507 with p-value: 0.0 , Concordance Index: 0.806736921550664\n",
      "Training at Epoch 34 iteration 0 with loss 0.26583454\n",
      "Training at Epoch 34 iteration 100 with loss 0.27032578\n",
      "Training at Epoch 34 iteration 200 with loss 0.2510938\n",
      "Training at Epoch 34 iteration 300 with loss 0.18677746\n",
      "Validation at Epoch 34 , MSE: 0.254715168591093 , Pearson Correlation: 0.7944845435587876 with p-value: 0.0 , Concordance Index: 0.8092169411383151\n",
      "Training at Epoch 35 iteration 0 with loss 0.21087557\n",
      "Training at Epoch 35 iteration 100 with loss 0.22810724\n",
      "Training at Epoch 35 iteration 200 with loss 0.30516157\n",
      "Training at Epoch 35 iteration 300 with loss 0.21417427\n",
      "Validation at Epoch 35 , MSE: 0.2556761511172115 , Pearson Correlation: 0.7957341951817682 with p-value: 0.0 , Concordance Index: 0.8142363751364597\n",
      "Training at Epoch 36 iteration 0 with loss 0.17365673\n",
      "Training at Epoch 36 iteration 100 with loss 0.26811144\n",
      "Training at Epoch 36 iteration 200 with loss 0.23328358\n",
      "Training at Epoch 36 iteration 300 with loss 0.25731447\n",
      "Validation at Epoch 36 , MSE: 0.2559457642380893 , Pearson Correlation: 0.799422136545758 with p-value: 0.0 , Concordance Index: 0.8127337474283564\n",
      "Training at Epoch 37 iteration 0 with loss 0.17421441\n",
      "Training at Epoch 37 iteration 100 with loss 0.2805039\n",
      "Training at Epoch 37 iteration 200 with loss 0.16534641\n",
      "Training at Epoch 37 iteration 300 with loss 0.22006656\n",
      "Validation at Epoch 37 , MSE: 0.32952278645964184 , Pearson Correlation: 0.7934489740191146 with p-value: 0.0 , Concordance Index: 0.8010512391650809\n",
      "Training at Epoch 38 iteration 0 with loss 0.2512241\n",
      "Training at Epoch 38 iteration 100 with loss 0.18280888\n",
      "Training at Epoch 38 iteration 200 with loss 0.16358562\n",
      "Training at Epoch 38 iteration 300 with loss 0.2114552\n",
      "Validation at Epoch 38 , MSE: 0.2469675475963409 , Pearson Correlation: 0.8041560299798638 with p-value: 0.0 , Concordance Index: 0.8143626506340358\n",
      "Training at Epoch 39 iteration 0 with loss 0.17007281\n",
      "Training at Epoch 39 iteration 100 with loss 0.2576394\n",
      "Training at Epoch 39 iteration 200 with loss 0.25703746\n",
      "Training at Epoch 39 iteration 300 with loss 0.30679893\n",
      "Validation at Epoch 39 , MSE: 0.2814202224785629 , Pearson Correlation: 0.7986617531118729 with p-value: 0.0 , Concordance Index: 0.8123491078575165\n",
      "Training at Epoch 40 iteration 0 with loss 0.17776462\n",
      "Training at Epoch 40 iteration 100 with loss 0.23892398\n",
      "Training at Epoch 40 iteration 200 with loss 0.3002319\n",
      "Training at Epoch 40 iteration 300 with loss 0.21091235\n",
      "Validation at Epoch 40 , MSE: 0.24471777008217963 , Pearson Correlation: 0.8029439370476041 with p-value: 0.0 , Concordance Index: 0.8139744687187216\n",
      "Training at Epoch 41 iteration 0 with loss 0.18120411\n",
      "Training at Epoch 41 iteration 100 with loss 0.1467629\n",
      "Training at Epoch 41 iteration 200 with loss 0.18784216\n",
      "Training at Epoch 41 iteration 300 with loss 0.39111277\n",
      "Validation at Epoch 41 , MSE: 0.25024235414513113 , Pearson Correlation: 0.8065926609762567 with p-value: 0.0 , Concordance Index: 0.8126689861050176\n",
      "Training at Epoch 42 iteration 0 with loss 0.18558024\n",
      "Training at Epoch 42 iteration 100 with loss 0.22143383\n",
      "Training at Epoch 42 iteration 200 with loss 0.17659724\n",
      "Training at Epoch 42 iteration 300 with loss 0.21279082\n",
      "Validation at Epoch 42 , MSE: 0.24589991385365795 , Pearson Correlation: 0.8058687406335383 with p-value: 0.0 , Concordance Index: 0.8180839667645736\n",
      "Training at Epoch 43 iteration 0 with loss 0.18575062\n",
      "Training at Epoch 43 iteration 100 with loss 0.14547281\n",
      "Training at Epoch 43 iteration 200 with loss 0.21407829\n",
      "Training at Epoch 43 iteration 300 with loss 0.25702018\n",
      "Validation at Epoch 43 , MSE: 0.23597818335337695 , Pearson Correlation: 0.8131261358345395 with p-value: 0.0 , Concordance Index: 0.8214152843928875\n",
      "Training at Epoch 44 iteration 0 with loss 0.1430232\n",
      "Training at Epoch 44 iteration 100 with loss 0.23007198\n",
      "Training at Epoch 44 iteration 200 with loss 0.23313954\n",
      "Training at Epoch 44 iteration 300 with loss 0.21242057\n",
      "Validation at Epoch 44 , MSE: 0.2410594394283686 , Pearson Correlation: 0.8093517312778701 with p-value: 0.0 , Concordance Index: 0.8200404838503456\n",
      "Training at Epoch 45 iteration 0 with loss 0.19044279\n",
      "Training at Epoch 45 iteration 100 with loss 0.22278084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 45 iteration 200 with loss 0.20137015\n",
      "Training at Epoch 45 iteration 300 with loss 0.20637983\n",
      "Validation at Epoch 45 , MSE: 0.2931538610613398 , Pearson Correlation: 0.8161000618379057 with p-value: 0.0 , Concordance Index: 0.8220322200148337\n",
      "Training at Epoch 46 iteration 0 with loss 0.19920787\n",
      "Training at Epoch 46 iteration 100 with loss 0.17406026\n",
      "Training at Epoch 46 iteration 200 with loss 0.19329071\n",
      "Training at Epoch 46 iteration 300 with loss 0.19324802\n",
      "Validation at Epoch 46 , MSE: 0.27236348972361674 , Pearson Correlation: 0.8138519945205422 with p-value: 0.0 , Concordance Index: 0.8187842761565732\n",
      "Training at Epoch 47 iteration 0 with loss 0.23279054\n",
      "Training at Epoch 47 iteration 100 with loss 0.17864995\n",
      "Training at Epoch 47 iteration 200 with loss 0.21056506\n",
      "Training at Epoch 47 iteration 300 with loss 0.1824354\n",
      "Validation at Epoch 47 , MSE: 0.27391643581608033 , Pearson Correlation: 0.8068993596091968 with p-value: 0.0 , Concordance Index: 0.8129289169844912\n",
      "Training at Epoch 48 iteration 0 with loss 0.26312447\n",
      "Training at Epoch 48 iteration 100 with loss 0.22185321\n",
      "Training at Epoch 48 iteration 200 with loss 0.23431794\n",
      "Training at Epoch 48 iteration 300 with loss 0.2589783\n",
      "Validation at Epoch 48 , MSE: 0.23025026174260313 , Pearson Correlation: 0.8170136575139418 with p-value: 0.0 , Concordance Index: 0.8225616567006185\n",
      "Training at Epoch 49 iteration 0 with loss 0.1223916\n",
      "Training at Epoch 49 iteration 100 with loss 0.18264055\n",
      "Training at Epoch 49 iteration 200 with loss 0.17989686\n",
      "Training at Epoch 49 iteration 300 with loss 0.16855526\n",
      "Validation at Epoch 49 , MSE: 0.2205644529408611 , Pearson Correlation: 0.8239693877895442 with p-value: 0.0 , Concordance Index: 0.8312742800086458\n",
      "Training at Epoch 50 iteration 0 with loss 0.30569243\n",
      "Training at Epoch 50 iteration 100 with loss 0.16925503\n",
      "Training at Epoch 50 iteration 200 with loss 0.20570143\n",
      "Training at Epoch 50 iteration 300 with loss 0.19284452\n",
      "Validation at Epoch 50 , MSE: 0.23454742649197957 , Pearson Correlation: 0.8259606548256397 with p-value: 0.0 , Concordance Index: 0.8328887640557276\n",
      "Training at Epoch 51 iteration 0 with loss 0.22376396\n",
      "Training at Epoch 51 iteration 100 with loss 0.23242217\n",
      "Training at Epoch 51 iteration 200 with loss 0.17831367\n",
      "Training at Epoch 51 iteration 300 with loss 0.17776337\n",
      "Validation at Epoch 51 , MSE: 0.22540333524221137 , Pearson Correlation: 0.8237001583277702 with p-value: 0.0 , Concordance Index: 0.8321182360105475\n",
      "Training at Epoch 52 iteration 0 with loss 0.18440701\n",
      "Training at Epoch 52 iteration 100 with loss 0.15421636\n",
      "Training at Epoch 52 iteration 200 with loss 0.1854191\n",
      "Training at Epoch 52 iteration 300 with loss 0.2379067\n",
      "Validation at Epoch 52 , MSE: 0.20853173553592427 , Pearson Correlation: 0.8344220487922347 with p-value: 0.0 , Concordance Index: 0.8367795147611765\n",
      "Training at Epoch 53 iteration 0 with loss 0.20401023\n",
      "Training at Epoch 53 iteration 100 with loss 0.11404045\n",
      "Training at Epoch 53 iteration 200 with loss 0.15747331\n",
      "Training at Epoch 53 iteration 300 with loss 0.22042069\n",
      "Validation at Epoch 53 , MSE: 0.21615491029018147 , Pearson Correlation: 0.8306163494334134 with p-value: 0.0 , Concordance Index: 0.83251870259484\n",
      "Training at Epoch 54 iteration 0 with loss 0.14299648\n",
      "Training at Epoch 54 iteration 100 with loss 0.23001932\n",
      "Training at Epoch 54 iteration 200 with loss 0.1770986\n",
      "Training at Epoch 54 iteration 300 with loss 0.2942966\n",
      "Validation at Epoch 54 , MSE: 0.2501904187767297 , Pearson Correlation: 0.8292196336328985 with p-value: 0.0 , Concordance Index: 0.8316417604022989\n",
      "Training at Epoch 55 iteration 0 with loss 0.19672471\n",
      "Training at Epoch 55 iteration 100 with loss 0.142104\n",
      "Training at Epoch 55 iteration 200 with loss 0.1882125\n",
      "Training at Epoch 55 iteration 300 with loss 0.18341456\n",
      "Validation at Epoch 55 , MSE: 0.22685709705865717 , Pearson Correlation: 0.8298601891084482 with p-value: 0.0 , Concordance Index: 0.8332577279953572\n",
      "Training at Epoch 56 iteration 0 with loss 0.16769859\n",
      "Training at Epoch 56 iteration 100 with loss 0.15354457\n",
      "Training at Epoch 56 iteration 200 with loss 0.18837331\n",
      "Training at Epoch 56 iteration 300 with loss 0.18643981\n",
      "Validation at Epoch 56 , MSE: 0.23465381325878834 , Pearson Correlation: 0.8226322913072514 with p-value: 0.0 , Concordance Index: 0.8305899944270141\n",
      "Training at Epoch 57 iteration 0 with loss 0.15828678\n",
      "Training at Epoch 57 iteration 100 with loss 0.23880166\n",
      "Training at Epoch 57 iteration 200 with loss 0.19497156\n",
      "Training at Epoch 57 iteration 300 with loss 0.20533583\n",
      "Validation at Epoch 57 , MSE: 0.23490776397150226 , Pearson Correlation: 0.8261580940950286 with p-value: 0.0 , Concordance Index: 0.828603049510501\n",
      "Training at Epoch 58 iteration 0 with loss 0.14188379\n",
      "Training at Epoch 58 iteration 100 with loss 0.16264115\n",
      "Training at Epoch 58 iteration 200 with loss 0.27134517\n",
      "Training at Epoch 58 iteration 300 with loss 0.16497058\n",
      "Validation at Epoch 58 , MSE: 0.20634967969974802 , Pearson Correlation: 0.8372939570839266 with p-value: 0.0 , Concordance Index: 0.8338584354409082\n",
      "Training at Epoch 59 iteration 0 with loss 0.13785982\n",
      "Training at Epoch 59 iteration 100 with loss 0.16934662\n",
      "Training at Epoch 59 iteration 200 with loss 0.14488962\n",
      "Training at Epoch 59 iteration 300 with loss 0.24447058\n",
      "Validation at Epoch 59 , MSE: 0.24024889528142337 , Pearson Correlation: 0.8281995247440275 with p-value: 0.0 , Concordance Index: 0.8348693811945046\n",
      "Training at Epoch 60 iteration 0 with loss 0.20227404\n",
      "Training at Epoch 60 iteration 100 with loss 0.15199661\n",
      "Training at Epoch 60 iteration 200 with loss 0.21587655\n",
      "Training at Epoch 60 iteration 300 with loss 0.19945133\n",
      "Validation at Epoch 60 , MSE: 0.21013252771272414 , Pearson Correlation: 0.8365628781877509 with p-value: 0.0 , Concordance Index: 0.8368555691998053\n",
      "Training at Epoch 61 iteration 0 with loss 0.19128245\n",
      "Training at Epoch 61 iteration 100 with loss 0.11310287\n",
      "Training at Epoch 61 iteration 200 with loss 0.19415411\n",
      "Training at Epoch 61 iteration 300 with loss 0.15344377\n",
      "Validation at Epoch 61 , MSE: 0.21382856500150502 , Pearson Correlation: 0.8418828074732749 with p-value: 0.0 , Concordance Index: 0.8403055856444582\n",
      "Training at Epoch 62 iteration 0 with loss 0.16562407\n",
      "Training at Epoch 62 iteration 100 with loss 0.15640946\n",
      "Training at Epoch 62 iteration 200 with loss 0.11651558\n",
      "Training at Epoch 62 iteration 300 with loss 0.1702704\n",
      "Validation at Epoch 62 , MSE: 0.2162447095154239 , Pearson Correlation: 0.8374758847636822 with p-value: 0.0 , Concordance Index: 0.8369025658169874\n",
      "Training at Epoch 63 iteration 0 with loss 0.15939891\n",
      "Training at Epoch 63 iteration 100 with loss 0.15985921\n",
      "Training at Epoch 63 iteration 200 with loss 0.16121107\n",
      "Training at Epoch 63 iteration 300 with loss 0.16741844\n",
      "Validation at Epoch 63 , MSE: 0.2756391213687168 , Pearson Correlation: 0.8423224386672058 with p-value: 0.0 , Concordance Index: 0.8402666501316889\n",
      "Training at Epoch 64 iteration 0 with loss 0.17065248\n",
      "Training at Epoch 64 iteration 100 with loss 0.16979195\n",
      "Training at Epoch 64 iteration 200 with loss 0.1779838\n",
      "Training at Epoch 64 iteration 300 with loss 0.1243289\n",
      "Validation at Epoch 64 , MSE: 0.21367358112252594 , Pearson Correlation: 0.8412688018890631 with p-value: 0.0 , Concordance Index: 0.8431657033356744\n",
      "Training at Epoch 65 iteration 0 with loss 0.10653531\n",
      "Training at Epoch 65 iteration 100 with loss 0.123516455\n",
      "Training at Epoch 65 iteration 200 with loss 0.14685814\n",
      "Training at Epoch 65 iteration 300 with loss 0.16070805\n",
      "Validation at Epoch 65 , MSE: 0.20601349676311673 , Pearson Correlation: 0.8427587170010579 with p-value: 0.0 , Concordance Index: 0.8434652358097844\n",
      "Training at Epoch 66 iteration 0 with loss 0.13670954\n",
      "Training at Epoch 66 iteration 100 with loss 0.1612285\n",
      "Training at Epoch 66 iteration 200 with loss 0.13986418\n",
      "Training at Epoch 66 iteration 300 with loss 0.20413469\n",
      "Validation at Epoch 66 , MSE: 0.21948135905803182 , Pearson Correlation: 0.8405495493810491 with p-value: 0.0 , Concordance Index: 0.8415147058917031\n",
      "Training at Epoch 67 iteration 0 with loss 0.12630597\n",
      "Training at Epoch 67 iteration 100 with loss 0.15750438\n",
      "Training at Epoch 67 iteration 200 with loss 0.10876533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 67 iteration 300 with loss 0.14193657\n",
      "Validation at Epoch 67 , MSE: 0.20856750871228383 , Pearson Correlation: 0.8429001782451714 with p-value: 0.0 , Concordance Index: 0.8417360115920044\n",
      "Training at Epoch 68 iteration 0 with loss 0.107186705\n",
      "Training at Epoch 68 iteration 100 with loss 0.12097235\n",
      "Training at Epoch 68 iteration 200 with loss 0.11111714\n",
      "Training at Epoch 68 iteration 300 with loss 0.13749462\n",
      "Validation at Epoch 68 , MSE: 0.2023187404043579 , Pearson Correlation: 0.8437123674403135 with p-value: 0.0 , Concordance Index: 0.8441180641614258\n",
      "Training at Epoch 69 iteration 0 with loss 0.13140449\n",
      "Training at Epoch 69 iteration 100 with loss 0.14743677\n",
      "Training at Epoch 69 iteration 200 with loss 0.12306302\n",
      "Training at Epoch 69 iteration 300 with loss 0.16115318\n",
      "Validation at Epoch 69 , MSE: 0.20788437705473423 , Pearson Correlation: 0.8422315875620378 with p-value: 0.0 , Concordance Index: 0.8416793794950875\n",
      "Training at Epoch 70 iteration 0 with loss 0.12666376\n",
      "Training at Epoch 70 iteration 100 with loss 0.12379304\n",
      "Training at Epoch 70 iteration 200 with loss 0.09857385\n",
      "Training at Epoch 70 iteration 300 with loss 0.14105771\n",
      "Validation at Epoch 70 , MSE: 0.2032973529984822 , Pearson Correlation: 0.8453484882542686 with p-value: 0.0 , Concordance Index: 0.8457166227965974\n",
      "Training at Epoch 71 iteration 0 with loss 0.10225665\n",
      "Training at Epoch 71 iteration 100 with loss 0.19021757\n",
      "Training at Epoch 71 iteration 200 with loss 0.13823912\n",
      "Training at Epoch 71 iteration 300 with loss 0.16305545\n",
      "Validation at Epoch 71 , MSE: 0.21069843178497505 , Pearson Correlation: 0.8436724261637155 with p-value: 0.0 , Concordance Index: 0.8451032900720226\n",
      "Training at Epoch 72 iteration 0 with loss 0.101149544\n",
      "Training at Epoch 72 iteration 100 with loss 0.14553498\n",
      "Training at Epoch 72 iteration 200 with loss 0.14325085\n",
      "Training at Epoch 72 iteration 300 with loss 0.13576855\n",
      "Validation at Epoch 72 , MSE: 0.20832088312351932 , Pearson Correlation: 0.8469731326052242 with p-value: 0.0 , Concordance Index: 0.8455185164249581\n",
      "Training at Epoch 73 iteration 0 with loss 0.13514586\n",
      "Training at Epoch 73 iteration 100 with loss 0.118497826\n",
      "Training at Epoch 73 iteration 200 with loss 0.1443201\n",
      "Training at Epoch 73 iteration 300 with loss 0.1113624\n",
      "Validation at Epoch 73 , MSE: 0.20253388316067503 , Pearson Correlation: 0.8441805028660897 with p-value: 0.0 , Concordance Index: 0.8470269042273885\n",
      "Training at Epoch 74 iteration 0 with loss 0.09950824\n",
      "Training at Epoch 74 iteration 100 with loss 0.10273786\n",
      "Training at Epoch 74 iteration 200 with loss 0.104656264\n",
      "Training at Epoch 74 iteration 300 with loss 0.10339452\n",
      "Validation at Epoch 74 , MSE: 0.21705914965444434 , Pearson Correlation: 0.8452427278756023 with p-value: 0.0 , Concordance Index: 0.8499502769886306\n",
      "Training at Epoch 75 iteration 0 with loss 0.14215946\n",
      "Training at Epoch 75 iteration 100 with loss 0.0961847\n",
      "Training at Epoch 75 iteration 200 with loss 0.12331951\n",
      "Training at Epoch 75 iteration 300 with loss 0.15130317\n",
      "Validation at Epoch 75 , MSE: 0.19871417532173935 , Pearson Correlation: 0.8446179648633848 with p-value: 0.0 , Concordance Index: 0.8417817138910132\n",
      "Training at Epoch 76 iteration 0 with loss 0.15954836\n",
      "Training at Epoch 76 iteration 100 with loss 0.13232154\n",
      "Training at Epoch 76 iteration 200 with loss 0.12701261\n",
      "Training at Epoch 76 iteration 300 with loss 0.13210264\n",
      "Validation at Epoch 76 , MSE: 0.2240879919971544 , Pearson Correlation: 0.8445331028002763 with p-value: 0.0 , Concordance Index: 0.8421498149518606\n",
      "Training at Epoch 77 iteration 0 with loss 0.15750398\n",
      "Training at Epoch 77 iteration 100 with loss 0.11341824\n",
      "Training at Epoch 77 iteration 200 with loss 0.114693\n",
      "Training at Epoch 77 iteration 300 with loss 0.13361749\n",
      "Validation at Epoch 77 , MSE: 0.2152338539087079 , Pearson Correlation: 0.8478969625574723 with p-value: 0.0 , Concordance Index: 0.8455267289116134\n",
      "Training at Epoch 78 iteration 0 with loss 0.10080556\n",
      "Training at Epoch 78 iteration 100 with loss 0.12171855\n",
      "Training at Epoch 78 iteration 200 with loss 0.11807407\n",
      "Training at Epoch 78 iteration 300 with loss 0.11452898\n",
      "Validation at Epoch 78 , MSE: 0.18960463618759138 , Pearson Correlation: 0.8518679693765236 with p-value: 0.0 , Concordance Index: 0.8496819519638107\n",
      "Training at Epoch 79 iteration 0 with loss 0.11710593\n",
      "Training at Epoch 79 iteration 100 with loss 0.1476192\n",
      "Training at Epoch 79 iteration 200 with loss 0.13384058\n",
      "Training at Epoch 79 iteration 300 with loss 0.12313308\n",
      "Validation at Epoch 79 , MSE: 0.19822040337060512 , Pearson Correlation: 0.8503488534686926 with p-value: 0.0 , Concordance Index: 0.8491997843832444\n",
      "Training at Epoch 80 iteration 0 with loss 0.087387584\n",
      "Training at Epoch 80 iteration 100 with loss 0.10811463\n",
      "Training at Epoch 80 iteration 200 with loss 0.18600343\n",
      "Training at Epoch 80 iteration 300 with loss 0.10030829\n",
      "Validation at Epoch 80 , MSE: 0.1932626936966475 , Pearson Correlation: 0.8513422745569593 with p-value: 0.0 , Concordance Index: 0.8515337428142256\n",
      "Training at Epoch 81 iteration 0 with loss 0.098010935\n",
      "Training at Epoch 81 iteration 100 with loss 0.14005096\n",
      "Training at Epoch 81 iteration 200 with loss 0.08274831\n",
      "Training at Epoch 81 iteration 300 with loss 0.11399409\n",
      "Validation at Epoch 81 , MSE: 0.19758804520753495 , Pearson Correlation: 0.8527537063190721 with p-value: 0.0 , Concordance Index: 0.8509730986791506\n",
      "Training at Epoch 82 iteration 0 with loss 0.10215923\n",
      "Training at Epoch 82 iteration 100 with loss 0.088796765\n",
      "Training at Epoch 82 iteration 200 with loss 0.1028263\n",
      "Training at Epoch 82 iteration 300 with loss 0.11578086\n",
      "Validation at Epoch 82 , MSE: 0.21772542272704945 , Pearson Correlation: 0.8529054553962128 with p-value: 0.0 , Concordance Index: 0.8475180563440468\n",
      "Training at Epoch 83 iteration 0 with loss 0.1321531\n",
      "Training at Epoch 83 iteration 100 with loss 0.09774816\n",
      "Training at Epoch 83 iteration 200 with loss 0.10050143\n",
      "Training at Epoch 83 iteration 300 with loss 0.09495833\n",
      "Validation at Epoch 83 , MSE: 0.2136586002959394 , Pearson Correlation: 0.8508724011744425 with p-value: 0.0 , Concordance Index: 0.8516967663511669\n",
      "Training at Epoch 84 iteration 0 with loss 0.12597932\n",
      "Training at Epoch 84 iteration 100 with loss 0.124858126\n",
      "Training at Epoch 84 iteration 200 with loss 0.12111996\n",
      "Training at Epoch 84 iteration 300 with loss 0.08302106\n",
      "Validation at Epoch 84 , MSE: 0.1990206659886085 , Pearson Correlation: 0.8477119170050185 with p-value: 0.0 , Concordance Index: 0.8468090878877765\n",
      "Training at Epoch 85 iteration 0 with loss 0.07115703\n",
      "Training at Epoch 85 iteration 100 with loss 0.1317057\n",
      "Training at Epoch 85 iteration 200 with loss 0.09400135\n",
      "Training at Epoch 85 iteration 300 with loss 0.08817591\n",
      "Validation at Epoch 85 , MSE: 0.1880923648098855 , Pearson Correlation: 0.8524468842300589 with p-value: 0.0 , Concordance Index: 0.8530510470307388\n",
      "Training at Epoch 86 iteration 0 with loss 0.090310104\n",
      "Training at Epoch 86 iteration 100 with loss 0.123432584\n",
      "Training at Epoch 86 iteration 200 with loss 0.0826193\n",
      "Training at Epoch 86 iteration 300 with loss 0.15323539\n",
      "Validation at Epoch 86 , MSE: 0.19529560739508625 , Pearson Correlation: 0.8476772162914558 with p-value: 0.0 , Concordance Index: 0.8502067033691905\n",
      "Training at Epoch 87 iteration 0 with loss 0.080911815\n",
      "Training at Epoch 87 iteration 100 with loss 0.13101102\n",
      "Training at Epoch 87 iteration 200 with loss 0.08883078\n",
      "Training at Epoch 87 iteration 300 with loss 0.12456667\n",
      "Validation at Epoch 87 , MSE: 0.1981152364558615 , Pearson Correlation: 0.8516459469462152 with p-value: 0.0 , Concordance Index: 0.851878531009729\n",
      "Training at Epoch 88 iteration 0 with loss 0.07875684\n",
      "Training at Epoch 88 iteration 100 with loss 0.113229\n",
      "Training at Epoch 88 iteration 200 with loss 0.09287766\n",
      "Training at Epoch 88 iteration 300 with loss 0.09923973\n",
      "Validation at Epoch 88 , MSE: 0.2791987337318223 , Pearson Correlation: 0.8473231716104132 with p-value: 0.0 , Concordance Index: 0.8484163358636674\n",
      "Training at Epoch 89 iteration 0 with loss 0.1758956\n",
      "Training at Epoch 89 iteration 100 with loss 0.15466869\n",
      "Training at Epoch 89 iteration 200 with loss 0.06840886\n",
      "Training at Epoch 89 iteration 300 with loss 0.09052813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation at Epoch 89 , MSE: 0.18879584363341734 , Pearson Correlation: 0.8552581698425819 with p-value: 0.0 , Concordance Index: 0.8493616044313579\n",
      "Training at Epoch 90 iteration 0 with loss 0.10148429\n",
      "Training at Epoch 90 iteration 100 with loss 0.07839349\n",
      "Training at Epoch 90 iteration 200 with loss 0.07834745\n",
      "Training at Epoch 90 iteration 300 with loss 0.0998727\n",
      "Validation at Epoch 90 , MSE: 0.19582125600456016 , Pearson Correlation: 0.8511291809184155 with p-value: 0.0 , Concordance Index: 0.8505655474059094\n",
      "Training at Epoch 91 iteration 0 with loss 0.081786595\n",
      "Training at Epoch 91 iteration 100 with loss 0.09030631\n",
      "Training at Epoch 91 iteration 200 with loss 0.10174892\n",
      "Training at Epoch 91 iteration 300 with loss 0.11394987\n",
      "Validation at Epoch 91 , MSE: 0.20908388322739013 , Pearson Correlation: 0.8478519940615383 with p-value: 0.0 , Concordance Index: 0.8477589281991904\n",
      "Training at Epoch 92 iteration 0 with loss 0.07235121\n",
      "Training at Epoch 92 iteration 100 with loss 0.08341678\n",
      "Training at Epoch 92 iteration 200 with loss 0.11056797\n",
      "Training at Epoch 92 iteration 300 with loss 0.110210285\n",
      "Validation at Epoch 92 , MSE: 0.19718609031082673 , Pearson Correlation: 0.8528774001655518 with p-value: 0.0 , Concordance Index: 0.851195925770989\n",
      "Training at Epoch 93 iteration 0 with loss 0.08601681\n",
      "Training at Epoch 93 iteration 100 with loss 0.08848184\n",
      "Training at Epoch 93 iteration 200 with loss 0.14170763\n",
      "Training at Epoch 93 iteration 300 with loss 0.14256622\n",
      "Validation at Epoch 93 , MSE: 0.18961202081054754 , Pearson Correlation: 0.8550672175716182 with p-value: 0.0 , Concordance Index: 0.8546280564036914\n",
      "Training at Epoch 94 iteration 0 with loss 0.08315914\n",
      "Training at Epoch 94 iteration 100 with loss 0.07144792\n",
      "Training at Epoch 94 iteration 200 with loss 0.109951824\n",
      "Training at Epoch 94 iteration 300 with loss 0.07713781\n",
      "Validation at Epoch 94 , MSE: 0.2025433794457135 , Pearson Correlation: 0.8565218271749488 with p-value: 0.0 , Concordance Index: 0.8569312236865494\n",
      "Training at Epoch 95 iteration 0 with loss 0.085088074\n",
      "Training at Epoch 95 iteration 100 with loss 0.09484902\n",
      "Training at Epoch 95 iteration 200 with loss 0.07999084\n",
      "Training at Epoch 95 iteration 300 with loss 0.11516863\n",
      "Validation at Epoch 95 , MSE: 0.195291974748004 , Pearson Correlation: 0.8487014918161339 with p-value: 0.0 , Concordance Index: 0.8531190857796275\n",
      "Training at Epoch 96 iteration 0 with loss 0.081413455\n",
      "Training at Epoch 96 iteration 100 with loss 0.06010697\n",
      "Training at Epoch 96 iteration 200 with loss 0.1060314\n",
      "Training at Epoch 96 iteration 300 with loss 0.08848443\n",
      "Validation at Epoch 96 , MSE: 0.1903152710427138 , Pearson Correlation: 0.8529740974876179 with p-value: 0.0 , Concordance Index: 0.8525666919767684\n",
      "Training at Epoch 97 iteration 0 with loss 0.08045774\n",
      "Training at Epoch 97 iteration 100 with loss 0.07858796\n",
      "Training at Epoch 97 iteration 200 with loss 0.09438899\n",
      "Training at Epoch 97 iteration 300 with loss 0.1323199\n",
      "Validation at Epoch 97 , MSE: 0.1888422605033678 , Pearson Correlation: 0.8521231818633057 with p-value: 0.0 , Concordance Index: 0.8529498177251833\n",
      "Training at Epoch 98 iteration 0 with loss 0.07730898\n",
      "Training at Epoch 98 iteration 100 with loss 0.09733562\n",
      "Training at Epoch 98 iteration 200 with loss 0.06377132\n",
      "Training at Epoch 98 iteration 300 with loss 0.113953054\n",
      "Validation at Epoch 98 , MSE: 0.21204893970889843 , Pearson Correlation: 0.8565689045993777 with p-value: 0.0 , Concordance Index: 0.8556206621986097\n",
      "Training at Epoch 99 iteration 0 with loss 0.09585332\n",
      "Training at Epoch 99 iteration 100 with loss 0.08413041\n",
      "Training at Epoch 99 iteration 200 with loss 0.0944461\n",
      "Training at Epoch 99 iteration 300 with loss 0.065783754\n",
      "Validation at Epoch 99 , MSE: 0.20532750896585933 , Pearson Correlation: 0.8597496055395153 with p-value: 0.0 , Concordance Index: 0.8568210174140141\n",
      "Training at Epoch 100 iteration 0 with loss 0.11175461\n",
      "Training at Epoch 100 iteration 100 with loss 0.08406766\n",
      "Training at Epoch 100 iteration 200 with loss 0.098233305\n",
      "Training at Epoch 100 iteration 300 with loss 0.1574293\n",
      "Validation at Epoch 100 , MSE: 0.1918805189450315 , Pearson Correlation: 0.8567659539114503 with p-value: 0.0 , Concordance Index: 0.8551461394212893\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.19945655726244765 , Pearson Correlation: 0.8506343800999702 with p-value: 0.0 , Concordance Index: 0.8536301623899886\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n",
      "Let's use 1 GPU/s!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 138.70436\n",
      "Training at Epoch 1 iteration 100 with loss 0.77190566\n",
      "Training at Epoch 1 iteration 200 with loss 0.835519\n",
      "Training at Epoch 1 iteration 300 with loss 0.8509926\n",
      "Validation at Epoch 1 , MSE: 0.6235369147324705 , Pearson Correlation: 0.3586581634380183 with p-value: 0.0 , Concordance Index: 0.6424431400227089\n",
      "Training at Epoch 2 iteration 0 with loss 0.38018072\n",
      "Training at Epoch 2 iteration 100 with loss 0.6370832\n",
      "Training at Epoch 2 iteration 200 with loss 0.6170039\n",
      "Training at Epoch 2 iteration 300 with loss 0.511665\n",
      "Validation at Epoch 2 , MSE: 0.532612506927327 , Pearson Correlation: 0.4929160110746351 with p-value: 0.0 , Concordance Index: 0.6989713458759194\n",
      "Training at Epoch 3 iteration 0 with loss 0.4556545\n",
      "Training at Epoch 3 iteration 100 with loss 0.53847533\n",
      "Training at Epoch 3 iteration 200 with loss 0.5321324\n",
      "Training at Epoch 3 iteration 300 with loss 0.4545812\n",
      "Validation at Epoch 3 , MSE: 0.47928677440605816 , Pearson Correlation: 0.5627528616640024 with p-value: 0.0 , Concordance Index: 0.7332646386666231\n",
      "Training at Epoch 4 iteration 0 with loss 0.51106226\n",
      "Training at Epoch 4 iteration 100 with loss 0.55051875\n",
      "Training at Epoch 4 iteration 200 with loss 0.35169065\n",
      "Training at Epoch 4 iteration 300 with loss 0.43755528\n",
      "Validation at Epoch 4 , MSE: 0.46598453151868247 , Pearson Correlation: 0.6111012140055226 with p-value: 0.0 , Concordance Index: 0.7497316646894246\n",
      "Training at Epoch 5 iteration 0 with loss 0.4298411\n",
      "Training at Epoch 5 iteration 100 with loss 0.4379104\n",
      "Training at Epoch 5 iteration 200 with loss 0.4332876\n",
      "Training at Epoch 5 iteration 300 with loss 0.44852278\n",
      "Validation at Epoch 5 , MSE: 0.5376626335871747 , Pearson Correlation: 0.6315824415700547 with p-value: 0.0 , Concordance Index: 0.755747357022217\n",
      "Training at Epoch 6 iteration 0 with loss 0.7071015\n",
      "Training at Epoch 6 iteration 100 with loss 0.43735507\n",
      "Training at Epoch 6 iteration 200 with loss 0.33615276\n",
      "Training at Epoch 6 iteration 300 with loss 0.4852496\n",
      "Validation at Epoch 6 , MSE: 0.6584870702494158 , Pearson Correlation: 0.6464636440946026 with p-value: 0.0 , Concordance Index: 0.7628166436484832\n",
      "Training at Epoch 7 iteration 0 with loss 0.53394544\n",
      "Training at Epoch 7 iteration 100 with loss 0.39702135\n",
      "Training at Epoch 7 iteration 200 with loss 0.33597288\n",
      "Training at Epoch 7 iteration 300 with loss 0.45907682\n",
      "Validation at Epoch 7 , MSE: 0.40545179799579384 , Pearson Correlation: 0.6579321426215908 with p-value: 0.0 , Concordance Index: 0.7656125014013903\n",
      "Training at Epoch 8 iteration 0 with loss 0.31325215\n",
      "Training at Epoch 8 iteration 100 with loss 0.3441312\n",
      "Training at Epoch 8 iteration 200 with loss 0.3754233\n",
      "Training at Epoch 8 iteration 300 with loss 0.29644266\n",
      "Validation at Epoch 8 , MSE: 0.40431573676899757 , Pearson Correlation: 0.660783790169667 with p-value: 0.0 , Concordance Index: 0.7676248970680835\n",
      "Training at Epoch 9 iteration 0 with loss 0.36800858\n",
      "Training at Epoch 9 iteration 100 with loss 0.31777158\n",
      "Training at Epoch 9 iteration 200 with loss 0.43517676\n",
      "Training at Epoch 9 iteration 300 with loss 0.4169507\n",
      "Validation at Epoch 9 , MSE: 0.4178544012926201 , Pearson Correlation: 0.6664771330805394 with p-value: 0.0 , Concordance Index: 0.7709277671894957\n",
      "Training at Epoch 10 iteration 0 with loss 0.46478847\n",
      "Training at Epoch 10 iteration 100 with loss 0.34665865\n",
      "Training at Epoch 10 iteration 200 with loss 0.35410255\n",
      "Training at Epoch 10 iteration 300 with loss 0.35237634\n",
      "Validation at Epoch 10 , MSE: 0.3924899290710993 , Pearson Correlation: 0.6630877977151511 with p-value: 0.0 , Concordance Index: 0.7690726964476783\n",
      "Training at Epoch 11 iteration 0 with loss 0.21395397\n",
      "Training at Epoch 11 iteration 100 with loss 0.5402952\n",
      "Training at Epoch 11 iteration 200 with loss 0.48017418\n",
      "Training at Epoch 11 iteration 300 with loss 0.4995064\n",
      "Validation at Epoch 11 , MSE: 0.42666105807041693 , Pearson Correlation: 0.6688235993108258 with p-value: 0.0 , Concordance Index: 0.7697461808909185\n",
      "Training at Epoch 12 iteration 0 with loss 0.35394755\n",
      "Training at Epoch 12 iteration 100 with loss 0.54481465\n",
      "Training at Epoch 12 iteration 200 with loss 0.35378915\n",
      "Training at Epoch 12 iteration 300 with loss 0.5515803\n",
      "Validation at Epoch 12 , MSE: 0.4846991311338236 , Pearson Correlation: 0.6653112379147401 with p-value: 0.0 , Concordance Index: 0.7700400018708909\n",
      "Training at Epoch 13 iteration 0 with loss 0.46239695\n",
      "Training at Epoch 13 iteration 100 with loss 0.3752057\n",
      "Training at Epoch 13 iteration 200 with loss 0.43505234\n",
      "Training at Epoch 13 iteration 300 with loss 0.5880359\n",
      "Validation at Epoch 13 , MSE: 0.39582235324442344 , Pearson Correlation: 0.6683967874255298 with p-value: 0.0 , Concordance Index: 0.7696803577281591\n",
      "Training at Epoch 14 iteration 0 with loss 0.39245534\n",
      "Training at Epoch 14 iteration 100 with loss 0.43248585\n",
      "Training at Epoch 14 iteration 200 with loss 0.4494274\n",
      "Training at Epoch 14 iteration 300 with loss 0.32755578\n",
      "Validation at Epoch 14 , MSE: 0.43758263426050487 , Pearson Correlation: 0.665391399564369 with p-value: 0.0 , Concordance Index: 0.7700909429461621\n",
      "Training at Epoch 15 iteration 0 with loss 0.47959507\n",
      "Training at Epoch 15 iteration 100 with loss 0.52841264\n",
      "Training at Epoch 15 iteration 200 with loss 0.40621692\n",
      "Training at Epoch 15 iteration 300 with loss 0.44987\n",
      "Validation at Epoch 15 , MSE: 0.3786423848696961 , Pearson Correlation: 0.6768346030722562 with p-value: 0.0 , Concordance Index: 0.7709040632850216\n",
      "Training at Epoch 16 iteration 0 with loss 0.3802788\n",
      "Training at Epoch 16 iteration 100 with loss 0.28987768\n",
      "Training at Epoch 16 iteration 200 with loss 0.41436705\n",
      "Training at Epoch 16 iteration 300 with loss 0.447667\n",
      "Validation at Epoch 16 , MSE: 0.40357091385443705 , Pearson Correlation: 0.7013943907804653 with p-value: 0.0 , Concordance Index: 0.7777759939112212\n",
      "Training at Epoch 17 iteration 0 with loss 0.3514731\n",
      "Training at Epoch 17 iteration 100 with loss 0.29686916\n",
      "Training at Epoch 17 iteration 200 with loss 0.35128835\n",
      "Training at Epoch 17 iteration 300 with loss 0.34617412\n",
      "Validation at Epoch 17 , MSE: 0.34250805832475056 , Pearson Correlation: 0.7140656797477349 with p-value: 0.0 , Concordance Index: 0.7863624741755683\n",
      "Training at Epoch 18 iteration 0 with loss 0.28538734\n",
      "Training at Epoch 18 iteration 100 with loss 0.3551262\n",
      "Training at Epoch 18 iteration 200 with loss 0.6058735\n",
      "Training at Epoch 18 iteration 300 with loss 0.46556604\n",
      "Validation at Epoch 18 , MSE: 0.34333253299286376 , Pearson Correlation: 0.7196101224287004 with p-value: 0.0 , Concordance Index: 0.7866186246351524\n",
      "Training at Epoch 19 iteration 0 with loss 0.28081372\n",
      "Training at Epoch 19 iteration 100 with loss 0.28726766\n",
      "Training at Epoch 19 iteration 200 with loss 0.41283366\n",
      "Training at Epoch 19 iteration 300 with loss 0.28130257\n",
      "Validation at Epoch 19 , MSE: 0.32764437417764325 , Pearson Correlation: 0.7324042833755335 with p-value: 0.0 , Concordance Index: 0.7925721405597199\n",
      "Training at Epoch 20 iteration 0 with loss 0.29795957\n",
      "Training at Epoch 20 iteration 100 with loss 0.30837846\n",
      "Training at Epoch 20 iteration 200 with loss 0.23495464\n",
      "Training at Epoch 20 iteration 300 with loss 0.50339\n",
      "Validation at Epoch 20 , MSE: 0.3278936093435069 , Pearson Correlation: 0.7334774402643062 with p-value: 0.0 , Concordance Index: 0.7903744489069187\n",
      "Training at Epoch 21 iteration 0 with loss 0.27201328\n",
      "Training at Epoch 21 iteration 100 with loss 0.27889916\n",
      "Training at Epoch 21 iteration 200 with loss 0.40082103\n",
      "Training at Epoch 21 iteration 300 with loss 0.29395092\n",
      "Validation at Epoch 21 , MSE: 0.33040213369801197 , Pearson Correlation: 0.7342938293456455 with p-value: 0.0 , Concordance Index: 0.7937664072744793\n",
      "Training at Epoch 22 iteration 0 with loss 0.34524944\n",
      "Training at Epoch 22 iteration 100 with loss 0.40990883\n",
      "Training at Epoch 22 iteration 200 with loss 0.2900573\n",
      "Training at Epoch 22 iteration 300 with loss 0.29405865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation at Epoch 22 , MSE: 0.3393880142118578 , Pearson Correlation: 0.7269140717230155 with p-value: 0.0 , Concordance Index: 0.7860269651925148\n",
      "Training at Epoch 23 iteration 0 with loss 0.30672795\n",
      "Training at Epoch 23 iteration 100 with loss 0.33132145\n",
      "Training at Epoch 23 iteration 200 with loss 0.31989515\n",
      "Training at Epoch 23 iteration 300 with loss 0.31595206\n",
      "Validation at Epoch 23 , MSE: 0.32213744833859587 , Pearson Correlation: 0.7359154472478122 with p-value: 0.0 , Concordance Index: 0.7957903182117151\n",
      "Training at Epoch 24 iteration 0 with loss 0.14728713\n",
      "Training at Epoch 24 iteration 100 with loss 0.39326212\n",
      "Training at Epoch 24 iteration 200 with loss 0.3834597\n",
      "Training at Epoch 24 iteration 300 with loss 0.321271\n",
      "Validation at Epoch 24 , MSE: 0.3782266757545426 , Pearson Correlation: 0.7459550423934508 with p-value: 0.0 , Concordance Index: 0.7975727716298355\n",
      "Training at Epoch 25 iteration 0 with loss 0.27293366\n",
      "Training at Epoch 25 iteration 100 with loss 0.35112056\n",
      "Training at Epoch 25 iteration 200 with loss 0.25554675\n",
      "Training at Epoch 25 iteration 300 with loss 0.27230382\n",
      "Validation at Epoch 25 , MSE: 0.33374565249372373 , Pearson Correlation: 0.7461263277159845 with p-value: 0.0 , Concordance Index: 0.7977340913397615\n",
      "Training at Epoch 26 iteration 0 with loss 0.27576497\n",
      "Training at Epoch 26 iteration 100 with loss 0.24993989\n",
      "Training at Epoch 26 iteration 200 with loss 0.335369\n",
      "Training at Epoch 26 iteration 300 with loss 0.2713703\n",
      "Validation at Epoch 26 , MSE: 0.30513435326569827 , Pearson Correlation: 0.7533686605162403 with p-value: 0.0 , Concordance Index: 0.8033313375044235\n",
      "Training at Epoch 27 iteration 0 with loss 0.32611308\n",
      "Training at Epoch 27 iteration 100 with loss 0.3317419\n",
      "Training at Epoch 27 iteration 200 with loss 0.26004958\n",
      "Training at Epoch 27 iteration 300 with loss 0.25287864\n",
      "Validation at Epoch 27 , MSE: 0.3452720125165378 , Pearson Correlation: 0.7579091024433358 with p-value: 0.0 , Concordance Index: 0.8014088623307642\n",
      "Training at Epoch 28 iteration 0 with loss 0.3111032\n",
      "Training at Epoch 28 iteration 100 with loss 0.33435333\n",
      "Training at Epoch 28 iteration 200 with loss 0.33662695\n",
      "Training at Epoch 28 iteration 300 with loss 0.32890117\n",
      "Validation at Epoch 28 , MSE: 0.3005602132018499 , Pearson Correlation: 0.7548536321121251 with p-value: 0.0 , Concordance Index: 0.8075375208294372\n",
      "Training at Epoch 29 iteration 0 with loss 0.20135166\n",
      "Training at Epoch 29 iteration 100 with loss 0.31760427\n",
      "Training at Epoch 29 iteration 200 with loss 0.18156941\n",
      "Training at Epoch 29 iteration 300 with loss 0.2346712\n",
      "Validation at Epoch 29 , MSE: 0.2960819596811985 , Pearson Correlation: 0.7636897105932997 with p-value: 0.0 , Concordance Index: 0.8098500625524325\n",
      "Training at Epoch 30 iteration 0 with loss 0.25248596\n",
      "Training at Epoch 30 iteration 100 with loss 0.2746926\n",
      "Training at Epoch 30 iteration 200 with loss 0.272445\n",
      "Training at Epoch 30 iteration 300 with loss 0.33225274\n",
      "Validation at Epoch 30 , MSE: 0.3300658442864761 , Pearson Correlation: 0.7600134418111603 with p-value: 0.0 , Concordance Index: 0.8020597096587199\n",
      "Training at Epoch 31 iteration 0 with loss 0.24910855\n",
      "Training at Epoch 31 iteration 100 with loss 0.22140932\n",
      "Training at Epoch 31 iteration 200 with loss 0.21652661\n",
      "Training at Epoch 31 iteration 300 with loss 0.34060332\n",
      "Validation at Epoch 31 , MSE: 0.3036305533262611 , Pearson Correlation: 0.7673789054805209 with p-value: 0.0 , Concordance Index: 0.8071058873311127\n",
      "Training at Epoch 32 iteration 0 with loss 0.30486047\n",
      "Training at Epoch 32 iteration 100 with loss 0.21768004\n",
      "Training at Epoch 32 iteration 200 with loss 0.26704356\n",
      "Training at Epoch 32 iteration 300 with loss 0.41802365\n",
      "Validation at Epoch 32 , MSE: 0.31345533541367254 , Pearson Correlation: 0.7702380135088847 with p-value: 0.0 , Concordance Index: 0.8093591201146976\n",
      "Training at Epoch 33 iteration 0 with loss 0.27726316\n",
      "Training at Epoch 33 iteration 100 with loss 0.34698036\n",
      "Training at Epoch 33 iteration 200 with loss 0.29039684\n",
      "Training at Epoch 33 iteration 300 with loss 0.20541088\n",
      "Validation at Epoch 33 , MSE: 0.2856259136670464 , Pearson Correlation: 0.7725228170113821 with p-value: 0.0 , Concordance Index: 0.8086182917666618\n",
      "Training at Epoch 34 iteration 0 with loss 0.21480432\n",
      "Training at Epoch 34 iteration 100 with loss 0.2717499\n",
      "Training at Epoch 34 iteration 200 with loss 0.23664276\n",
      "Training at Epoch 34 iteration 300 with loss 0.33717358\n",
      "Validation at Epoch 34 , MSE: 0.34067098965999504 , Pearson Correlation: 0.773720634085674 with p-value: 0.0 , Concordance Index: 0.8079480379545133\n",
      "Training at Epoch 35 iteration 0 with loss 0.2664231\n",
      "Training at Epoch 35 iteration 100 with loss 0.20618579\n",
      "Training at Epoch 35 iteration 200 with loss 0.2412881\n",
      "Training at Epoch 35 iteration 300 with loss 0.2441738\n",
      "Validation at Epoch 35 , MSE: 0.3400088834642219 , Pearson Correlation: 0.7729420461149002 with p-value: 0.0 , Concordance Index: 0.8048249482921227\n",
      "Training at Epoch 36 iteration 0 with loss 0.26933986\n",
      "Training at Epoch 36 iteration 100 with loss 0.32410032\n",
      "Training at Epoch 36 iteration 200 with loss 0.2817513\n",
      "Training at Epoch 36 iteration 300 with loss 0.305124\n",
      "Validation at Epoch 36 , MSE: 0.2732060332983316 , Pearson Correlation: 0.7831570354513445 with p-value: 0.0 , Concordance Index: 0.8139320443786119\n",
      "Training at Epoch 37 iteration 0 with loss 0.2935128\n",
      "Training at Epoch 37 iteration 100 with loss 0.25832528\n",
      "Training at Epoch 37 iteration 200 with loss 0.2511591\n",
      "Training at Epoch 37 iteration 300 with loss 0.25279203\n",
      "Validation at Epoch 37 , MSE: 0.28603140703375746 , Pearson Correlation: 0.7809911551772045 with p-value: 0.0 , Concordance Index: 0.8165558464367705\n",
      "Training at Epoch 38 iteration 0 with loss 0.23359919\n",
      "Training at Epoch 38 iteration 100 with loss 0.2722391\n",
      "Training at Epoch 38 iteration 200 with loss 0.2778921\n",
      "Training at Epoch 38 iteration 300 with loss 0.27911475\n",
      "Validation at Epoch 38 , MSE: 0.31458021751840765 , Pearson Correlation: 0.778913676038954 with p-value: 0.0 , Concordance Index: 0.8122627084439875\n",
      "Training at Epoch 39 iteration 0 with loss 0.23726209\n",
      "Training at Epoch 39 iteration 100 with loss 0.17777762\n",
      "Training at Epoch 39 iteration 200 with loss 0.3568254\n",
      "Training at Epoch 39 iteration 300 with loss 0.26174134\n",
      "Validation at Epoch 39 , MSE: 0.27775761857373704 , Pearson Correlation: 0.785283822641993 with p-value: 0.0 , Concordance Index: 0.814803754898208\n",
      "Training at Epoch 40 iteration 0 with loss 0.19602028\n",
      "Training at Epoch 40 iteration 100 with loss 0.19944355\n",
      "Training at Epoch 40 iteration 200 with loss 0.33905518\n",
      "Training at Epoch 40 iteration 300 with loss 0.20670643\n",
      "Validation at Epoch 40 , MSE: 0.2887556600600849 , Pearson Correlation: 0.7787329239674831 with p-value: 0.0 , Concordance Index: 0.8064581344483949\n",
      "Training at Epoch 41 iteration 0 with loss 0.1792168\n",
      "Training at Epoch 41 iteration 100 with loss 0.26709503\n",
      "Training at Epoch 41 iteration 200 with loss 0.16611339\n",
      "Training at Epoch 41 iteration 300 with loss 0.29860362\n",
      "Validation at Epoch 41 , MSE: 0.27554719338658656 , Pearson Correlation: 0.7803464970313887 with p-value: 0.0 , Concordance Index: 0.8127403651950781\n",
      "Training at Epoch 42 iteration 0 with loss 0.2681116\n",
      "Training at Epoch 42 iteration 100 with loss 0.28016093\n",
      "Training at Epoch 42 iteration 200 with loss 0.24097097\n",
      "Training at Epoch 42 iteration 300 with loss 0.18145871\n",
      "Validation at Epoch 42 , MSE: 0.32056608360556876 , Pearson Correlation: 0.786040575597243 with p-value: 0.0 , Concordance Index: 0.8080244760480028\n",
      "Training at Epoch 43 iteration 0 with loss 0.25500587\n",
      "Training at Epoch 43 iteration 100 with loss 0.25786725\n",
      "Training at Epoch 43 iteration 200 with loss 0.26387545\n",
      "Training at Epoch 43 iteration 300 with loss 0.25102583\n",
      "Validation at Epoch 43 , MSE: 0.26614052528175763 , Pearson Correlation: 0.7948780377833824 with p-value: 0.0 , Concordance Index: 0.8183807217484073\n",
      "Training at Epoch 44 iteration 0 with loss 0.1790553\n",
      "Training at Epoch 44 iteration 100 with loss 0.19476643\n",
      "Training at Epoch 44 iteration 200 with loss 0.24363787\n",
      "Training at Epoch 44 iteration 300 with loss 0.17747802\n",
      "Validation at Epoch 44 , MSE: 0.3588827070331088 , Pearson Correlation: 0.7970003396419301 with p-value: 0.0 , Concordance Index: 0.8167629775548009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 45 iteration 0 with loss 0.28850788\n",
      "Training at Epoch 45 iteration 100 with loss 0.18743822\n",
      "Training at Epoch 45 iteration 200 with loss 0.22433424\n",
      "Training at Epoch 45 iteration 300 with loss 0.2102351\n",
      "Validation at Epoch 45 , MSE: 0.2598641662874676 , Pearson Correlation: 0.7971477507404899 with p-value: 0.0 , Concordance Index: 0.8216566195048497\n",
      "Training at Epoch 46 iteration 0 with loss 0.18351835\n",
      "Training at Epoch 46 iteration 100 with loss 0.19739759\n",
      "Training at Epoch 46 iteration 200 with loss 0.13399619\n",
      "Training at Epoch 46 iteration 300 with loss 0.24391958\n",
      "Validation at Epoch 46 , MSE: 0.2756735428158841 , Pearson Correlation: 0.7985692534932324 with p-value: 0.0 , Concordance Index: 0.8202253213112295\n",
      "Training at Epoch 47 iteration 0 with loss 0.19435152\n",
      "Training at Epoch 47 iteration 100 with loss 0.2399174\n",
      "Training at Epoch 47 iteration 200 with loss 0.25317234\n",
      "Training at Epoch 47 iteration 300 with loss 0.18715021\n",
      "Validation at Epoch 47 , MSE: 0.2555638645780942 , Pearson Correlation: 0.7993230922316944 with p-value: 0.0 , Concordance Index: 0.8215105147811662\n",
      "Training at Epoch 48 iteration 0 with loss 0.23482996\n",
      "Training at Epoch 48 iteration 100 with loss 0.19024217\n",
      "Training at Epoch 48 iteration 200 with loss 0.18498763\n",
      "Training at Epoch 48 iteration 300 with loss 0.29344612\n",
      "Validation at Epoch 48 , MSE: 0.24875007961658988 , Pearson Correlation: 0.8039997002667421 with p-value: 0.0 , Concordance Index: 0.8249063090502808\n",
      "Training at Epoch 49 iteration 0 with loss 0.1753653\n",
      "Training at Epoch 49 iteration 100 with loss 0.14620245\n",
      "Training at Epoch 49 iteration 200 with loss 0.15458417\n",
      "Training at Epoch 49 iteration 300 with loss 0.16474238\n",
      "Validation at Epoch 49 , MSE: 0.27177773469121225 , Pearson Correlation: 0.8092542260128008 with p-value: 0.0 , Concordance Index: 0.8234446565429835\n",
      "Training at Epoch 50 iteration 0 with loss 0.154239\n",
      "Training at Epoch 50 iteration 100 with loss 0.34041348\n",
      "Training at Epoch 50 iteration 200 with loss 0.23703614\n",
      "Training at Epoch 50 iteration 300 with loss 0.21141538\n",
      "Validation at Epoch 50 , MSE: 0.2663846642932984 , Pearson Correlation: 0.8089688735659999 with p-value: 0.0 , Concordance Index: 0.8253185058008894\n",
      "Training at Epoch 51 iteration 0 with loss 0.18352656\n",
      "Training at Epoch 51 iteration 100 with loss 0.21172145\n",
      "Training at Epoch 51 iteration 200 with loss 0.1707941\n",
      "Training at Epoch 51 iteration 300 with loss 0.18215375\n",
      "Validation at Epoch 51 , MSE: 0.27666157573406924 , Pearson Correlation: 0.808856833359506 with p-value: 0.0 , Concordance Index: 0.8280141610287867\n",
      "Training at Epoch 52 iteration 0 with loss 0.28832197\n",
      "Training at Epoch 52 iteration 100 with loss 0.18278207\n",
      "Training at Epoch 52 iteration 200 with loss 0.2514354\n",
      "Training at Epoch 52 iteration 300 with loss 0.21829934\n",
      "Validation at Epoch 52 , MSE: 0.24767591531629007 , Pearson Correlation: 0.811366012586101 with p-value: 0.0 , Concordance Index: 0.8270128848008854\n",
      "Training at Epoch 53 iteration 0 with loss 0.15718201\n",
      "Training at Epoch 53 iteration 100 with loss 0.21448098\n",
      "Training at Epoch 53 iteration 200 with loss 0.1847619\n",
      "Training at Epoch 53 iteration 300 with loss 0.20146622\n",
      "Validation at Epoch 53 , MSE: 0.25263383762961217 , Pearson Correlation: 0.8085893350627246 with p-value: 0.0 , Concordance Index: 0.8250109678790682\n",
      "Training at Epoch 54 iteration 0 with loss 0.15757607\n",
      "Training at Epoch 54 iteration 100 with loss 0.22591303\n",
      "Training at Epoch 54 iteration 200 with loss 0.21523131\n",
      "Training at Epoch 54 iteration 300 with loss 0.25851783\n",
      "Validation at Epoch 54 , MSE: 0.24041006247447805 , Pearson Correlation: 0.8131601181048463 with p-value: 0.0 , Concordance Index: 0.8314051736612503\n",
      "Training at Epoch 55 iteration 0 with loss 0.22478783\n",
      "Training at Epoch 55 iteration 100 with loss 0.17665015\n",
      "Training at Epoch 55 iteration 200 with loss 0.24763669\n",
      "Training at Epoch 55 iteration 300 with loss 0.15577495\n",
      "Validation at Epoch 55 , MSE: 0.25811069738889514 , Pearson Correlation: 0.8081284066953117 with p-value: 0.0 , Concordance Index: 0.8281720155653168\n",
      "Training at Epoch 56 iteration 0 with loss 0.16159275\n",
      "Training at Epoch 56 iteration 100 with loss 0.23067018\n",
      "Training at Epoch 56 iteration 200 with loss 0.21167493\n",
      "Training at Epoch 56 iteration 300 with loss 0.16315524\n",
      "Validation at Epoch 56 , MSE: 0.2401834790667307 , Pearson Correlation: 0.818561709126579 with p-value: 0.0 , Concordance Index: 0.8352757420808796\n",
      "Training at Epoch 57 iteration 0 with loss 0.1486764\n",
      "Training at Epoch 57 iteration 100 with loss 0.24529678\n",
      "Training at Epoch 57 iteration 200 with loss 0.17097506\n",
      "Training at Epoch 57 iteration 300 with loss 0.19049096\n",
      "Validation at Epoch 57 , MSE: 0.28243345572418205 , Pearson Correlation: 0.8038178467081768 with p-value: 0.0 , Concordance Index: 0.8267509010472223\n",
      "Training at Epoch 58 iteration 0 with loss 0.1703794\n",
      "Training at Epoch 58 iteration 100 with loss 0.18162884\n",
      "Training at Epoch 58 iteration 200 with loss 0.24158773\n",
      "Training at Epoch 58 iteration 300 with loss 0.14376487\n",
      "Validation at Epoch 58 , MSE: 0.23399218605398192 , Pearson Correlation: 0.820894721540029 with p-value: 0.0 , Concordance Index: 0.832076812029581\n",
      "Training at Epoch 59 iteration 0 with loss 0.17494571\n",
      "Training at Epoch 59 iteration 100 with loss 0.17362754\n",
      "Training at Epoch 59 iteration 200 with loss 0.15774697\n",
      "Training at Epoch 59 iteration 300 with loss 0.15005536\n",
      "Validation at Epoch 59 , MSE: 0.2378634915160593 , Pearson Correlation: 0.817412042098279 with p-value: 0.0 , Concordance Index: 0.8298904843297066\n",
      "Training at Epoch 60 iteration 0 with loss 0.14116493\n",
      "Training at Epoch 60 iteration 100 with loss 0.13605273\n",
      "Training at Epoch 60 iteration 200 with loss 0.12415806\n",
      "Training at Epoch 60 iteration 300 with loss 0.2494894\n",
      "Validation at Epoch 60 , MSE: 0.2533767825208104 , Pearson Correlation: 0.8176566228102154 with p-value: 0.0 , Concordance Index: 0.8330358933403892\n",
      "Training at Epoch 61 iteration 0 with loss 0.19814646\n",
      "Training at Epoch 61 iteration 100 with loss 0.16349037\n",
      "Training at Epoch 61 iteration 200 with loss 0.15560676\n",
      "Training at Epoch 61 iteration 300 with loss 0.19552532\n",
      "Validation at Epoch 61 , MSE: 0.2382890385447667 , Pearson Correlation: 0.8206686104967703 with p-value: 0.0 , Concordance Index: 0.834378065458457\n",
      "Training at Epoch 62 iteration 0 with loss 0.16118838\n",
      "Training at Epoch 62 iteration 100 with loss 0.14691553\n",
      "Training at Epoch 62 iteration 200 with loss 0.16279672\n",
      "Training at Epoch 62 iteration 300 with loss 0.20240314\n",
      "Validation at Epoch 62 , MSE: 0.24898992723945435 , Pearson Correlation: 0.8187660841591706 with p-value: 0.0 , Concordance Index: 0.8290794597398223\n",
      "Training at Epoch 63 iteration 0 with loss 0.16357723\n",
      "Training at Epoch 63 iteration 100 with loss 0.18325202\n",
      "Training at Epoch 63 iteration 200 with loss 0.11819803\n",
      "Training at Epoch 63 iteration 300 with loss 0.31542125\n",
      "Validation at Epoch 63 , MSE: 0.22897879916998892 , Pearson Correlation: 0.8241970399557278 with p-value: 0.0 , Concordance Index: 0.8369544597076674\n",
      "Training at Epoch 64 iteration 0 with loss 0.17849222\n",
      "Training at Epoch 64 iteration 100 with loss 0.18868503\n",
      "Training at Epoch 64 iteration 200 with loss 0.23246084\n",
      "Training at Epoch 64 iteration 300 with loss 0.17425406\n",
      "Validation at Epoch 64 , MSE: 0.28491667658023917 , Pearson Correlation: 0.8272108519100264 with p-value: 0.0 , Concordance Index: 0.8377017568837675\n",
      "Training at Epoch 65 iteration 0 with loss 0.18407421\n",
      "Training at Epoch 65 iteration 100 with loss 0.20849906\n",
      "Training at Epoch 65 iteration 200 with loss 0.12440215\n",
      "Training at Epoch 65 iteration 300 with loss 0.11859262\n",
      "Validation at Epoch 65 , MSE: 0.22067825427981336 , Pearson Correlation: 0.827816250265877 with p-value: 0.0 , Concordance Index: 0.8363292909790687\n",
      "Training at Epoch 66 iteration 0 with loss 0.13322388\n",
      "Training at Epoch 66 iteration 100 with loss 0.19043684\n",
      "Training at Epoch 66 iteration 200 with loss 0.2280064\n",
      "Training at Epoch 66 iteration 300 with loss 0.2000229\n",
      "Validation at Epoch 66 , MSE: 0.23699713017947996 , Pearson Correlation: 0.8211899072632208 with p-value: 0.0 , Concordance Index: 0.8333119950275821\n",
      "Training at Epoch 67 iteration 0 with loss 0.12748289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 67 iteration 100 with loss 0.1626054\n",
      "Training at Epoch 67 iteration 200 with loss 0.16200867\n",
      "Training at Epoch 67 iteration 300 with loss 0.24314997\n",
      "Validation at Epoch 67 , MSE: 0.24220169798572483 , Pearson Correlation: 0.8305103502770691 with p-value: 0.0 , Concordance Index: 0.8396372756358862\n",
      "Training at Epoch 68 iteration 0 with loss 0.15531948\n",
      "Training at Epoch 68 iteration 100 with loss 0.1276138\n",
      "Training at Epoch 68 iteration 200 with loss 0.18702063\n",
      "Training at Epoch 68 iteration 300 with loss 0.18783078\n",
      "Validation at Epoch 68 , MSE: 0.22021888784776358 , Pearson Correlation: 0.8307062189322747 with p-value: 0.0 , Concordance Index: 0.8367472831943524\n",
      "Training at Epoch 69 iteration 0 with loss 0.15110177\n",
      "Training at Epoch 69 iteration 100 with loss 0.12532488\n",
      "Training at Epoch 69 iteration 200 with loss 0.11818357\n",
      "Training at Epoch 69 iteration 300 with loss 0.14188606\n",
      "Validation at Epoch 69 , MSE: 0.24422628837861174 , Pearson Correlation: 0.8285167825043569 with p-value: 0.0 , Concordance Index: 0.8379961907000829\n",
      "Training at Epoch 70 iteration 0 with loss 0.11624018\n",
      "Training at Epoch 70 iteration 100 with loss 0.16087393\n",
      "Training at Epoch 70 iteration 200 with loss 0.13352488\n",
      "Training at Epoch 70 iteration 300 with loss 0.19978829\n",
      "Validation at Epoch 70 , MSE: 0.2316787899596019 , Pearson Correlation: 0.8298019731680525 with p-value: 0.0 , Concordance Index: 0.8375196763969895\n",
      "Training at Epoch 71 iteration 0 with loss 0.13473555\n",
      "Training at Epoch 71 iteration 100 with loss 0.13812378\n",
      "Training at Epoch 71 iteration 200 with loss 0.14027329\n",
      "Training at Epoch 71 iteration 300 with loss 0.20505127\n",
      "Validation at Epoch 71 , MSE: 0.2562040038770759 , Pearson Correlation: 0.8333048456219956 with p-value: 0.0 , Concordance Index: 0.840052650056421\n",
      "Training at Epoch 72 iteration 0 with loss 0.19681081\n",
      "Training at Epoch 72 iteration 100 with loss 0.11168083\n",
      "Training at Epoch 72 iteration 200 with loss 0.11320495\n",
      "Training at Epoch 72 iteration 300 with loss 0.21331245\n",
      "Validation at Epoch 72 , MSE: 0.22083099261354305 , Pearson Correlation: 0.8329869886847625 with p-value: 0.0 , Concordance Index: 0.8455633652426373\n",
      "Training at Epoch 73 iteration 0 with loss 0.14853352\n",
      "Training at Epoch 73 iteration 100 with loss 0.14057088\n",
      "Training at Epoch 73 iteration 200 with loss 0.16314033\n",
      "Training at Epoch 73 iteration 300 with loss 0.15696934\n",
      "Validation at Epoch 73 , MSE: 0.21929624212184476 , Pearson Correlation: 0.8346886947401588 with p-value: 0.0 , Concordance Index: 0.8422283325620422\n",
      "Training at Epoch 74 iteration 0 with loss 0.12807694\n",
      "Training at Epoch 74 iteration 100 with loss 0.17628337\n",
      "Training at Epoch 74 iteration 200 with loss 0.14402701\n",
      "Training at Epoch 74 iteration 300 with loss 0.12945521\n",
      "Validation at Epoch 74 , MSE: 0.2179524991788012 , Pearson Correlation: 0.835191810081973 with p-value: 0.0 , Concordance Index: 0.846828819329627\n",
      "Training at Epoch 75 iteration 0 with loss 0.11644625\n",
      "Training at Epoch 75 iteration 100 with loss 0.13232502\n",
      "Training at Epoch 75 iteration 200 with loss 0.12546925\n",
      "Training at Epoch 75 iteration 300 with loss 0.106613845\n",
      "Validation at Epoch 75 , MSE: 0.20960839772566714 , Pearson Correlation: 0.8370946862794308 with p-value: 0.0 , Concordance Index: 0.843808005243579\n",
      "Training at Epoch 76 iteration 0 with loss 0.10447556\n",
      "Training at Epoch 76 iteration 100 with loss 0.12036861\n",
      "Training at Epoch 76 iteration 200 with loss 0.11504495\n",
      "Training at Epoch 76 iteration 300 with loss 0.13162373\n",
      "Validation at Epoch 76 , MSE: 0.21778085262111235 , Pearson Correlation: 0.8343123227479461 with p-value: 0.0 , Concordance Index: 0.8410064579483277\n",
      "Training at Epoch 77 iteration 0 with loss 0.14490847\n",
      "Training at Epoch 77 iteration 100 with loss 0.11997898\n",
      "Training at Epoch 77 iteration 200 with loss 0.11069321\n",
      "Training at Epoch 77 iteration 300 with loss 0.10076231\n",
      "Validation at Epoch 77 , MSE: 0.24679078395883136 , Pearson Correlation: 0.8372568362035901 with p-value: 0.0 , Concordance Index: 0.8432023489215041\n",
      "Training at Epoch 78 iteration 0 with loss 0.14331052\n",
      "Training at Epoch 78 iteration 100 with loss 0.13227665\n",
      "Training at Epoch 78 iteration 200 with loss 0.12454811\n",
      "Training at Epoch 78 iteration 300 with loss 0.15103939\n",
      "Validation at Epoch 78 , MSE: 0.2265616587951414 , Pearson Correlation: 0.8372453889691356 with p-value: 0.0 , Concordance Index: 0.8437845812766936\n",
      "Training at Epoch 79 iteration 0 with loss 0.12233436\n",
      "Training at Epoch 79 iteration 100 with loss 0.14167055\n",
      "Training at Epoch 79 iteration 200 with loss 0.120403916\n",
      "Training at Epoch 79 iteration 300 with loss 0.116662875\n",
      "Validation at Epoch 79 , MSE: 0.2109382889633728 , Pearson Correlation: 0.836649244072887 with p-value: 0.0 , Concordance Index: 0.84612907371421\n",
      "Training at Epoch 80 iteration 0 with loss 0.09549589\n",
      "Training at Epoch 80 iteration 100 with loss 0.17041656\n",
      "Training at Epoch 80 iteration 200 with loss 0.12877019\n",
      "Training at Epoch 80 iteration 300 with loss 0.13548562\n",
      "Validation at Epoch 80 , MSE: 0.2050719486390203 , Pearson Correlation: 0.8417826664695668 with p-value: 0.0 , Concordance Index: 0.8460668821742235\n",
      "Training at Epoch 81 iteration 0 with loss 0.1223342\n",
      "Training at Epoch 81 iteration 100 with loss 0.10992116\n",
      "Training at Epoch 81 iteration 200 with loss 0.13225318\n",
      "Training at Epoch 81 iteration 300 with loss 0.11876569\n",
      "Validation at Epoch 81 , MSE: 0.20756374761842847 , Pearson Correlation: 0.8418902306005381 with p-value: 0.0 , Concordance Index: 0.8456168635856111\n",
      "Training at Epoch 82 iteration 0 with loss 0.1269224\n",
      "Training at Epoch 82 iteration 100 with loss 0.10582474\n",
      "Training at Epoch 82 iteration 200 with loss 0.14083828\n",
      "Training at Epoch 82 iteration 300 with loss 0.10386555\n",
      "Validation at Epoch 82 , MSE: 0.21576920178158654 , Pearson Correlation: 0.839048557466992 with p-value: 0.0 , Concordance Index: 0.8423680668141116\n",
      "Training at Epoch 83 iteration 0 with loss 0.09389418\n",
      "Training at Epoch 83 iteration 100 with loss 0.122584864\n",
      "Training at Epoch 83 iteration 200 with loss 0.17836848\n",
      "Training at Epoch 83 iteration 300 with loss 0.18190916\n",
      "Validation at Epoch 83 , MSE: 0.20506392556001568 , Pearson Correlation: 0.8422136505756493 with p-value: 0.0 , Concordance Index: 0.8488014411610758\n",
      "Training at Epoch 84 iteration 0 with loss 0.095657565\n",
      "Training at Epoch 84 iteration 100 with loss 0.10645545\n",
      "Training at Epoch 84 iteration 200 with loss 0.11818182\n",
      "Training at Epoch 84 iteration 300 with loss 0.15824214\n",
      "Validation at Epoch 84 , MSE: 0.2208963679012805 , Pearson Correlation: 0.8409192458908802 with p-value: 0.0 , Concordance Index: 0.8461447729168221\n",
      "Training at Epoch 85 iteration 0 with loss 0.11530309\n",
      "Training at Epoch 85 iteration 100 with loss 0.13420783\n",
      "Training at Epoch 85 iteration 200 with loss 0.09676899\n",
      "Training at Epoch 85 iteration 300 with loss 0.11757326\n",
      "Validation at Epoch 85 , MSE: 0.21502884024459906 , Pearson Correlation: 0.8479568352030024 with p-value: 0.0 , Concordance Index: 0.8507483314320022\n",
      "Training at Epoch 86 iteration 0 with loss 0.13170838\n",
      "Training at Epoch 86 iteration 100 with loss 0.0972731\n",
      "Training at Epoch 86 iteration 200 with loss 0.08828224\n",
      "Training at Epoch 86 iteration 300 with loss 0.09376729\n",
      "Validation at Epoch 86 , MSE: 0.2003394467179181 , Pearson Correlation: 0.8461258394202046 with p-value: 0.0 , Concordance Index: 0.8510620279807758\n",
      "Training at Epoch 87 iteration 0 with loss 0.093458824\n",
      "Training at Epoch 87 iteration 100 with loss 0.12387613\n",
      "Training at Epoch 87 iteration 200 with loss 0.16371585\n",
      "Training at Epoch 87 iteration 300 with loss 0.10783923\n",
      "Validation at Epoch 87 , MSE: 0.21174938959606918 , Pearson Correlation: 0.8411225596575465 with p-value: 0.0 , Concordance Index: 0.8473838750410657\n",
      "Training at Epoch 88 iteration 0 with loss 0.094144806\n",
      "Training at Epoch 88 iteration 100 with loss 0.11994183\n",
      "Training at Epoch 88 iteration 200 with loss 0.15185294\n",
      "Training at Epoch 88 iteration 300 with loss 0.12176653\n",
      "Validation at Epoch 88 , MSE: 0.2096370748414472 , Pearson Correlation: 0.8427657260284093 with p-value: 0.0 , Concordance Index: 0.8470377435614014\n",
      "Training at Epoch 89 iteration 0 with loss 0.110885665\n",
      "Training at Epoch 89 iteration 100 with loss 0.15136111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 89 iteration 200 with loss 0.1382595\n",
      "Training at Epoch 89 iteration 300 with loss 0.100334466\n",
      "Validation at Epoch 89 , MSE: 0.24982680308515653 , Pearson Correlation: 0.8415444254790468 with p-value: 0.0 , Concordance Index: 0.8466087051601834\n",
      "Training at Epoch 90 iteration 0 with loss 0.12935536\n",
      "Training at Epoch 90 iteration 100 with loss 0.13117811\n",
      "Training at Epoch 90 iteration 200 with loss 0.13633926\n",
      "Training at Epoch 90 iteration 300 with loss 0.107614815\n",
      "Validation at Epoch 90 , MSE: 0.20709666657666043 , Pearson Correlation: 0.839438031666216 with p-value: 0.0 , Concordance Index: 0.8458997518678608\n",
      "Training at Epoch 91 iteration 0 with loss 0.08989336\n",
      "Training at Epoch 91 iteration 100 with loss 0.092610314\n",
      "Training at Epoch 91 iteration 200 with loss 0.1195761\n",
      "Training at Epoch 91 iteration 300 with loss 0.117124304\n",
      "Validation at Epoch 91 , MSE: 0.2178151032350029 , Pearson Correlation: 0.8413573626807883 with p-value: 0.0 , Concordance Index: 0.8458391491628375\n",
      "Training at Epoch 92 iteration 0 with loss 0.10174954\n",
      "Training at Epoch 92 iteration 100 with loss 0.0938062\n",
      "Training at Epoch 92 iteration 200 with loss 0.1381617\n",
      "Training at Epoch 92 iteration 300 with loss 0.1577214\n",
      "Validation at Epoch 92 , MSE: 0.21632465434587578 , Pearson Correlation: 0.840540011405855 with p-value: 0.0 , Concordance Index: 0.8458509443709689\n",
      "Training at Epoch 93 iteration 0 with loss 0.119310185\n",
      "Training at Epoch 93 iteration 100 with loss 0.093082294\n",
      "Training at Epoch 93 iteration 200 with loss 0.14048956\n",
      "Training at Epoch 93 iteration 300 with loss 0.09506637\n",
      "Validation at Epoch 93 , MSE: 0.20532199035647783 , Pearson Correlation: 0.8426184670404966 with p-value: 0.0 , Concordance Index: 0.8494386699036329\n",
      "Training at Epoch 94 iteration 0 with loss 0.09607465\n",
      "Training at Epoch 94 iteration 100 with loss 0.101585284\n",
      "Training at Epoch 94 iteration 200 with loss 0.09788739\n",
      "Training at Epoch 94 iteration 300 with loss 0.15212816\n",
      "Validation at Epoch 94 , MSE: 0.23084581214174804 , Pearson Correlation: 0.8456729277638648 with p-value: 0.0 , Concordance Index: 0.8505293067493906\n",
      "Training at Epoch 95 iteration 0 with loss 0.123478085\n",
      "Training at Epoch 95 iteration 100 with loss 0.109713115\n",
      "Training at Epoch 95 iteration 200 with loss 0.08955774\n",
      "Training at Epoch 95 iteration 300 with loss 0.1016845\n",
      "Validation at Epoch 95 , MSE: 0.242381106135628 , Pearson Correlation: 0.8422674544517507 with p-value: 0.0 , Concordance Index: 0.8473652327108313\n",
      "Training at Epoch 96 iteration 0 with loss 0.1085472\n",
      "Training at Epoch 96 iteration 100 with loss 0.084436536\n",
      "Training at Epoch 96 iteration 200 with loss 0.09820409\n",
      "Training at Epoch 96 iteration 300 with loss 0.14347759\n",
      "Validation at Epoch 96 , MSE: 0.21377002090083985 , Pearson Correlation: 0.8434245951206467 with p-value: 0.0 , Concordance Index: 0.8483423662131733\n",
      "Training at Epoch 97 iteration 0 with loss 0.09211747\n",
      "Training at Epoch 97 iteration 100 with loss 0.09325831\n",
      "Training at Epoch 97 iteration 200 with loss 0.09118712\n",
      "Training at Epoch 97 iteration 300 with loss 0.11208516\n",
      "Validation at Epoch 97 , MSE: 0.2344447245771719 , Pearson Correlation: 0.841706688990291 with p-value: 0.0 , Concordance Index: 0.8506578661955524\n",
      "Training at Epoch 98 iteration 0 with loss 0.15467478\n",
      "Training at Epoch 98 iteration 100 with loss 0.10955\n",
      "Training at Epoch 98 iteration 200 with loss 0.09365019\n",
      "Training at Epoch 98 iteration 300 with loss 0.08393504\n",
      "Validation at Epoch 98 , MSE: 0.2015596582697691 , Pearson Correlation: 0.845514967327581 with p-value: 0.0 , Concordance Index: 0.8497567849267802\n",
      "Training at Epoch 99 iteration 0 with loss 0.07210918\n",
      "Training at Epoch 99 iteration 100 with loss 0.06685814\n",
      "Training at Epoch 99 iteration 200 with loss 0.11207779\n",
      "Training at Epoch 99 iteration 300 with loss 0.10575169\n",
      "Validation at Epoch 99 , MSE: 0.20617149856638256 , Pearson Correlation: 0.8450146759242111 with p-value: 0.0 , Concordance Index: 0.8525449254812948\n",
      "Training at Epoch 100 iteration 0 with loss 0.09757606\n",
      "Training at Epoch 100 iteration 100 with loss 0.099298045\n",
      "Training at Epoch 100 iteration 200 with loss 0.114270315\n",
      "Training at Epoch 100 iteration 300 with loss 0.1456605\n",
      "Validation at Epoch 100 , MSE: 0.20764456938453305 , Pearson Correlation: 0.8390185214663884 with p-value: 0.0 , Concordance Index: 0.8524345846760439\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.2024908103427836 , Pearson Correlation: 0.8442703583946664 with p-value: 0.0 , Concordance Index: 0.8528283307961947\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n",
      "Let's use 1 GPU/s!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 139.46524\n",
      "Training at Epoch 1 iteration 100 with loss 0.8609999\n",
      "Training at Epoch 1 iteration 200 with loss 0.7148015\n",
      "Training at Epoch 1 iteration 300 with loss 0.73661745\n",
      "Validation at Epoch 1 , MSE: 0.6367081121993841 , Pearson Correlation: 0.4090436750484895 with p-value: 0.0 , Concordance Index: 0.6715894473455478\n",
      "Training at Epoch 2 iteration 0 with loss 0.6340263\n",
      "Training at Epoch 2 iteration 100 with loss 0.66415685\n",
      "Training at Epoch 2 iteration 200 with loss 0.5679356\n",
      "Training at Epoch 2 iteration 300 with loss 0.6172343\n",
      "Validation at Epoch 2 , MSE: 0.5460745795356179 , Pearson Correlation: 0.5336723108294461 with p-value: 0.0 , Concordance Index: 0.7246377944283311\n",
      "Training at Epoch 3 iteration 0 with loss 0.33704826\n",
      "Training at Epoch 3 iteration 100 with loss 0.5240692\n",
      "Training at Epoch 3 iteration 200 with loss 0.8823863\n",
      "Training at Epoch 3 iteration 300 with loss 0.46652448\n",
      "Validation at Epoch 3 , MSE: 0.4698760989716909 , Pearson Correlation: 0.6115798957439783 with p-value: 0.0 , Concordance Index: 0.7501125538253782\n",
      "Training at Epoch 4 iteration 0 with loss 0.44859618\n",
      "Training at Epoch 4 iteration 100 with loss 0.5703726\n",
      "Training at Epoch 4 iteration 200 with loss 0.4281483\n",
      "Training at Epoch 4 iteration 300 with loss 0.372777\n",
      "Validation at Epoch 4 , MSE: 0.4230606565908921 , Pearson Correlation: 0.6413677618135093 with p-value: 0.0 , Concordance Index: 0.7582908245582861\n",
      "Training at Epoch 5 iteration 0 with loss 0.41253194\n",
      "Training at Epoch 5 iteration 100 with loss 0.42813507\n",
      "Training at Epoch 5 iteration 200 with loss 0.32366478\n",
      "Training at Epoch 5 iteration 300 with loss 0.35794038\n",
      "Validation at Epoch 5 , MSE: 0.4073164029561115 , Pearson Correlation: 0.6555872587813809 with p-value: 0.0 , Concordance Index: 0.7669682542754528\n",
      "Training at Epoch 6 iteration 0 with loss 0.3909537\n",
      "Training at Epoch 6 iteration 100 with loss 0.56435865\n",
      "Training at Epoch 6 iteration 200 with loss 0.413429\n",
      "Training at Epoch 6 iteration 300 with loss 0.32955784\n",
      "Validation at Epoch 6 , MSE: 0.40918218087047253 , Pearson Correlation: 0.6676720194622535 with p-value: 0.0 , Concordance Index: 0.7692286368163718\n",
      "Training at Epoch 7 iteration 0 with loss 0.45275587\n",
      "Training at Epoch 7 iteration 100 with loss 0.47273266\n",
      "Training at Epoch 7 iteration 200 with loss 0.40192166\n",
      "Training at Epoch 7 iteration 300 with loss 0.44112036\n",
      "Validation at Epoch 7 , MSE: 0.43704335747466044 , Pearson Correlation: 0.6669560899739739 with p-value: 0.0 , Concordance Index: 0.7711262580716788\n",
      "Training at Epoch 8 iteration 0 with loss 0.50519043\n",
      "Training at Epoch 8 iteration 100 with loss 0.5522798\n",
      "Training at Epoch 8 iteration 200 with loss 0.41786677\n",
      "Training at Epoch 8 iteration 300 with loss 0.4241264\n",
      "Validation at Epoch 8 , MSE: 0.39186159010888444 , Pearson Correlation: 0.6662035445157647 with p-value: 0.0 , Concordance Index: 0.7707486373962209\n",
      "Training at Epoch 9 iteration 0 with loss 0.37689647\n",
      "Training at Epoch 9 iteration 100 with loss 0.34628108\n",
      "Training at Epoch 9 iteration 200 with loss 0.4342202\n",
      "Training at Epoch 9 iteration 300 with loss 0.4134375\n",
      "Validation at Epoch 9 , MSE: 0.5049455437938667 , Pearson Correlation: 0.6713783654654258 with p-value: 0.0 , Concordance Index: 0.7723976589409591\n",
      "Training at Epoch 10 iteration 0 with loss 0.40651405\n",
      "Training at Epoch 10 iteration 100 with loss 0.3330407\n",
      "Training at Epoch 10 iteration 200 with loss 0.34724948\n",
      "Training at Epoch 10 iteration 300 with loss 0.35799336\n",
      "Validation at Epoch 10 , MSE: 0.39105407093491146 , Pearson Correlation: 0.6691036402174889 with p-value: 0.0 , Concordance Index: 0.7706377140181502\n",
      "Training at Epoch 11 iteration 0 with loss 0.3637471\n",
      "Training at Epoch 11 iteration 100 with loss 0.37258703\n",
      "Training at Epoch 11 iteration 200 with loss 0.48296678\n",
      "Training at Epoch 11 iteration 300 with loss 0.38780567\n",
      "Validation at Epoch 11 , MSE: 0.43517179757192503 , Pearson Correlation: 0.6702949675069604 with p-value: 0.0 , Concordance Index: 0.7727338488532826\n",
      "Training at Epoch 12 iteration 0 with loss 0.38928863\n",
      "Training at Epoch 12 iteration 100 with loss 0.24008581\n",
      "Training at Epoch 12 iteration 200 with loss 0.52810955\n",
      "Training at Epoch 12 iteration 300 with loss 0.30270472\n",
      "Validation at Epoch 12 , MSE: 0.39326317979445596 , Pearson Correlation: 0.6733046772250917 with p-value: 0.0 , Concordance Index: 0.7717826738878862\n",
      "Training at Epoch 13 iteration 0 with loss 0.3264246\n",
      "Training at Epoch 13 iteration 100 with loss 0.5484078\n",
      "Training at Epoch 13 iteration 200 with loss 0.36175254\n",
      "Training at Epoch 13 iteration 300 with loss 0.47514102\n",
      "Validation at Epoch 13 , MSE: 0.3789052726525663 , Pearson Correlation: 0.678758766622076 with p-value: 0.0 , Concordance Index: 0.7754047560851585\n",
      "Training at Epoch 14 iteration 0 with loss 0.43687657\n",
      "Training at Epoch 14 iteration 100 with loss 0.35796997\n",
      "Training at Epoch 14 iteration 200 with loss 0.35108304\n",
      "Training at Epoch 14 iteration 300 with loss 0.4346097\n",
      "Validation at Epoch 14 , MSE: 0.4040121164409913 , Pearson Correlation: 0.6979030123480492 with p-value: 0.0 , Concordance Index: 0.7799817961882154\n",
      "Training at Epoch 15 iteration 0 with loss 0.42551678\n",
      "Training at Epoch 15 iteration 100 with loss 0.29720616\n",
      "Training at Epoch 15 iteration 200 with loss 0.2908544\n",
      "Training at Epoch 15 iteration 300 with loss 0.36857286\n",
      "Validation at Epoch 15 , MSE: 0.34177548679934916 , Pearson Correlation: 0.7177234886973931 with p-value: 0.0 , Concordance Index: 0.788364814786709\n",
      "Training at Epoch 16 iteration 0 with loss 0.40225112\n",
      "Training at Epoch 16 iteration 100 with loss 0.24666966\n",
      "Training at Epoch 16 iteration 200 with loss 0.42084098\n",
      "Training at Epoch 16 iteration 300 with loss 0.47641444\n",
      "Validation at Epoch 16 , MSE: 0.3993524948692106 , Pearson Correlation: 0.7216259344754559 with p-value: 0.0 , Concordance Index: 0.7890709308737401\n",
      "Training at Epoch 17 iteration 0 with loss 0.41809434\n",
      "Training at Epoch 17 iteration 100 with loss 0.3885846\n",
      "Training at Epoch 17 iteration 200 with loss 0.45149812\n",
      "Training at Epoch 17 iteration 300 with loss 0.2702254\n",
      "Validation at Epoch 17 , MSE: 0.42504219888360756 , Pearson Correlation: 0.7248785665440971 with p-value: 0.0 , Concordance Index: 0.7857942840951008\n",
      "Training at Epoch 18 iteration 0 with loss 0.36823934\n",
      "Training at Epoch 18 iteration 100 with loss 0.34829542\n",
      "Training at Epoch 18 iteration 200 with loss 0.34145638\n",
      "Training at Epoch 18 iteration 300 with loss 0.30091575\n",
      "Validation at Epoch 18 , MSE: 0.4079644685818902 , Pearson Correlation: 0.7306104062049658 with p-value: 0.0 , Concordance Index: 0.7848311701698384\n",
      "Training at Epoch 19 iteration 0 with loss 0.35571986\n",
      "Training at Epoch 19 iteration 100 with loss 0.324948\n",
      "Training at Epoch 19 iteration 200 with loss 0.42894053\n",
      "Training at Epoch 19 iteration 300 with loss 0.32786384\n",
      "Validation at Epoch 19 , MSE: 0.342041879690475 , Pearson Correlation: 0.7356589576792782 with p-value: 0.0 , Concordance Index: 0.7915523203580345\n",
      "Training at Epoch 20 iteration 0 with loss 0.2991493\n",
      "Training at Epoch 20 iteration 100 with loss 0.33320338\n",
      "Training at Epoch 20 iteration 200 with loss 0.37212577\n",
      "Training at Epoch 20 iteration 300 with loss 0.28414556\n",
      "Validation at Epoch 20 , MSE: 0.3424404569229512 , Pearson Correlation: 0.7461455674638 with p-value: 0.0 , Concordance Index: 0.800036585573085\n",
      "Training at Epoch 21 iteration 0 with loss 0.25529727\n",
      "Training at Epoch 21 iteration 100 with loss 0.31749058\n",
      "Training at Epoch 21 iteration 200 with loss 0.19804749\n",
      "Training at Epoch 21 iteration 300 with loss 0.28026444\n",
      "Validation at Epoch 21 , MSE: 0.314047033820825 , Pearson Correlation: 0.7493696219014221 with p-value: 0.0 , Concordance Index: 0.8020002191381709\n",
      "Training at Epoch 22 iteration 0 with loss 0.28804988\n",
      "Training at Epoch 22 iteration 100 with loss 0.33376902\n",
      "Training at Epoch 22 iteration 200 with loss 0.4587853\n",
      "Training at Epoch 22 iteration 300 with loss 0.26941398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation at Epoch 22 , MSE: 0.32315906195633937 , Pearson Correlation: 0.7511600503342932 with p-value: 0.0 , Concordance Index: 0.7980720289705443\n",
      "Training at Epoch 23 iteration 0 with loss 0.23712516\n",
      "Training at Epoch 23 iteration 100 with loss 0.22566727\n",
      "Training at Epoch 23 iteration 200 with loss 0.3584891\n",
      "Training at Epoch 23 iteration 300 with loss 0.2844079\n",
      "Validation at Epoch 23 , MSE: 0.32189146012316056 , Pearson Correlation: 0.7541484091414316 with p-value: 0.0 , Concordance Index: 0.8037732908641279\n",
      "Training at Epoch 24 iteration 0 with loss 0.3232067\n",
      "Training at Epoch 24 iteration 100 with loss 0.31845796\n",
      "Training at Epoch 24 iteration 200 with loss 0.3031874\n",
      "Training at Epoch 24 iteration 300 with loss 0.211002\n",
      "Validation at Epoch 24 , MSE: 0.3232353221314734 , Pearson Correlation: 0.7543632750807707 with p-value: 0.0 , Concordance Index: 0.8043292696130214\n",
      "Training at Epoch 25 iteration 0 with loss 0.17400283\n",
      "Training at Epoch 25 iteration 100 with loss 0.33140767\n",
      "Training at Epoch 25 iteration 200 with loss 0.28265643\n"
     ]
    }
   ],
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "\n",
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
