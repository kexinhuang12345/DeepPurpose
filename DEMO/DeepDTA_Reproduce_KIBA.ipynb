{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:08:47] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Done!\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_drug, X_target, y = load_process_KIBA('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 256,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU/s!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 139.46227\n",
      "Training at Epoch 1 iteration 100 with loss 0.8524759\n",
      "Training at Epoch 1 iteration 200 with loss 0.7659789\n",
      "Training at Epoch 1 iteration 300 with loss 0.77633584\n",
      "Validation at Epoch 1 , MSE: 0.6252079559108886 , Pearson Correlation: 0.37120514588057757 with p-value: 0.0 , Concordance Index: 0.6476415418668936\n",
      "Training at Epoch 2 iteration 0 with loss 0.6057545\n",
      "Training at Epoch 2 iteration 100 with loss 0.7182188\n",
      "Training at Epoch 2 iteration 200 with loss 0.5523121\n",
      "Training at Epoch 2 iteration 300 with loss 0.7289833\n",
      "Validation at Epoch 2 , MSE: 0.5057249716094536 , Pearson Correlation: 0.5271302441704545 with p-value: 0.0 , Concordance Index: 0.7108944244194332\n",
      "Training at Epoch 3 iteration 0 with loss 0.3336088\n",
      "Training at Epoch 3 iteration 100 with loss 0.55122924\n",
      "Training at Epoch 3 iteration 200 with loss 0.9139983\n",
      "Training at Epoch 3 iteration 300 with loss 0.3553281\n",
      "Validation at Epoch 3 , MSE: 0.43898317224256905 , Pearson Correlation: 0.6078014781089629 with p-value: 0.0 , Concordance Index: 0.7420012120873392\n",
      "Training at Epoch 4 iteration 0 with loss 0.6549053\n",
      "Training at Epoch 4 iteration 100 with loss 0.28032207\n",
      "Training at Epoch 4 iteration 200 with loss 0.5554817\n",
      "Training at Epoch 4 iteration 300 with loss 0.4001999\n",
      "Validation at Epoch 4 , MSE: 0.517115460522088 , Pearson Correlation: 0.6388425484955205 with p-value: 0.0 , Concordance Index: 0.7548923258982349\n",
      "Training at Epoch 5 iteration 0 with loss 0.3249922\n",
      "Training at Epoch 5 iteration 100 with loss 0.49228954\n",
      "Training at Epoch 5 iteration 200 with loss 0.53248477\n",
      "Training at Epoch 5 iteration 300 with loss 0.35868204\n",
      "Validation at Epoch 5 , MSE: 0.43980806543009365 , Pearson Correlation: 0.6566629620181142 with p-value: 0.0 , Concordance Index: 0.7574936859223567\n",
      "Training at Epoch 6 iteration 0 with loss 0.33518466\n",
      "Training at Epoch 6 iteration 100 with loss 0.4694142\n",
      "Training at Epoch 6 iteration 200 with loss 0.43182057\n",
      "Training at Epoch 6 iteration 300 with loss 0.27362764\n",
      "Validation at Epoch 6 , MSE: 0.40906901873856194 , Pearson Correlation: 0.6642595221495057 with p-value: 0.0 , Concordance Index: 0.7633581128907642\n",
      "Training at Epoch 7 iteration 0 with loss 0.4240064\n",
      "Training at Epoch 7 iteration 100 with loss 0.579832\n",
      "Training at Epoch 7 iteration 200 with loss 0.29981527\n",
      "Training at Epoch 7 iteration 300 with loss 0.37393552\n",
      "Validation at Epoch 7 , MSE: 0.4669870538496263 , Pearson Correlation: 0.6709961444282361 with p-value: 0.0 , Concordance Index: 0.7629225786099979\n",
      "Training at Epoch 8 iteration 0 with loss 0.49253836\n",
      "Training at Epoch 8 iteration 100 with loss 0.43154156\n",
      "Training at Epoch 8 iteration 200 with loss 0.8942315\n",
      "Training at Epoch 8 iteration 300 with loss 0.36026978\n",
      "Validation at Epoch 8 , MSE: 0.40576572643883924 , Pearson Correlation: 0.6698314683974463 with p-value: 0.0 , Concordance Index: 0.7633775503707003\n",
      "Training at Epoch 9 iteration 0 with loss 0.54117924\n",
      "Training at Epoch 9 iteration 100 with loss 0.4534474\n",
      "Training at Epoch 9 iteration 200 with loss 0.2908664\n",
      "Training at Epoch 9 iteration 300 with loss 0.40684277\n",
      "Validation at Epoch 9 , MSE: 0.3866416384830573 , Pearson Correlation: 0.6740064110006907 with p-value: 0.0 , Concordance Index: 0.7670906313072465\n",
      "Training at Epoch 10 iteration 0 with loss 0.5149473\n",
      "Training at Epoch 10 iteration 100 with loss 0.3061192\n",
      "Training at Epoch 10 iteration 200 with loss 0.39455894\n",
      "Training at Epoch 10 iteration 300 with loss 0.41524413\n",
      "Validation at Epoch 10 , MSE: 0.5004661130110899 , Pearson Correlation: 0.6746381122340862 with p-value: 0.0 , Concordance Index: 0.7636888073994913\n",
      "Training at Epoch 11 iteration 0 with loss 0.50837636\n",
      "Training at Epoch 11 iteration 100 with loss 0.34029388\n",
      "Training at Epoch 11 iteration 200 with loss 0.4000504\n",
      "Training at Epoch 11 iteration 300 with loss 0.43241504\n",
      "Validation at Epoch 11 , MSE: 0.687117328399177 , Pearson Correlation: 0.6775114338921054 with p-value: 0.0 , Concordance Index: 0.768135395853816\n",
      "Training at Epoch 12 iteration 0 with loss 0.61384964\n",
      "Training at Epoch 12 iteration 100 with loss 0.4489369\n",
      "Training at Epoch 12 iteration 200 with loss 0.41723198\n",
      "Training at Epoch 12 iteration 300 with loss 0.52659756\n",
      "Validation at Epoch 12 , MSE: 0.44284007519234136 , Pearson Correlation: 0.6815251759494406 with p-value: 0.0 , Concordance Index: 0.7671332681158448\n",
      "Training at Epoch 13 iteration 0 with loss 0.4339065\n",
      "Training at Epoch 13 iteration 100 with loss 0.43391797\n",
      "Training at Epoch 13 iteration 200 with loss 0.44804138\n",
      "Training at Epoch 13 iteration 300 with loss 0.29588428\n",
      "Validation at Epoch 13 , MSE: 0.3794264554744155 , Pearson Correlation: 0.6824709263168197 with p-value: 0.0 , Concordance Index: 0.7648438539097174\n",
      "Training at Epoch 14 iteration 0 with loss 0.35877725\n",
      "Training at Epoch 14 iteration 100 with loss 0.40320885\n",
      "Training at Epoch 14 iteration 200 with loss 0.6108784\n",
      "Training at Epoch 14 iteration 300 with loss 0.4231795\n",
      "Validation at Epoch 14 , MSE: 0.37035736481551695 , Pearson Correlation: 0.6886761842378898 with p-value: 0.0 , Concordance Index: 0.769635147299312\n",
      "Training at Epoch 15 iteration 0 with loss 0.28133658\n",
      "Training at Epoch 15 iteration 100 with loss 0.2723529\n",
      "Training at Epoch 15 iteration 200 with loss 0.37842792\n",
      "Training at Epoch 15 iteration 300 with loss 0.42256156\n",
      "Validation at Epoch 15 , MSE: 0.39174580991934793 , Pearson Correlation: 0.6980164319885487 with p-value: 0.0 , Concordance Index: 0.7729698407516334\n",
      "Training at Epoch 16 iteration 0 with loss 0.442822\n",
      "Training at Epoch 16 iteration 100 with loss 0.29855317\n",
      "Training at Epoch 16 iteration 200 with loss 0.44767448\n",
      "Training at Epoch 16 iteration 300 with loss 0.3829686\n",
      "Validation at Epoch 16 , MSE: 0.3587687227351904 , Pearson Correlation: 0.7275656094433479 with p-value: 0.0 , Concordance Index: 0.7817976053933012\n",
      "Training at Epoch 17 iteration 0 with loss 0.39717722\n",
      "Training at Epoch 17 iteration 100 with loss 0.34678438\n",
      "Training at Epoch 17 iteration 200 with loss 0.30226183\n",
      "Training at Epoch 17 iteration 300 with loss 0.42329437\n",
      "Validation at Epoch 17 , MSE: 0.4687368140248108 , Pearson Correlation: 0.7304166804308427 with p-value: 0.0 , Concordance Index: 0.7828565923015529\n",
      "Training at Epoch 18 iteration 0 with loss 0.3633739\n",
      "Training at Epoch 18 iteration 100 with loss 0.28657123\n",
      "Training at Epoch 18 iteration 200 with loss 0.32053304\n",
      "Training at Epoch 18 iteration 300 with loss 0.32039723\n",
      "Validation at Epoch 18 , MSE: 0.3276044065524828 , Pearson Correlation: 0.7382404349298669 with p-value: 0.0 , Concordance Index: 0.7846119602326115\n",
      "Training at Epoch 19 iteration 0 with loss 0.17331107\n",
      "Training at Epoch 19 iteration 100 with loss 0.43098885\n",
      "Training at Epoch 19 iteration 200 with loss 0.34547406\n",
      "Training at Epoch 19 iteration 300 with loss 0.29107505\n",
      "Validation at Epoch 19 , MSE: 0.3122119465124941 , Pearson Correlation: 0.7406594366731748 with p-value: 0.0 , Concordance Index: 0.7859064449263984\n",
      "Training at Epoch 20 iteration 0 with loss 0.3300522\n",
      "Training at Epoch 20 iteration 100 with loss 0.23845857\n",
      "Training at Epoch 20 iteration 200 with loss 0.3112779\n",
      "Training at Epoch 20 iteration 300 with loss 0.2908824\n",
      "Validation at Epoch 20 , MSE: 0.332362568609342 , Pearson Correlation: 0.7433144190944236 with p-value: 0.0 , Concordance Index: 0.779341019776788\n",
      "Training at Epoch 21 iteration 0 with loss 0.21694058\n",
      "Training at Epoch 21 iteration 100 with loss 0.31264272\n",
      "Training at Epoch 21 iteration 200 with loss 0.291134\n",
      "Training at Epoch 21 iteration 300 with loss 0.2443328\n",
      "Validation at Epoch 21 , MSE: 0.32488440260458695 , Pearson Correlation: 0.7549241003756116 with p-value: 0.0 , Concordance Index: 0.7905469464642452\n",
      "Training at Epoch 22 iteration 0 with loss 0.296259\n",
      "Training at Epoch 22 iteration 100 with loss 0.32945767\n",
      "Training at Epoch 22 iteration 200 with loss 0.28351027\n",
      "Training at Epoch 22 iteration 300 with loss 0.27165496\n",
      "Validation at Epoch 22 , MSE: 0.3556623065139081 , Pearson Correlation: 0.7558565473223899 with p-value: 0.0 , Concordance Index: 0.7933693699770804\n",
      "Training at Epoch 23 iteration 0 with loss 0.3517964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 23 iteration 100 with loss 0.21723273\n",
      "Training at Epoch 23 iteration 200 with loss 0.3215351\n",
      "Training at Epoch 23 iteration 300 with loss 0.37353116\n",
      "Validation at Epoch 23 , MSE: 0.2904944052104942 , Pearson Correlation: 0.7605299689697724 with p-value: 0.0 , Concordance Index: 0.7966217114894854\n",
      "Training at Epoch 24 iteration 0 with loss 0.2798943\n",
      "Training at Epoch 24 iteration 100 with loss 0.39643136\n",
      "Training at Epoch 24 iteration 200 with loss 0.4295775\n",
      "Training at Epoch 24 iteration 300 with loss 0.24249879\n",
      "Validation at Epoch 24 , MSE: 0.3018565196551627 , Pearson Correlation: 0.7695774972212105 with p-value: 0.0 , Concordance Index: 0.7993369790819714\n",
      "Training at Epoch 25 iteration 0 with loss 0.22099498\n",
      "Training at Epoch 25 iteration 100 with loss 0.26581356\n",
      "Training at Epoch 25 iteration 200 with loss 0.31408113\n",
      "Training at Epoch 25 iteration 300 with loss 0.31087956\n",
      "Validation at Epoch 25 , MSE: 0.28863161072602156 , Pearson Correlation: 0.762775379909726 with p-value: 0.0 , Concordance Index: 0.8012207040164403\n",
      "Training at Epoch 26 iteration 0 with loss 0.2655613\n",
      "Training at Epoch 26 iteration 100 with loss 0.25201494\n"
     ]
    }
   ],
   "source": [
    "model = models.model_initialize(**config)\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_DeepDTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
