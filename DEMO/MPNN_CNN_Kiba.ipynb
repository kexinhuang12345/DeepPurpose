{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [00:02:30] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Done!\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n",
      "cost about 48 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t1 = time()\n",
    "X_drug, X_target, y = load_process_KIBA('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'MPNN'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         test_every_X_epoch = 10, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 128,\n",
    "                         hidden_dim_drug = 128,\n",
    "                         mpnn_hidden_size = 128,\n",
    "                         mpnn_depth = 3, \n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n",
    "t2 = time()\n",
    "print(\"cost about \" + str(int(t2-t1)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU/s!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 139.43924. Total time 0.0033333333333333335 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.85528827. Total time 0.31472222222222224 hours\n",
      "Training at Epoch 1 iteration 200 with loss 0.40343657. Total time 0.5869444444444445 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.84512866. Total time 0.8316666666666667 hours\n",
      "Training at Epoch 1 iteration 400 with loss 0.662899. Total time 1.1133333333333333 hours\n",
      "Training at Epoch 1 iteration 500 with loss 0.8523878. Total time 1.3780555555555556 hours\n",
      "Training at Epoch 1 iteration 600 with loss 0.81808466. Total time 1.5905555555555555 hours\n",
      "Validation at Epoch 1 , MSE: 0.7203050738666983 , Pearson Correlation: 0.43944927099263914 with p-value: 0.0 , Concordance Index: 0.6855492954255099\n",
      "Training at Epoch 2 iteration 0 with loss 1.0755687. Total time 1.7641666666666667 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.9385077. Total time 1.9722222222222223 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.50950605. Total time 2.1744444444444446 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.653787. Total time 2.375 hours\n",
      "Training at Epoch 2 iteration 400 with loss 0.53988457. Total time 2.5769444444444445 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.88967. Total time 2.7894444444444444 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.75896376. Total time 2.9897222222222224 hours\n",
      "Validation at Epoch 2 , MSE: 0.6282908156777344 , Pearson Correlation: 0.5119921128416285 with p-value: 0.0 , Concordance Index: 0.7084808842338484\n",
      "Training at Epoch 3 iteration 0 with loss 0.9119583. Total time 3.158611111111111 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.87829775. Total time 3.3555555555555556 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.662268. Total time 3.5580555555555557 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.5763321. Total time 3.763888888888889 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.97758454. Total time 3.962222222222222 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.8677438. Total time 4.161388888888889 hours\n",
      "Training at Epoch 3 iteration 600 with loss 1.2172973. Total time 4.361666666666666 hours\n",
      "Validation at Epoch 3 , MSE: 0.5056636588625827 , Pearson Correlation: 0.5363573220833262 with p-value: 0.0 , Concordance Index: 0.7165463485894722\n",
      "Training at Epoch 4 iteration 0 with loss 0.6207135. Total time 4.5313888888888885 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.52476555. Total time 4.744166666666667 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.67531085. Total time 4.943333333333333 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.5518958. Total time 5.14 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.684854. Total time 5.34 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.44150734. Total time 5.541388888888889 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.47156352. Total time 5.745833333333334 hours\n",
      "Validation at Epoch 4 , MSE: 0.5685114318197219 , Pearson Correlation: 0.5679749673620769 with p-value: 0.0 , Concordance Index: 0.7231542591481104\n",
      "Training at Epoch 5 iteration 0 with loss 0.8866825. Total time 5.916944444444445 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.6268705. Total time 6.118611111111111 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.5030127. Total time 6.315 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.8109578. Total time 6.5119444444444445 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.67774314. Total time 6.733333333333333 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.8688271. Total time 6.929722222222222 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.49849248. Total time 7.126111111111111 hours\n",
      "Validation at Epoch 5 , MSE: 0.48221697213259984 , Pearson Correlation: 0.5789969106627126 with p-value: 0.0 , Concordance Index: 0.7268057499819236\n",
      "Training at Epoch 6 iteration 0 with loss 0.6151125. Total time 7.293333333333333 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.8194757. Total time 7.487777777777778 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.6671729. Total time 7.6947222222222225 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.6358709. Total time 7.895555555555555 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.59426993. Total time 8.094444444444445 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.6593819. Total time 8.293611111111112 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.5536511. Total time 8.494444444444444 hours\n",
      "Validation at Epoch 6 , MSE: 0.4549318653259487 , Pearson Correlation: 0.5995402946588382 with p-value: 0.0 , Concordance Index: 0.7342030987689182\n",
      "Training at Epoch 7 iteration 0 with loss 0.45920575. Total time 8.674444444444445 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.29518282. Total time 8.877222222222223 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.65242475. Total time 9.073055555555555 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.7034983. Total time 9.274722222222222 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.6272925. Total time 9.474444444444444 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.5037556. Total time 9.681944444444444 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.36792699. Total time 9.886944444444444 hours\n",
      "Validation at Epoch 7 , MSE: 0.4679173334323973 , Pearson Correlation: 0.615660113196679 with p-value: 0.0 , Concordance Index: 0.7444807811391342\n",
      "Training at Epoch 8 iteration 0 with loss 0.36232987. Total time 10.057777777777778 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.5194818. Total time 10.263333333333334 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.75429994. Total time 10.471388888888889 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.4488921. Total time 10.686666666666667 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.49060357. Total time 10.893333333333333 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.59408844. Total time 11.091666666666667 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.4925796. Total time 11.297222222222222 hours\n",
      "Validation at Epoch 8 , MSE: 0.42919969140712577 , Pearson Correlation: 0.633669523367207 with p-value: 0.0 , Concordance Index: 0.7453815340820761\n",
      "Training at Epoch 9 iteration 0 with loss 0.49596468. Total time 11.4675 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.8084144. Total time 11.7225 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.5014702. Total time 12.017777777777777 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.6114176. Total time 12.351666666666667 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.58063036. Total time 12.643888888888888 hours\n"
     ]
    }
   ],
   "source": [
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_MPNN_CNN_Kiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
