{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [00:50:26] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "\n",
    "import DeepPurpose.models as models\n",
    "from DeepPurpose.utils import *\n",
    "from DeepPurpose.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Beginning to extract zip file...\n",
      "Default set to logspace (nM -> p) for easier regression\n",
      "Done!\n",
      "in total: 30056 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 68\n",
      "drug encoding finished...\n",
      "encoding protein...\n",
      "unique target sequence: 379\n",
      "protein encoding finished...\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X_drug, X_target, y = load_process_DAVIS('./data/', binary=False)\n",
    "\n",
    "drug_encoding = 'MPNN'\n",
    "target_encoding = 'CNN'\n",
    "train, val, test = data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])\n",
    "\n",
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 30, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 16,\n",
    "                         hidden_dim_drug = 128,\n",
    "                         mpnn_hidden_size = 128,\n",
    "                         mpnn_depth = 3, \n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n",
    "model = models.model_initialize(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 0.18162273\n",
      "Training at Epoch 1 iteration 100 with loss 0.03262544\n",
      "Training at Epoch 1 iteration 200 with loss 0.28088984\n",
      "Training at Epoch 1 iteration 300 with loss 0.18376702\n",
      "Training at Epoch 1 iteration 400 with loss 0.4720042\n",
      "Training at Epoch 1 iteration 500 with loss 0.12979831\n",
      "Training at Epoch 1 iteration 600 with loss 0.19930425\n",
      "Training at Epoch 1 iteration 700 with loss 0.1931547\n",
      "Training at Epoch 1 iteration 800 with loss 0.29235488\n",
      "Training at Epoch 1 iteration 900 with loss 0.19123395\n",
      "Training at Epoch 1 iteration 1000 with loss 0.15141267\n",
      "Training at Epoch 1 iteration 1100 with loss 0.18739717\n",
      "Training at Epoch 1 iteration 1200 with loss 0.061301395\n",
      "Training at Epoch 1 iteration 1300 with loss 0.25031063\n",
      "Validation at Epoch 1 , MSE: 0.3274485154008011 , Pearson Correlation: 0.7518610210370498 with p-value: 0.0 , Concordance Index: 0.8431469564086888\n",
      "Training at Epoch 2 iteration 0 with loss 0.30559564\n",
      "Training at Epoch 2 iteration 100 with loss 0.13342743\n",
      "Training at Epoch 2 iteration 200 with loss 0.20626137\n",
      "Training at Epoch 2 iteration 300 with loss 0.2846519\n",
      "Training at Epoch 2 iteration 400 with loss 0.40040943\n",
      "Training at Epoch 2 iteration 500 with loss 0.10270547\n",
      "Training at Epoch 2 iteration 600 with loss 0.20929007\n",
      "Training at Epoch 2 iteration 700 with loss 0.62022823\n",
      "Training at Epoch 2 iteration 800 with loss 0.15289566\n",
      "Training at Epoch 2 iteration 900 with loss 0.20481464\n",
      "Training at Epoch 2 iteration 1000 with loss 0.019367304\n",
      "Training at Epoch 2 iteration 1100 with loss 0.09213311\n",
      "Training at Epoch 2 iteration 1200 with loss 0.3284087\n",
      "Training at Epoch 2 iteration 1300 with loss 0.054926414\n",
      "Validation at Epoch 2 , MSE: 0.3763668880952773 , Pearson Correlation: 0.7323640756604823 with p-value: 0.0 , Concordance Index: 0.851138711445618\n",
      "Training at Epoch 3 iteration 0 with loss 0.46215612\n",
      "Training at Epoch 3 iteration 100 with loss 0.17719403\n",
      "Training at Epoch 3 iteration 200 with loss 0.57122684\n",
      "Training at Epoch 3 iteration 300 with loss 0.13013001\n",
      "Training at Epoch 3 iteration 400 with loss 0.2667763\n",
      "Training at Epoch 3 iteration 500 with loss 0.85566175\n",
      "Training at Epoch 3 iteration 600 with loss 0.4531058\n",
      "Training at Epoch 3 iteration 700 with loss 0.045001127\n",
      "Training at Epoch 3 iteration 800 with loss 0.18548368\n",
      "Training at Epoch 3 iteration 900 with loss 0.12670079\n",
      "Training at Epoch 3 iteration 1000 with loss 0.20074166\n",
      "Training at Epoch 3 iteration 1100 with loss 0.3632115\n",
      "Training at Epoch 3 iteration 1200 with loss 0.14744027\n",
      "Training at Epoch 3 iteration 1300 with loss 0.23306528\n",
      "Validation at Epoch 3 , MSE: 0.33259842618247937 , Pearson Correlation: 0.7493617219593001 with p-value: 0.0 , Concordance Index: 0.8466547551282863\n",
      "Training at Epoch 4 iteration 0 with loss 0.40024525\n",
      "Training at Epoch 4 iteration 100 with loss 0.33047172\n",
      "Training at Epoch 4 iteration 200 with loss 0.21985932\n",
      "Training at Epoch 4 iteration 300 with loss 0.5519475\n",
      "Training at Epoch 4 iteration 400 with loss 0.3210627\n",
      "Training at Epoch 4 iteration 500 with loss 0.062053323\n",
      "Training at Epoch 4 iteration 600 with loss 0.20374288\n",
      "Training at Epoch 4 iteration 700 with loss 0.2854244\n",
      "Training at Epoch 4 iteration 800 with loss 0.3766162\n",
      "Training at Epoch 4 iteration 900 with loss 0.43381304\n",
      "Training at Epoch 4 iteration 1000 with loss 0.42547524\n",
      "Training at Epoch 4 iteration 1100 with loss 0.2832109\n",
      "Training at Epoch 4 iteration 1200 with loss 0.108662926\n",
      "Training at Epoch 4 iteration 1300 with loss 0.20001829\n",
      "Validation at Epoch 4 , MSE: 0.31813157847868967 , Pearson Correlation: 0.7620336555134184 with p-value: 0.0 , Concordance Index: 0.8456092013998693\n",
      "Training at Epoch 5 iteration 0 with loss 0.06651865\n",
      "Training at Epoch 5 iteration 100 with loss 0.09658027\n",
      "Training at Epoch 5 iteration 200 with loss 0.40947038\n",
      "Training at Epoch 5 iteration 300 with loss 0.2548736\n",
      "Training at Epoch 5 iteration 400 with loss 0.08416821\n",
      "Training at Epoch 5 iteration 500 with loss 0.15686975\n",
      "Training at Epoch 5 iteration 600 with loss 0.14902888\n",
      "Training at Epoch 5 iteration 700 with loss 1.2096919\n",
      "Training at Epoch 5 iteration 800 with loss 0.34292316\n",
      "Training at Epoch 5 iteration 900 with loss 0.4005794\n",
      "Training at Epoch 5 iteration 1000 with loss 0.62107086\n",
      "Training at Epoch 5 iteration 1100 with loss 0.58576304\n",
      "Training at Epoch 5 iteration 1200 with loss 0.49827853\n",
      "Training at Epoch 5 iteration 1300 with loss 0.2540508\n",
      "Validation at Epoch 5 , MSE: 0.3353600245349447 , Pearson Correlation: 0.7591693693651493 with p-value: 0.0 , Concordance Index: 0.8548184632358625\n",
      "Training at Epoch 6 iteration 0 with loss 0.16267966\n",
      "Training at Epoch 6 iteration 100 with loss 0.4914792\n",
      "Training at Epoch 6 iteration 200 with loss 0.5825545\n",
      "Training at Epoch 6 iteration 300 with loss 0.33102965\n",
      "Training at Epoch 6 iteration 400 with loss 0.029028537\n",
      "Training at Epoch 6 iteration 500 with loss 0.19289589\n",
      "Training at Epoch 6 iteration 600 with loss 0.34967783\n",
      "Training at Epoch 6 iteration 700 with loss 0.192421\n",
      "Training at Epoch 6 iteration 800 with loss 0.6279389\n",
      "Training at Epoch 6 iteration 900 with loss 0.1615931\n",
      "Training at Epoch 6 iteration 1000 with loss 0.1462441\n",
      "Training at Epoch 6 iteration 1100 with loss 0.15129492\n",
      "Training at Epoch 6 iteration 1200 with loss 0.7760381\n",
      "Training at Epoch 6 iteration 1300 with loss 0.1399984\n",
      "Validation at Epoch 6 , MSE: 0.3165761402602868 , Pearson Correlation: 0.7645119289444384 with p-value: 0.0 , Concordance Index: 0.8566475783385687\n",
      "Training at Epoch 7 iteration 0 with loss 0.19604897\n",
      "Training at Epoch 7 iteration 100 with loss 0.40566346\n",
      "Training at Epoch 7 iteration 200 with loss 0.0956471\n",
      "Training at Epoch 7 iteration 300 with loss 0.12282493\n",
      "Training at Epoch 7 iteration 400 with loss 0.45336005\n",
      "Training at Epoch 7 iteration 500 with loss 0.3144833\n",
      "Training at Epoch 7 iteration 600 with loss 0.06578341\n",
      "Training at Epoch 7 iteration 700 with loss 0.070600025\n",
      "Training at Epoch 7 iteration 800 with loss 0.3319767\n",
      "Training at Epoch 7 iteration 900 with loss 0.61680585\n",
      "Training at Epoch 7 iteration 1000 with loss 0.14856167\n",
      "Training at Epoch 7 iteration 1100 with loss 0.17637846\n",
      "Training at Epoch 7 iteration 1200 with loss 0.23047583\n",
      "Training at Epoch 7 iteration 1300 with loss 0.3393266\n",
      "Validation at Epoch 7 , MSE: 0.33119904957371926 , Pearson Correlation: 0.749233310359413 with p-value: 0.0 , Concordance Index: 0.8499589772240143\n",
      "Training at Epoch 8 iteration 0 with loss 0.061976347\n",
      "Training at Epoch 8 iteration 100 with loss 0.08365682\n",
      "Training at Epoch 8 iteration 200 with loss 0.10785526\n",
      "Training at Epoch 8 iteration 300 with loss 0.24234384\n",
      "Training at Epoch 8 iteration 400 with loss 0.4201635\n",
      "Training at Epoch 8 iteration 500 with loss 0.17282888\n",
      "Training at Epoch 8 iteration 600 with loss 0.16268201\n",
      "Training at Epoch 8 iteration 700 with loss 0.040412225\n",
      "Training at Epoch 8 iteration 800 with loss 0.42757437\n",
      "Training at Epoch 8 iteration 900 with loss 0.25767577\n",
      "Training at Epoch 8 iteration 1000 with loss 0.18704936\n",
      "Training at Epoch 8 iteration 1100 with loss 0.09268179\n",
      "Training at Epoch 8 iteration 1200 with loss 0.48375598\n",
      "Training at Epoch 8 iteration 1300 with loss 0.5940986\n",
      "Validation at Epoch 8 , MSE: 0.3098825370314792 , Pearson Correlation: 0.7687297287863357 with p-value: 0.0 , Concordance Index: 0.8575730064863422\n",
      "Training at Epoch 9 iteration 0 with loss 0.16432859\n",
      "Training at Epoch 9 iteration 100 with loss 0.21114843\n",
      "Training at Epoch 9 iteration 200 with loss 0.5573207\n",
      "Training at Epoch 9 iteration 300 with loss 0.26757357\n",
      "Training at Epoch 9 iteration 400 with loss 0.45591462\n",
      "Training at Epoch 9 iteration 500 with loss 0.35852677\n",
      "Training at Epoch 9 iteration 600 with loss 0.32230896\n",
      "Training at Epoch 9 iteration 700 with loss 0.08210944\n",
      "Training at Epoch 9 iteration 800 with loss 0.1948721\n",
      "Training at Epoch 9 iteration 900 with loss 0.03902567\n",
      "Training at Epoch 9 iteration 1000 with loss 0.32344815\n",
      "Training at Epoch 9 iteration 1100 with loss 0.13328257\n",
      "Training at Epoch 9 iteration 1200 with loss 0.18809475\n",
      "Training at Epoch 9 iteration 1300 with loss 0.29415432\n",
      "Validation at Epoch 9 , MSE: 0.3118511258996743 , Pearson Correlation: 0.767767260724313 with p-value: 0.0 , Concordance Index: 0.8571781512870786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 10 iteration 0 with loss 0.09310202\n",
      "Training at Epoch 10 iteration 100 with loss 0.18881153\n",
      "Training at Epoch 10 iteration 200 with loss 0.096591875\n",
      "Training at Epoch 10 iteration 300 with loss 0.50756043\n",
      "Training at Epoch 10 iteration 400 with loss 0.07353314\n",
      "Training at Epoch 10 iteration 500 with loss 0.6968722\n",
      "Training at Epoch 10 iteration 600 with loss 0.6715472\n",
      "Training at Epoch 10 iteration 700 with loss 0.3452581\n",
      "Training at Epoch 10 iteration 800 with loss 0.5682747\n",
      "Training at Epoch 10 iteration 900 with loss 0.37323463\n",
      "Training at Epoch 10 iteration 1000 with loss 0.11767764\n",
      "Training at Epoch 10 iteration 1100 with loss 0.19793227\n",
      "Training at Epoch 10 iteration 1200 with loss 0.2784537\n",
      "Training at Epoch 10 iteration 1300 with loss 0.6282196\n",
      "Validation at Epoch 10 , MSE: 0.29907184180309143 , Pearson Correlation: 0.7785231135766093 with p-value: 0.0 , Concordance Index: 0.8573692102544642\n",
      "Training at Epoch 11 iteration 0 with loss 0.04040824\n",
      "Training at Epoch 11 iteration 100 with loss 0.32186633\n",
      "Training at Epoch 11 iteration 200 with loss 0.19142438\n",
      "Training at Epoch 11 iteration 300 with loss 0.397745\n",
      "Training at Epoch 11 iteration 400 with loss 0.21142568\n",
      "Training at Epoch 11 iteration 500 with loss 0.3331135\n",
      "Training at Epoch 11 iteration 600 with loss 0.44820458\n",
      "Training at Epoch 11 iteration 700 with loss 0.27017954\n",
      "Training at Epoch 11 iteration 800 with loss 0.24693109\n",
      "Training at Epoch 11 iteration 900 with loss 0.69753885\n",
      "Training at Epoch 11 iteration 1000 with loss 0.063678004\n",
      "Training at Epoch 11 iteration 1100 with loss 0.052771576\n",
      "Training at Epoch 11 iteration 1200 with loss 0.14558806\n",
      "Training at Epoch 11 iteration 1300 with loss 0.056426637\n",
      "Validation at Epoch 11 , MSE: 0.3038033502078903 , Pearson Correlation: 0.7721714490799871 with p-value: 0.0 , Concordance Index: 0.8541225254569603\n",
      "Training at Epoch 12 iteration 0 with loss 0.039350193\n",
      "Training at Epoch 12 iteration 100 with loss 0.44744033\n",
      "Training at Epoch 12 iteration 200 with loss 0.07435378\n",
      "Training at Epoch 12 iteration 300 with loss 0.082406074\n",
      "Training at Epoch 12 iteration 400 with loss 0.22471157\n",
      "Training at Epoch 12 iteration 500 with loss 0.11562836\n",
      "Training at Epoch 12 iteration 600 with loss 0.17211896\n",
      "Training at Epoch 12 iteration 700 with loss 0.34762746\n",
      "Training at Epoch 12 iteration 800 with loss 0.4345094\n",
      "Training at Epoch 12 iteration 900 with loss 0.1324827\n",
      "Training at Epoch 12 iteration 1000 with loss 0.22761506\n",
      "Training at Epoch 12 iteration 1100 with loss 0.354333\n",
      "Training at Epoch 12 iteration 1200 with loss 0.46646455\n",
      "Training at Epoch 12 iteration 1300 with loss 0.39123937\n",
      "Validation at Epoch 12 , MSE: 0.3235827307563093 , Pearson Correlation: 0.7706878224994513 with p-value: 0.0 , Concordance Index: 0.8569288961974434\n",
      "Training at Epoch 13 iteration 0 with loss 0.36540863\n",
      "Training at Epoch 13 iteration 100 with loss 0.28763264\n",
      "Training at Epoch 13 iteration 200 with loss 0.28553036\n",
      "Training at Epoch 13 iteration 300 with loss 0.030978093\n",
      "Training at Epoch 13 iteration 400 with loss 0.16451232\n",
      "Training at Epoch 13 iteration 500 with loss 0.051599868\n",
      "Training at Epoch 13 iteration 600 with loss 0.1436593\n",
      "Training at Epoch 13 iteration 700 with loss 0.16178288\n",
      "Training at Epoch 13 iteration 800 with loss 0.61937016\n",
      "Training at Epoch 13 iteration 900 with loss 0.17615162\n",
      "Training at Epoch 13 iteration 1000 with loss 0.0402334\n",
      "Training at Epoch 13 iteration 1100 with loss 0.21694359\n",
      "Training at Epoch 13 iteration 1200 with loss 0.48769438\n",
      "Training at Epoch 13 iteration 1300 with loss 0.18604115\n",
      "Validation at Epoch 13 , MSE: 0.30921782640658163 , Pearson Correlation: 0.7723120969487463 with p-value: 0.0 , Concordance Index: 0.8582575246488029\n",
      "Training at Epoch 14 iteration 0 with loss 0.10967553\n",
      "Training at Epoch 14 iteration 100 with loss 0.11715732\n",
      "Training at Epoch 14 iteration 200 with loss 0.26013288\n",
      "Training at Epoch 14 iteration 300 with loss 0.09002142\n",
      "Training at Epoch 14 iteration 400 with loss 0.23169737\n",
      "Training at Epoch 14 iteration 500 with loss 0.69265604\n",
      "Training at Epoch 14 iteration 600 with loss 0.12527631\n",
      "Training at Epoch 14 iteration 700 with loss 0.1159018\n",
      "Training at Epoch 14 iteration 800 with loss 0.08369012\n",
      "Training at Epoch 14 iteration 900 with loss 0.16083902\n",
      "Training at Epoch 14 iteration 1000 with loss 0.26585466\n",
      "Training at Epoch 14 iteration 1100 with loss 0.5673704\n",
      "Training at Epoch 14 iteration 1200 with loss 0.1203098\n",
      "Training at Epoch 14 iteration 1300 with loss 0.045395307\n",
      "Validation at Epoch 14 , MSE: 0.3134570095085723 , Pearson Correlation: 0.773267800248544 with p-value: 0.0 , Concordance Index: 0.8632059519040893\n",
      "Training at Epoch 15 iteration 0 with loss 0.328855\n",
      "Training at Epoch 15 iteration 100 with loss 0.0795923\n",
      "Training at Epoch 15 iteration 200 with loss 0.3228597\n",
      "Training at Epoch 15 iteration 300 with loss 0.048132095\n",
      "Training at Epoch 15 iteration 400 with loss 0.056906234\n",
      "Training at Epoch 15 iteration 500 with loss 0.23384269\n",
      "Training at Epoch 15 iteration 600 with loss 0.1274816\n",
      "Training at Epoch 15 iteration 700 with loss 0.37157667\n",
      "Training at Epoch 15 iteration 800 with loss 0.55148\n",
      "Training at Epoch 15 iteration 900 with loss 0.23006032\n",
      "Training at Epoch 15 iteration 1000 with loss 0.116372086\n",
      "Training at Epoch 15 iteration 1100 with loss 0.1698446\n",
      "Training at Epoch 15 iteration 1200 with loss 0.016214069\n",
      "Training at Epoch 15 iteration 1300 with loss 0.38068137\n",
      "Validation at Epoch 15 , MSE: 0.31824670217525214 , Pearson Correlation: 0.7614795946852672 with p-value: 0.0 , Concordance Index: 0.8582898070260507\n",
      "Training at Epoch 16 iteration 0 with loss 0.17339186\n",
      "Training at Epoch 16 iteration 100 with loss 0.25362486\n",
      "Training at Epoch 16 iteration 200 with loss 0.18084691\n",
      "Training at Epoch 16 iteration 300 with loss 0.4137621\n",
      "Training at Epoch 16 iteration 400 with loss 0.20456174\n",
      "Training at Epoch 16 iteration 500 with loss 0.115403876\n",
      "Training at Epoch 16 iteration 600 with loss 0.018127626\n",
      "Training at Epoch 16 iteration 700 with loss 0.15059033\n",
      "Training at Epoch 16 iteration 800 with loss 0.108066425\n",
      "Training at Epoch 16 iteration 900 with loss 0.19758745\n",
      "Training at Epoch 16 iteration 1000 with loss 0.059876796\n",
      "Training at Epoch 16 iteration 1100 with loss 0.22343284\n",
      "Training at Epoch 16 iteration 1200 with loss 0.1755556\n",
      "Training at Epoch 16 iteration 1300 with loss 0.98487127\n",
      "Validation at Epoch 16 , MSE: 0.3163274787701699 , Pearson Correlation: 0.7702616954956548 with p-value: 0.0 , Concordance Index: 0.8493609846168982\n",
      "Training at Epoch 17 iteration 0 with loss 0.20126201\n",
      "Training at Epoch 17 iteration 100 with loss 0.13425669\n",
      "Training at Epoch 17 iteration 200 with loss 0.6761147\n",
      "Training at Epoch 17 iteration 300 with loss 0.13430059\n",
      "Training at Epoch 17 iteration 400 with loss 0.22851345\n",
      "Training at Epoch 17 iteration 500 with loss 0.07883597\n",
      "Training at Epoch 17 iteration 600 with loss 0.08727354\n",
      "Training at Epoch 17 iteration 700 with loss 0.23258106\n",
      "Training at Epoch 17 iteration 800 with loss 0.2758598\n",
      "Training at Epoch 17 iteration 900 with loss 0.35162196\n",
      "Training at Epoch 17 iteration 1000 with loss 0.24195898\n",
      "Training at Epoch 17 iteration 1100 with loss 0.1612456\n",
      "Training at Epoch 17 iteration 1200 with loss 0.28351104\n",
      "Training at Epoch 17 iteration 1300 with loss 0.17672984\n",
      "Validation at Epoch 17 , MSE: 0.3044262069131568 , Pearson Correlation: 0.773185699497208 with p-value: 0.0 , Concordance Index: 0.8566967705324704\n",
      "Training at Epoch 18 iteration 0 with loss 0.25885928\n",
      "Training at Epoch 18 iteration 100 with loss 0.18823175\n",
      "Training at Epoch 18 iteration 200 with loss 0.17267035\n",
      "Training at Epoch 18 iteration 300 with loss 1.3717865\n",
      "Training at Epoch 18 iteration 400 with loss 0.7828093\n",
      "Training at Epoch 18 iteration 500 with loss 0.88828623\n",
      "Training at Epoch 18 iteration 600 with loss 0.09067569\n",
      "Training at Epoch 18 iteration 700 with loss 0.20858243\n",
      "Training at Epoch 18 iteration 800 with loss 0.63711417\n",
      "Training at Epoch 18 iteration 900 with loss 0.2536072\n",
      "Training at Epoch 18 iteration 1000 with loss 0.13323395\n",
      "Training at Epoch 18 iteration 1100 with loss 0.41658086\n",
      "Training at Epoch 18 iteration 1200 with loss 0.0947012\n",
      "Training at Epoch 18 iteration 1300 with loss 0.3649518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation at Epoch 18 , MSE: 0.30469911655537024 , Pearson Correlation: 0.7733982739891384 with p-value: 0.0 , Concordance Index: 0.8607292127843484\n",
      "Training at Epoch 19 iteration 0 with loss 0.049213365\n",
      "Training at Epoch 19 iteration 100 with loss 0.21890602\n",
      "Training at Epoch 19 iteration 200 with loss 0.10918429\n",
      "Training at Epoch 19 iteration 300 with loss 0.46962386\n",
      "Training at Epoch 19 iteration 400 with loss 0.09832353\n",
      "Training at Epoch 19 iteration 500 with loss 0.27338734\n",
      "Training at Epoch 19 iteration 600 with loss 0.1602433\n",
      "Training at Epoch 19 iteration 700 with loss 0.11781935\n",
      "Training at Epoch 19 iteration 800 with loss 0.056241885\n",
      "Training at Epoch 19 iteration 900 with loss 0.087722026\n",
      "Training at Epoch 19 iteration 1000 with loss 0.1243666\n",
      "Training at Epoch 19 iteration 1100 with loss 0.11407921\n",
      "Training at Epoch 19 iteration 1200 with loss 0.091633745\n",
      "Training at Epoch 19 iteration 1300 with loss 0.19156292\n",
      "Validation at Epoch 19 , MSE: 0.32281963115546075 , Pearson Correlation: 0.7594975035222952 with p-value: 0.0 , Concordance Index: 0.8513682018144892\n",
      "Training at Epoch 20 iteration 0 with loss 0.53367186\n",
      "Training at Epoch 20 iteration 100 with loss 0.08816124\n",
      "Training at Epoch 20 iteration 200 with loss 0.08284724\n",
      "Training at Epoch 20 iteration 300 with loss 0.092265315\n",
      "Training at Epoch 20 iteration 400 with loss 0.07095027\n",
      "Training at Epoch 20 iteration 500 with loss 0.15450548\n",
      "Training at Epoch 20 iteration 600 with loss 0.50977534\n",
      "Training at Epoch 20 iteration 700 with loss 0.32550377\n",
      "Training at Epoch 20 iteration 800 with loss 0.30475175\n",
      "Training at Epoch 20 iteration 900 with loss 0.21852213\n",
      "Training at Epoch 20 iteration 1000 with loss 0.22982292\n",
      "Training at Epoch 20 iteration 1100 with loss 0.20071411\n",
      "Training at Epoch 20 iteration 1200 with loss 0.11415521\n",
      "Training at Epoch 20 iteration 1300 with loss 0.1572446\n",
      "Validation at Epoch 20 , MSE: 0.30254131308670207 , Pearson Correlation: 0.7740549546768687 with p-value: 0.0 , Concordance Index: 0.8634172148082558\n",
      "Training at Epoch 21 iteration 0 with loss 0.09219951\n",
      "Training at Epoch 21 iteration 100 with loss 0.1762352\n",
      "Training at Epoch 21 iteration 200 with loss 0.15906675\n",
      "Training at Epoch 21 iteration 300 with loss 0.33492392\n",
      "Training at Epoch 21 iteration 400 with loss 0.30389693\n",
      "Training at Epoch 21 iteration 500 with loss 0.04511091\n",
      "Training at Epoch 21 iteration 600 with loss 0.15068577\n",
      "Training at Epoch 21 iteration 700 with loss 0.13668321\n",
      "Training at Epoch 21 iteration 800 with loss 0.11887219\n",
      "Training at Epoch 21 iteration 900 with loss 0.073972166\n",
      "Training at Epoch 21 iteration 1000 with loss 0.14987817\n",
      "Training at Epoch 21 iteration 1100 with loss 0.20774227\n",
      "Training at Epoch 21 iteration 1200 with loss 0.43731764\n",
      "Training at Epoch 21 iteration 1300 with loss 0.28029525\n",
      "Validation at Epoch 21 , MSE: 0.30279697240104986 , Pearson Correlation: 0.7751916090042543 with p-value: 0.0 , Concordance Index: 0.8593513921390874\n",
      "Training at Epoch 22 iteration 0 with loss 0.47675747\n",
      "Training at Epoch 22 iteration 100 with loss 0.16025512\n",
      "Training at Epoch 22 iteration 200 with loss 0.22500193\n",
      "Training at Epoch 22 iteration 300 with loss 0.5613177\n",
      "Training at Epoch 22 iteration 400 with loss 0.16814135\n",
      "Training at Epoch 22 iteration 500 with loss 0.1244846\n",
      "Training at Epoch 22 iteration 600 with loss 0.2569944\n",
      "Training at Epoch 22 iteration 700 with loss 0.30753312\n",
      "Training at Epoch 22 iteration 800 with loss 0.3588439\n",
      "Training at Epoch 22 iteration 900 with loss 0.18741742\n",
      "Training at Epoch 22 iteration 1000 with loss 0.1276057\n",
      "Training at Epoch 22 iteration 1100 with loss 0.17758548\n",
      "Training at Epoch 22 iteration 1200 with loss 0.31092086\n",
      "Training at Epoch 22 iteration 1300 with loss 0.063216604\n",
      "Validation at Epoch 22 , MSE: 0.2938917225092974 , Pearson Correlation: 0.7801638757339329 with p-value: 0.0 , Concordance Index: 0.8598015885564902\n",
      "Training at Epoch 23 iteration 0 with loss 0.14127028\n",
      "Training at Epoch 23 iteration 100 with loss 0.0682358\n",
      "Training at Epoch 23 iteration 200 with loss 0.026445406\n",
      "Training at Epoch 23 iteration 300 with loss 0.08639736\n",
      "Training at Epoch 23 iteration 400 with loss 0.080832765\n",
      "Training at Epoch 23 iteration 500 with loss 0.18240203\n",
      "Training at Epoch 23 iteration 600 with loss 0.022041814\n",
      "Training at Epoch 23 iteration 700 with loss 0.22972474\n",
      "Training at Epoch 23 iteration 800 with loss 0.31881282\n",
      "Training at Epoch 23 iteration 900 with loss 0.39744717\n",
      "Training at Epoch 23 iteration 1000 with loss 0.094647154\n",
      "Training at Epoch 23 iteration 1100 with loss 0.25412342\n",
      "Training at Epoch 23 iteration 1200 with loss 0.23590271\n",
      "Training at Epoch 23 iteration 1300 with loss 0.378773\n",
      "Validation at Epoch 23 , MSE: 0.39280568353093476 , Pearson Correlation: 0.7736033211771693 with p-value: 0.0 , Concordance Index: 0.8614824682534663\n",
      "Training at Epoch 24 iteration 0 with loss 0.14838716\n",
      "Training at Epoch 24 iteration 100 with loss 0.15339836\n",
      "Training at Epoch 24 iteration 200 with loss 0.15267013\n",
      "Training at Epoch 24 iteration 300 with loss 0.031368718\n",
      "Training at Epoch 24 iteration 400 with loss 0.17953971\n",
      "Training at Epoch 24 iteration 500 with loss 0.12565073\n",
      "Training at Epoch 24 iteration 600 with loss 0.06560057\n",
      "Training at Epoch 24 iteration 700 with loss 0.043854624\n",
      "Training at Epoch 24 iteration 800 with loss 0.2889069\n",
      "Training at Epoch 24 iteration 900 with loss 0.19156884\n",
      "Training at Epoch 24 iteration 1000 with loss 0.3155557\n",
      "Training at Epoch 24 iteration 1100 with loss 0.027295467\n",
      "Training at Epoch 24 iteration 1200 with loss 0.13190165\n",
      "Training at Epoch 24 iteration 1300 with loss 0.21689162\n",
      "Validation at Epoch 24 , MSE: 0.3421036425313141 , Pearson Correlation: 0.7834859084480417 with p-value: 0.0 , Concordance Index: 0.8587331955951905\n",
      "Training at Epoch 25 iteration 0 with loss 0.11090569\n",
      "Training at Epoch 25 iteration 100 with loss 0.8473665\n",
      "Training at Epoch 25 iteration 200 with loss 0.13867155\n",
      "Training at Epoch 25 iteration 300 with loss 0.22319402\n",
      "Training at Epoch 25 iteration 400 with loss 0.12700303\n",
      "Training at Epoch 25 iteration 500 with loss 0.22641315\n",
      "Training at Epoch 25 iteration 600 with loss 0.3128882\n",
      "Training at Epoch 25 iteration 700 with loss 0.23121701\n",
      "Training at Epoch 25 iteration 800 with loss 0.1766106\n",
      "Training at Epoch 25 iteration 900 with loss 0.18570061\n",
      "Training at Epoch 25 iteration 1000 with loss 0.1367924\n",
      "Training at Epoch 25 iteration 1100 with loss 0.061741427\n",
      "Training at Epoch 25 iteration 1200 with loss 0.13138065\n",
      "Training at Epoch 25 iteration 1300 with loss 0.20691113\n",
      "Validation at Epoch 25 , MSE: 0.29762727943087763 , Pearson Correlation: 0.777600914263368 with p-value: 0.0 , Concordance Index: 0.8617464370796702\n",
      "Training at Epoch 26 iteration 0 with loss 0.35112044\n",
      "Training at Epoch 26 iteration 100 with loss 0.0755126\n",
      "Training at Epoch 26 iteration 200 with loss 0.06384772\n",
      "Training at Epoch 26 iteration 300 with loss 0.12912366\n",
      "Training at Epoch 26 iteration 400 with loss 0.08278365\n",
      "Training at Epoch 26 iteration 500 with loss 0.15557528\n",
      "Training at Epoch 26 iteration 600 with loss 0.0716977\n",
      "Training at Epoch 26 iteration 700 with loss 0.4022516\n",
      "Training at Epoch 26 iteration 800 with loss 0.15188706\n",
      "Training at Epoch 26 iteration 900 with loss 0.050492294\n",
      "Training at Epoch 26 iteration 1000 with loss 0.087813154\n",
      "Training at Epoch 26 iteration 1100 with loss 0.06268394\n",
      "Training at Epoch 26 iteration 1200 with loss 0.27646783\n",
      "Training at Epoch 26 iteration 1300 with loss 0.33461422\n",
      "Validation at Epoch 26 , MSE: 0.308806593250094 , Pearson Correlation: 0.7843391429787356 with p-value: 0.0 , Concordance Index: 0.8628510653623708\n",
      "Training at Epoch 27 iteration 0 with loss 0.09833125\n",
      "Training at Epoch 27 iteration 100 with loss 0.07687757\n",
      "Training at Epoch 27 iteration 200 with loss 0.037706967\n",
      "Training at Epoch 27 iteration 300 with loss 0.24319077\n",
      "Training at Epoch 27 iteration 400 with loss 0.21295199\n",
      "Training at Epoch 27 iteration 500 with loss 0.13735588\n",
      "Training at Epoch 27 iteration 600 with loss 0.12043725\n",
      "Training at Epoch 27 iteration 700 with loss 0.29292047\n",
      "Training at Epoch 27 iteration 800 with loss 0.44502294\n",
      "Training at Epoch 27 iteration 900 with loss 0.33541578\n",
      "Training at Epoch 27 iteration 1000 with loss 0.18086761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 27 iteration 1100 with loss 0.17451991\n",
      "Training at Epoch 27 iteration 1200 with loss 0.2964872\n",
      "Training at Epoch 27 iteration 1300 with loss 0.27980348\n",
      "Validation at Epoch 27 , MSE: 0.305921219399845 , Pearson Correlation: 0.7815690648189262 with p-value: 0.0 , Concordance Index: 0.8610707032375491\n",
      "Training at Epoch 28 iteration 0 with loss 0.3437407\n",
      "Training at Epoch 28 iteration 100 with loss 0.079807535\n",
      "Training at Epoch 28 iteration 200 with loss 0.6265162\n",
      "Training at Epoch 28 iteration 300 with loss 0.056284208\n",
      "Training at Epoch 28 iteration 400 with loss 0.21211028\n",
      "Training at Epoch 28 iteration 500 with loss 0.46807632\n",
      "Training at Epoch 28 iteration 600 with loss 0.55382514\n",
      "Training at Epoch 28 iteration 700 with loss 0.30266973\n",
      "Training at Epoch 28 iteration 800 with loss 0.34189954\n",
      "Training at Epoch 28 iteration 900 with loss 0.030159222\n",
      "Training at Epoch 28 iteration 1000 with loss 0.26034155\n",
      "Training at Epoch 28 iteration 1100 with loss 0.25772482\n",
      "Training at Epoch 28 iteration 1200 with loss 0.22466052\n",
      "Training at Epoch 28 iteration 1300 with loss 0.21252331\n",
      "Validation at Epoch 28 , MSE: 0.30147315950370673 , Pearson Correlation: 0.7811465129730828 with p-value: 0.0 , Concordance Index: 0.8557050207661333\n",
      "Training at Epoch 29 iteration 0 with loss 0.28468615\n",
      "Training at Epoch 29 iteration 100 with loss 0.06851866\n",
      "Training at Epoch 29 iteration 200 with loss 0.1977443\n",
      "Training at Epoch 29 iteration 300 with loss 0.29838008\n",
      "Training at Epoch 29 iteration 400 with loss 0.048205346\n",
      "Training at Epoch 29 iteration 500 with loss 0.3806076\n",
      "Training at Epoch 29 iteration 600 with loss 0.259853\n",
      "Training at Epoch 29 iteration 700 with loss 0.2708258\n",
      "Training at Epoch 29 iteration 800 with loss 0.16178373\n",
      "Training at Epoch 29 iteration 900 with loss 0.2775786\n",
      "Training at Epoch 29 iteration 1000 with loss 0.14811769\n",
      "Training at Epoch 29 iteration 1100 with loss 0.10863811\n",
      "Training at Epoch 29 iteration 1200 with loss 0.16432898\n",
      "Training at Epoch 29 iteration 1300 with loss 0.33355373\n",
      "Validation at Epoch 29 , MSE: 0.3136866711960009 , Pearson Correlation: 0.7720167256098882 with p-value: 0.0 , Concordance Index: 0.8540865097435681\n",
      "Training at Epoch 30 iteration 0 with loss 0.27789\n",
      "Training at Epoch 30 iteration 100 with loss 0.14670148\n",
      "Training at Epoch 30 iteration 200 with loss 0.15566112\n",
      "Training at Epoch 30 iteration 300 with loss 0.1525705\n",
      "Training at Epoch 30 iteration 400 with loss 0.0704634\n",
      "Training at Epoch 30 iteration 500 with loss 0.30786595\n",
      "Training at Epoch 30 iteration 600 with loss 0.22842112\n",
      "Training at Epoch 30 iteration 700 with loss 0.11517185\n",
      "Training at Epoch 30 iteration 800 with loss 0.19768125\n",
      "Training at Epoch 30 iteration 900 with loss 0.054173265\n",
      "Training at Epoch 30 iteration 1000 with loss 0.030902538\n",
      "Training at Epoch 30 iteration 1100 with loss 0.030927958\n",
      "Training at Epoch 30 iteration 1200 with loss 0.12833662\n",
      "Training at Epoch 30 iteration 1300 with loss 0.27119812\n",
      "Validation at Epoch 30 , MSE: 0.30254828804015305 , Pearson Correlation: 0.778635352585396 with p-value: 0.0 , Concordance Index: 0.8564701350677095\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.2809569065991725 , Pearson Correlation: 0.8037093414888673 with p-value: 0.0 , Concordance Index: 0.8680340658564099\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./model_GraphDTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
